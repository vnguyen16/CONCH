{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from conch.open_clip_custom import create_model_from_pretrained, tokenize, get_tokenizer\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import skimage\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from huggingface_hub import login, hf_hub_download\n",
    "\n",
    "# show all jupyter output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('../').resolve()\n",
    "os.chdir(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONCHModelForFinetuning(nn.Module):\n",
    "    def __init__(self, num_classes=2, config={'hidden_size': 512}): # change number of classes for each dataset(8 for breast, 2 for breast)\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.model = self.make_conch()\n",
    "        # self.fc = nn.Linear(self.config['hidden_size'], num_classes) # full finetuning?\n",
    "\n",
    "        # linear probing\n",
    "        # Freeze all parameters in the backbone\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Only this linear layer will be trained\n",
    "        self.fc = nn.Linear(self.config['hidden_size'], num_classes)\n",
    "\n",
    "    def make_conch(self):\n",
    "        # Load the model from \"create_model_from_pretrained\"\n",
    "        model_cfg = 'conch_ViT-B-16'\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        # checkpoint_path = 'checkpoints/CONCH/pytorch_model.bin'\n",
    "        checkpoint_path = 'C:\\\\Users\\\\Vivian\\\\Documents\\\\CONCH\\\\checkpoints\\\\conch\\\\pytorch_model.bin' # load in checkpoint here\n",
    "        # checkpoint_path = r'C:\\Users\\Vivian\\Documents\\CONCH\\_finetune_weights\\Fold2_F_PT_model.pth' # loading breakhis finetuned model\n",
    "        model, preprocess = create_model_from_pretrained(model_cfg, checkpoint_path, device=device)\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, h = self.model.visual(x)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CONCHModelForFinetuning().to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load breakhis (PT + FA) checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONCHModelForFinetuning(nn.Module):\n",
    "    def __init__(self, num_classes=2, config={'hidden_size': 512}, checkpoint_path=None):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.model = self.make_conch()\n",
    "        self.fc = nn.Linear(self.config['hidden_size'], num_classes)\n",
    "\n",
    "        if checkpoint_path is not None:\n",
    "            print(f\"Loading fine-tuned weights from: {checkpoint_path}\")\n",
    "            self.load_state_dict(torch.load(checkpoint_path, map_location='cuda'))\n",
    "\n",
    "    def make_conch(self):\n",
    "        # Load the base pretrained model\n",
    "        model_cfg = 'conch_ViT-B-16'\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        base_checkpoint = 'C:\\\\Users\\\\Vivian\\\\Documents\\\\CONCH\\\\checkpoints\\\\conch\\\\pytorch_model.bin'\n",
    "        model, _ = create_model_from_pretrained(model_cfg, base_checkpoint, device=device)\n",
    "        return model\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, h = self.model.visual(x)\n",
    "        return self.fc(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = r'C:\\Users\\Vivian\\Documents\\CONCH\\_finetune_weights\\Fold2_F_PT_model.pth'\n",
    "model = CONCHModelForFinetuning(num_classes=2, checkpoint_path=checkpoint_path).to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNI 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class UNI2ModelForFinetuning(nn.Module):\n",
    "    def __init__(self, num_classes=2): # change number of classes for each dataset\n",
    "        super().__init__()\n",
    "        # self.config = config\n",
    "        self.model = self.make_uni2()\n",
    "        # self.fc = nn.Linear(1536, num_classes)  # Match Vision Transformer output # full finetuning\n",
    "\n",
    "        # Freeze all backbone parameters for linear probing\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Add a small trainable classification head\n",
    "        self.fc = nn.Linear(1536, num_classes)  # Match Vision Transformer output\n",
    "\n",
    "    def make_uni2(self):\n",
    "        # # Load the model from \"create_model_from_pretrained\"\n",
    "        # model_cfg = 'conch_ViT-B-16'\n",
    "        # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        # # checkpoint_path = 'checkpoints/CONCH/pytorch_model.bin'\n",
    "        # checkpoint_path = 'C:\\\\Users\\\\Vivian\\\\Documents\\\\CONCH\\\\checkpoints\\\\conch\\\\pytorch_model.bin' # load in checkpoint here\n",
    "        # model, preprocess = create_model_from_pretrained(model_cfg, checkpoint_path, device=device)\n",
    "        \n",
    "        # return model\n",
    "\n",
    "        # local_dir = 'assets\\\\ckpts\\\\uni2-h'\n",
    "        local_dir = 'C:\\\\Users\\\\Vivian\\\\Documents\\\\UNI2\\\\UNI\\\\assets\\\\ckpts\\\\uni2-h' \n",
    "        os.makedirs(local_dir, exist_ok=True)  # create directory if it does not exist\n",
    "        # hf_hub_download(\"MahmoodLab/UNI2-h\", filename=\"pytorch_model.bin\", local_dir=local_dir, force_download=True)\n",
    "       \n",
    "        timm_kwargs = {\n",
    "        'model_name': 'vit_giant_patch14_224',\n",
    "        'img_size': 224, \n",
    "        'patch_size': 14, \n",
    "        'depth': 24,\n",
    "        'num_heads': 24,\n",
    "        'init_values': 1e-5, \n",
    "        'embed_dim': 1536,\n",
    "        'mlp_ratio': 2.66667*2,\n",
    "        'num_classes': 0, \n",
    "        'no_embed_class': True,\n",
    "        'mlp_layer': timm.layers.SwiGLUPacked, \n",
    "        'act_layer': torch.nn.SiLU, \n",
    "        'reg_tokens': 8, \n",
    "        'dynamic_img_size': True\n",
    "        }\n",
    "        model = timm.create_model(**timm_kwargs)\n",
    "        model.load_state_dict(torch.load(os.path.join(local_dir, \"pytorch_model.bin\"), map_location=\"cpu\"), strict=True)\n",
    "        # transform = transforms.Compose(\n",
    "        # [\n",
    "        # transforms.Resize(224),\n",
    "        # transforms.CenterCrop(224),\n",
    "        # transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        # ]\n",
    "        # )\n",
    "\n",
    "        return model \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        # out, h = self.model.visual(x)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNI2ModelForFinetuning().to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from huggingface_hub import login, hf_hub_download\n",
    "\n",
    "\n",
    "class UNIModelForFinetuning(nn.Module):\n",
    "    def __init__(self, num_classes=2,checkpoint_path=None): # change number of classes accordingly \n",
    "        ## ************ change for UNI ************\n",
    "        super().__init__()\n",
    "        # self.config = config\n",
    "        self.model = self.make_uni()\n",
    "        # self.fc = nn.Linear(self.config['hidden_size'], num_classes) # keep commented\n",
    "        # self.fc = nn.Linear(1024, num_classes)  # Match Vision Transformer output # full finetuning\n",
    "\n",
    "        #***** Freeze all backbone parameters - linear probing *****\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Add a trainable classification head\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "\n",
    "        # ----- Load checkpoint if needed -----\n",
    "        if checkpoint_path:\n",
    "            print(f\"Loading checkpoint from: {checkpoint_path}\")\n",
    "            self.load_state_dict(torch.load(checkpoint_path, map_location='cuda'))\n",
    "    \n",
    "    def make_uni(self):\n",
    "        # login()  # login with your User Access Token, found at https://huggingface.co/settings/tokens\n",
    "\n",
    "        local_dir = r\"C:\\Users\\Vivian\\Documents\\CONCH\\checkpoints\\uni\" # load in UNI model\n",
    "        os.makedirs(local_dir, exist_ok=True)  # create directory if it does not exist\n",
    "        \n",
    "        # hf_hub_download(\"MahmoodLab/UNI\", filename=\"pytorch_model.bin\", local_dir=local_dir, force_download=True)\n",
    "        model = timm.create_model(\n",
    "            \"vit_large_patch16_224\", img_size=224, patch_size=16, init_values=1e-5, num_classes=0, dynamic_img_size=True\n",
    "        )\n",
    "        model.load_state_dict(torch.load(os.path.join(local_dir, \"pytorch_model.bin\"), map_location=\"cpu\"), strict=True)\n",
    "        \n",
    "        # transform = transforms.Compose(\n",
    "        #     [\n",
    "        #         transforms.Resize(224),\n",
    "        #         transforms.ToTensor(),\n",
    "        #         transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        #     ]\n",
    "        # )\n",
    "        # model.eval()\n",
    "        return model \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        # out, h = self.model.visual(x)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNIModelForFinetuning().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a checkpoint\n",
    "model = UNIModelForFinetuning(num_classes=2, checkpoint_path=r\"C:\\Users\\Vivian\\Documents\\CONCH\\_finetune_weights_UNI\\linprob_ann_CL_uni.pth\").to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# resnet = models.resnet18(pretrained=True) # resnet18\n",
    "resnet = models.resnet50(pretrained=True) # resnet50\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, 2)  # 2 output classes for CrossEntropyLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Making metadata -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves metadata to csv for each fold and mode - use this \n",
    "# need to make metadata for new datasets\n",
    "def make_metadata(fold):\n",
    "    metadata = pd.DataFrame()\n",
    "    for mode in ['train', 'test']:\n",
    "        pathname = f'/Users/Vivian/Documents/CONCH/Folds/Fold {fold}/{mode}/'\n",
    "        images = os.listdir(pathname)\n",
    "        for image in images:\n",
    "            if not image.startswith('SOB'):\n",
    "                continue\n",
    "            label = image.split('-')[0].replace('SOB_', '')\n",
    "            class_name, subclass_name = label.split('_')\n",
    "            #metadata = metadata.append({'image': pathname+image, 'fold': fold, 'mode': mode, 'class': class_name, 'subclass': subclass_name}, ignore_index=True)\n",
    "            metadata = pd.concat([metadata, pd.DataFrame({'image': pathname+image, 'fold': fold, 'mode': mode, 'class': class_name, 'subclass': subclass_name}, index=[0])], ignore_index=True)\n",
    "        metadata.to_csv(f'/Users/Vivian/Documents/CONCH/Folds/Fold {fold}/{mode}/metadata.csv', index=False)\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making metadata for our private dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def make_metadata():\n",
    "    metadata = pd.DataFrame()\n",
    "    \n",
    "    # # Define paths\n",
    "    # base_path = \"patches\"  # Root where patches are stored\n",
    "    # metadata_dir = \"metadata\"  # Directory containing train/test CSVs\n",
    "    # output_dir = \"metadata/fine_tuning\"  # Where metadata CSVs will be saved\n",
    "    # os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # ***********Define paths for only test set\n",
    "    base_path = \"patches_annotated\"  # Root where patches are stored\n",
    "    metadata_dir = \"metadata\"  # Directory containing train/test CSVs\n",
    "    output_dir = \"metadata/fine_tuning\"  # Where metadata CSVs will be saved\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # ************\n",
    "\n",
    "    # Load train/test slide selections\n",
    "    # train_slides = pd.read_csv(os.path.join(metadata_dir, \"train_patient_split.csv\"))\n",
    "    test_slides = pd.read_csv(os.path.join(metadata_dir, \"test_ann_series8.csv\"))\n",
    "\n",
    "    # train_slides = pd.read_csv(os.path.join(metadata_dir, \"train_all_slides.csv\"))\n",
    "    # test_slides = pd.read_csv(os.path.join(metadata_dir, \"test_all_slides.csv\"))\n",
    "\n",
    "\n",
    "    # Process both train and test sets\n",
    "    # for mode, slides_df in zip([\"train\", \"test\"], [train_slides, test_slides]):\n",
    "    for mode, slides_df in zip([\"test\"], [test_slides]): # only creating test set\n",
    "\n",
    "        entries = []\n",
    "        \n",
    "        for _, row in slides_df.iterrows():\n",
    "            slide_name = row[\"Filename\"]\n",
    "            class_name = row[\"Class\"]\n",
    "            magnification = f\"{row['Magnification']}x\"\n",
    "\n",
    "            # Define the path where patches are stored for this slide\n",
    "            slide_patch_dir = os.path.join(base_path, magnification, class_name, slide_name)\n",
    "\n",
    "            # Ensure slide directory exists and has patches\n",
    "            if not os.path.exists(slide_patch_dir) or len(os.listdir(slide_patch_dir)) == 0:\n",
    "                print(f\"Skipping {slide_name}: No patches found.\")\n",
    "                continue\n",
    "            \n",
    "            # Add all patches in the slide directory to the metadata\n",
    "            for patch_file in os.listdir(slide_patch_dir):\n",
    "                if patch_file.endswith(\".npy\"):  # Ensure we're only adding valid patch files\n",
    "                    patch_path = os.path.join(slide_patch_dir, patch_file)\n",
    "                    entries.append({\n",
    "                        \"image\": patch_path,\n",
    "                        \"fold\": 1,  # Since you're using only one fold\n",
    "                        \"mode\": mode,\n",
    "                        \"class\": class_name,\n",
    "                        \"magnification\": magnification\n",
    "                    })\n",
    "\n",
    "        # Convert list to DataFrame\n",
    "        mode_metadata = pd.DataFrame(entries)\n",
    "\n",
    "        # output_csv = \n",
    "\n",
    "        # Save metadata CSV for the mode\n",
    "        mode_metadata.to_csv(os.path.join(output_dir, f\"{mode}_ann_series8_2.csv\"), index=False) # manually change metadata file name here\n",
    "\n",
    "        print(f\"Saved {mode}_ann_series8_2.csv with {len(mode_metadata)} entries.\")\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making metadata for our private dataset - train, val, test\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def make_metadata():\n",
    "    # === CONFIGURATION ===\n",
    "    annotated_base_path = r\"C:\\Users\\Vivian\\Documents\\CONCH\\patches_tiled\\patches_10x\"\n",
    "    # fallback_base_path = \"patches\"\n",
    "    metadata_dir = \"metadata/patient_split_annotate/slide_csv\"\n",
    "    output_dir = \"metadata/patient_split_annotate/patch_csv_10x\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Define your CSVs and the filenames for outputs\n",
    "    slide_sets = {\n",
    "        \"train\": {\n",
    "            \"input_csv\": os.path.join(metadata_dir, \"train_split.csv\"),\n",
    "            \"output_csv\": \"train_patches.csv\"\n",
    "        },\n",
    "        \"val\": {\n",
    "            \"input_csv\": os.path.join(metadata_dir, \"val_split.csv\"),\n",
    "            \"output_csv\": \"val_patches.csv\"\n",
    "        },\n",
    "        \"test\": {\n",
    "            \"input_csv\": os.path.join(metadata_dir, \"test_split.csv\"),\n",
    "            \"output_csv\": \"test_patches.csv\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # === PROCESS EACH SET ===\n",
    "    for mode, paths in slide_sets.items():\n",
    "        slides_df = pd.read_csv(paths[\"input_csv\"])\n",
    "        entries = []\n",
    "\n",
    "        for _, row in slides_df.iterrows():\n",
    "            slide_name = row[\"Filename\"]\n",
    "            class_name = row[\"Class\"]\n",
    "            magnification = f\"{row['Magnification']}x\"\n",
    "\n",
    "            # Try annotated path first\n",
    "            slide_patch_dir = os.path.join(annotated_base_path, magnification, class_name, slide_name)\n",
    "            if not os.path.exists(slide_patch_dir) or len(os.listdir(slide_patch_dir)) == 0:\n",
    "                print(f\"[{mode}] Skipping {slide_name}: No patches found in annotated path.\")\n",
    "                continue\n",
    "\n",
    "            # # Fallback to regular patches if needed\n",
    "            # if not os.path.exists(slide_patch_dir) or len(os.listdir(slide_patch_dir)) == 0:\n",
    "            #     slide_patch_dir = os.path.join(fallback_base_path, magnification, class_name, slide_name)\n",
    "            #     if not os.path.exists(slide_patch_dir) or len(os.listdir(slide_patch_dir)) == 0:\n",
    "            #         print(f\"[{mode}] Skipping {slide_name}: No patches found in either location.\")\n",
    "            #         continue\n",
    "\n",
    "            # Collect patch metadata\n",
    "            for patch_file in os.listdir(slide_patch_dir):\n",
    "                if patch_file.endswith(\".npy\"):\n",
    "                    patch_path = os.path.join(slide_patch_dir, patch_file)\n",
    "                    entries.append({\n",
    "                        \"image\": patch_path,\n",
    "                        \"fold\": 1,\n",
    "                        \"mode\": mode,\n",
    "                        \"class\": class_name,\n",
    "                        \"magnification\": magnification\n",
    "                    })\n",
    "\n",
    "        # Save metadata to CSV\n",
    "        mode_metadata = pd.DataFrame(entries)\n",
    "        output_csv_path = os.path.join(output_dir, paths[\"output_csv\"])\n",
    "        mode_metadata.to_csv(output_csv_path, index=False)\n",
    "        print(f\"[{mode}] Saved {paths['output_csv']} with {len(mode_metadata)} entries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Saved train_patches.csv with 1044596 entries.\n",
      "[val] Saved val_patches.csv with 289282 entries.\n",
      "[test] Saved test_patches.csv with 203137 entries.\n"
     ]
    }
   ],
   "source": [
    "make_metadata() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "class HistopathologyDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.label_map = {\n",
    "            'B_A': 0,\n",
    "            'B_F': 1,\n",
    "            'B_PT': 2,\n",
    "            'B_TA': 3,\n",
    "            'M_DC': 4,\n",
    "            'M_LC': 5,\n",
    "            'M_MC': 6,\n",
    "            'M_PC': 7\n",
    "        }  # Example mapping of subclasses to numerical labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx]['image']\n",
    "        class_name = self.data.iloc[idx]['class']\n",
    "        subclass_name = self.data.iloc[idx]['subclass']\n",
    "        label = self.label_map[class_name + '_' + subclass_name]\n",
    "        image = plt.imread(img_path)\n",
    "        image = skimage.transform.resize(image, (224, 224))\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using breakhis dataset but only with 2 classes FA and PT \n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class HistopathologyDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.label_map = {\n",
    "            'B_F': 0,   # Fibroadenoma → Class 0\n",
    "            'B_PT': 1   # Phyllodes Tumor → Class 1\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx]['image']\n",
    "        class_name = self.data.iloc[idx]['class']\n",
    "        subclass_name = self.data.iloc[idx]['subclass']\n",
    "\n",
    "        # Map \"B_F\" -> 0, \"B_PT\" -> 1\n",
    "        label = self.label_map[class_name + '_' + subclass_name]\n",
    "\n",
    "        # Load and preprocess image\n",
    "        image = plt.imread(img_path)\n",
    "        image = skimage.transform.resize(image, (224, 224))\n",
    "        image = image.transpose((2, 0, 1))  # Convert to C x H x W for PyTorch\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated dataset class for our private dataset with numpy files\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class HistopathologyDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        \"\"\"\n",
    "        Custom PyTorch Dataset for loading histopathology patches from .npy files.\n",
    "        \n",
    "        Args:\n",
    "            csv_file (str): Path to the dataset metadata CSV file.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "        # Mapping FA -> 0, PT -> 1\n",
    "        self.label_map = {'FA': 0, 'PT': 1}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image patch\n",
    "        img_path = self.data.iloc[idx]['image']\n",
    "        image = np.load(img_path)  # Load .npy file (already in NumPy format)\n",
    "\n",
    "        # Ensure image is in (C, H, W) format for PyTorch\n",
    "        if image.shape[-1] == 3:  # Check if image is in (H, W, C) format\n",
    "            image = np.transpose(image, (2, 0, 1))  # Convert to (C, H, W)\n",
    "\n",
    "        # Resize to 224x224 if needed\n",
    "        if image.shape[1] != 224 or image.shape[2] != 224:\n",
    "            import skimage.transform\n",
    "            image = skimage.transform.resize(image, (3, 224, 224), anti_aliasing=True)\n",
    "        \n",
    "        # Normalize pixel values\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "\n",
    "        # Apply transformations if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Get label\n",
    "        class_name = self.data.iloc[idx]['class']\n",
    "        label = self.label_map[class_name]  # Convert class name to label\n",
    "\n",
    "        return image, label, img_path\n",
    "        # return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "right now, we are only using the first fold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = HistopathologyDataset('/Users/Vivian/Documents/CONCH/Folds/Fold 1/train/metadata.csv')\n",
    "# test_data = HistopathologyDataset('/Users/Vivian/Documents/CONCH/Folds/Fold 1/test/metadata.csv')\n",
    "\n",
    "# early results --> pick one fold \n",
    "# pick a fold to train and test\n",
    "\n",
    "train_data = HistopathologyDataset('/Users/Vivian/Documents/CONCH/Folds/Fold 2/train/metadata.csv')\n",
    "test_data = HistopathologyDataset('/Users/Vivian/Documents/CONCH/Folds/Fold 2/test/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataloder for me please \n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instantiating train and test set for private data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# subset of slides\n",
    "# train_dataset = HistopathologyDataset(\"metadata/fine_tuning/train_metadata.csv\")\n",
    "# test_dataset = HistopathologyDataset(\"metadata/fine_tuning/test_metadata.csv\")\n",
    "\n",
    "# testing with all slides successfully tiled\n",
    "# train_dataset = HistopathologyDataset(\"metadata\\\\fine_tuning\\\\train_patient_split_metadata.csv\")\n",
    "# test_dataset = HistopathologyDataset(\"metadata\\\\fine_tuning\\\\test_patient_split_metadata.csv\")\n",
    "\n",
    "# adding val set\n",
    "# train_dataset = HistopathologyDataset(\"metadata\\\\patient_split_annotate\\\\patch_csv\\\\train_cleaned_CL_patches.csv\")\n",
    "train_dataset = HistopathologyDataset(r\"C:\\Users\\Vivian\\Documents\\CONCH\\metadata\\patient_split_annotate\\patch_csv_2.5x\\train_patches.csv\")\n",
    "# val_dataset = HistopathologyDataset(\"metadata\\\\patient_split_annotate\\\\patch_csv\\\\val_cleaned_CL_patches.csv\")\n",
    "val_dataset = HistopathologyDataset(r\"C:\\Users\\Vivian\\Documents\\CONCH\\metadata\\patient_split_annotate\\patch_csv_2.5x\\val_patches.csv\")\n",
    "test_dataset = HistopathologyDataset(r\"C:\\Users\\Vivian\\Documents\\CONCH\\metadata\\patient_split_annotate\\patch_csv_2.5x\\test_patches.csv\")\n",
    "\n",
    "# Check dataset sample\n",
    "# sample_image, sample_label = train_dataset[0]\n",
    "# print(\"Image shape:\", sample_image.shape)\n",
    "# print(\"Label:\", sample_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataloder \n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNI - Cleanlab issues patches - run2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Setup\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Only optimize the classification head (linear layer) - for linear probing\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=2e-5) # increased learning rate\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = 'cuda'\n",
    "num_epochs = 5\n",
    "patience = 5\n",
    "\n",
    "# model_save_path = '/Users/Vivian/Documents/CONCH/_finetune_weights_CONCH/with_val_earlystop.pth'\n",
    "# csv_save_path = \"/Users/Vivian/Documents/CONCH/patch_predictions/with_val_earlystop.csv\"\n",
    "\n",
    "# Define model save path \n",
    "model_dir = \"/Users/Vivian/Documents/CONCH/_finetune_weights_ResNet50/10x\"\n",
    "# Define CSV path for saving patch predictions\n",
    "csv_dir = \"patch_predictions/10x\"\n",
    "\n",
    "# check for model save path directory \n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model_save_path = os.path.join(model_dir, \"linprob.pth\") # change model name here\n",
    "# check for csv save path directory \n",
    "os.makedirs(csv_dir, exist_ok=True)\n",
    "csv_save_path = os.path.join(csv_dir, \"ResNet50_linprob.csv\") # change prediction csv name here\n",
    "\n",
    "\n",
    "best_val_accuracy = 0\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# Mixed Precision\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Metrics tracking\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "# Store per-epoch metrics as a list of dicts\n",
    "epoch_metrics = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    correct_train, total_train = 0, 0\n",
    "    all_train_labels, all_train_preds = [], []\n",
    "\n",
    "    for images, labels, _ in tqdm.tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1) # without softmax (auroc)\n",
    "\n",
    "        # probs = torch.softmax(outputs, dim=1)[:, 1]  # probability for class 1\n",
    "        # _, predicted = torch.max(outputs, 1)    \n",
    "\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "        all_train_labels.extend(labels.cpu().numpy())\n",
    "        all_train_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # print(f\"Train Loss: {avg_train_loss:.4f} | Accuracy: {train_accuracy:.4f}\")\n",
    "    train_precision = precision_score(all_train_labels, all_train_preds, average=\"binary\")\n",
    "    train_recall = recall_score(all_train_labels, all_train_preds, average=\"binary\")\n",
    "    train_f1 = f1_score(all_train_labels, all_train_preds, average=\"binary\")\n",
    "\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Accuracy: {train_accuracy:.4f} | \"\n",
    "        f\"Precision: {train_precision:.4f} | Recall: {train_recall:.4f} | F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    correct_val, total_val = 0, 0\n",
    "    all_val_labels, all_val_preds = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in tqdm.tqdm(val_loader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "            all_val_labels.extend(labels.cpu().numpy())\n",
    "            all_val_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_accuracy = correct_val / total_val\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    val_precision = precision_score(all_val_labels, all_val_preds, average=\"binary\")\n",
    "    val_recall = recall_score(all_val_labels, all_val_preds, average=\"binary\")\n",
    "    val_f1 = f1_score(all_val_labels, all_val_preds, average=\"binary\")\n",
    "\n",
    "    print(f\"Val Loss: {avg_val_loss:.4f} | Accuracy: {val_accuracy:.4f} | \"\n",
    "          f\"Precision: {val_precision:.4f} | Recall: {val_recall:.4f} | F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "\n",
    "    # Collect metrics for this epoch\n",
    "    epoch_metrics.append({\n",
    "        \"Epoch\": epoch + 1,\n",
    "        \"Train Loss\": avg_train_loss,\n",
    "        \"Train Accuracy\": train_accuracy,\n",
    "        \"Train Precision\": train_precision,\n",
    "        \"Train Recall\": train_recall,\n",
    "        \"Train F1 Score\": train_f1,\n",
    "        \"Val Loss\": avg_val_loss,\n",
    "        \"Val Accuracy\": val_accuracy,\n",
    "        \"Val Precision\": val_precision,\n",
    "        \"Val Recall\": val_recall,\n",
    "        \"Val F1 Score\": val_f1\n",
    "    })\n",
    "\n",
    "\n",
    "    # --- Early Stopping ---\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"✅ Model saved with improved val accuracy: {val_accuracy:.4f}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No improvement for {epochs_no_improve} epoch(s)\")\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"⏹️ Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# --- Plotting ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Val Accuracy')\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Final Test Evaluation ---\n",
    "print(\"\\n🔍 Evaluating best model on the test set...\")\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.eval()\n",
    "\n",
    "total_test_loss = 0\n",
    "correct_test, total_test = 0, 0\n",
    "all_test_labels, all_test_preds = [], []\n",
    "test_predictions_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, file_paths in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "        total_test += labels.size(0)\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "        all_test_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        for i in range(labels.size(0)):\n",
    "            test_predictions_list.append([file_paths[i], predicted[i].item(), labels[i].item()])\n",
    "\n",
    "avg_test_loss = total_test_loss / len(test_loader)\n",
    "test_accuracy = correct_test / total_test\n",
    "test_precision = precision_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "test_recall = recall_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "test_f1 = f1_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "\n",
    "print(f\"\\n📊 Final Test Results:\\n\"\n",
    "      f\"Test Loss: {avg_test_loss:.4f} | Accuracy: {test_accuracy:.4f} | \"\n",
    "      f\"Precision: {test_precision:.4f} | Recall: {test_recall:.4f} | F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "# Save test predictions\n",
    "test_csv_path = csv_save_path.replace(\".csv\", \"_test.csv\")\n",
    "df_test = pd.DataFrame(test_predictions_list, columns=[\"Patch Path\", \"Predicted\", \"True Label\"])\n",
    "df_test.to_csv(test_csv_path, index=False)\n",
    "print(f\"✅ Test predictions saved to: {test_csv_path}\")\n",
    "\n",
    "# --- Append summary row ---\n",
    "summary_row = {\n",
    "    \"Epoch\": \"Best Val\",\n",
    "    \"Train Loss\": \"\",\n",
    "    \"Train Accuracy\": \"\",\n",
    "    \"Train Precision\": \"\",\n",
    "    \"Train Recall\": \"\",\n",
    "    \"Train F1 Score\": \"\",\n",
    "    \"Val Loss\": \"\",\n",
    "    \"Val Accuracy\": best_val_accuracy,\n",
    "    \"Val Precision\": \"\",\n",
    "    \"Val Recall\": \"\",\n",
    "    \"Val F1 Score\": \"\",\n",
    "    \"Test Loss\": avg_test_loss,\n",
    "    \"Test Accuracy\": test_accuracy,\n",
    "    \"Test Precision\": test_precision,\n",
    "    \"Test Recall\": test_recall,\n",
    "    \"Test F1 Score\": test_f1\n",
    "}\n",
    "epoch_metrics.append(summary_row)\n",
    "\n",
    "\n",
    "metrics_df = pd.DataFrame(epoch_metrics)\n",
    "metrics_csv_path = csv_save_path.replace(\".csv\", \"_epoch_metrics.csv\")\n",
    "metrics_df.to_csv(metrics_csv_path, index=False)\n",
    "print(f\"📊 Epoch metrics saved to: {metrics_csv_path}\")\n",
    "\n",
    "# # Save as CSV (one row)\n",
    "# summary_path = csv_save_path.replace(\".csv\", \"_metrics_summary.csv\")\n",
    "# pd.DataFrame([metrics]).to_csv(summary_path, index=False)\n",
    "# print(f\"📁 Metrics summary saved to: {summary_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Final Test Evaluation ---\n",
    "print(\"\\n🔍 Evaluating best model on the test set...\")\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.eval()\n",
    "\n",
    "total_test_loss = 0\n",
    "correct_test, total_test = 0, 0\n",
    "all_test_labels, all_test_preds = [], []\n",
    "test_predictions_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, file_paths in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "        total_test += labels.size(0)\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "        all_test_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        for i in range(labels.size(0)):\n",
    "            test_predictions_list.append([file_paths[i], predicted[i].item(), labels[i].item()])\n",
    "\n",
    "avg_test_loss = total_test_loss / len(test_loader)\n",
    "test_accuracy = correct_test / total_test\n",
    "test_precision = precision_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "test_recall = recall_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "test_f1 = f1_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "\n",
    "print(f\"\\n📊 Final Test Results:\\n\"\n",
    "      f\"Test Loss: {avg_test_loss:.4f} | Accuracy: {test_accuracy:.4f} | \"\n",
    "      f\"Precision: {test_precision:.4f} | Recall: {test_recall:.4f} | F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "# Save test predictions\n",
    "test_csv_path = csv_save_path.replace(\".csv\", \"_test.csv\")\n",
    "df_test = pd.DataFrame(test_predictions_list, columns=[\"Patch Path\", \"Predicted\", \"True Label\"])\n",
    "df_test.to_csv(test_csv_path, index=False)\n",
    "print(f\"✅ Test predictions saved to: {test_csv_path}\")\n",
    "\n",
    "# --- Append summary row ---\n",
    "summary_row = {\n",
    "    \"Epoch\": \"Best Val\",\n",
    "    \"Train Loss\": \"\",\n",
    "    \"Train Accuracy\": \"\",\n",
    "    \"Train Precision\": \"\",\n",
    "    \"Train Recall\": \"\",\n",
    "    \"Train F1 Score\": \"\",\n",
    "    \"Val Loss\": \"\",\n",
    "    \"Val Accuracy\": best_val_accuracy,\n",
    "    \"Val Precision\": \"\",\n",
    "    \"Val Recall\": \"\",\n",
    "    \"Val F1 Score\": \"\",\n",
    "    \"Test Loss\": avg_test_loss,\n",
    "    \"Test Accuracy\": test_accuracy,\n",
    "    \"Test Precision\": test_precision,\n",
    "    \"Test Recall\": test_recall,\n",
    "    \"Test F1 Score\": test_f1\n",
    "}\n",
    "epoch_metrics.append(summary_row)\n",
    "\n",
    "\n",
    "metrics_df = pd.DataFrame(epoch_metrics)\n",
    "metrics_csv_path = csv_save_path.replace(\".csv\", \"_epoch_metrics.csv\")\n",
    "metrics_df.to_csv(metrics_csv_path, index=False)\n",
    "print(f\"📊 Epoch metrics saved to: {metrics_csv_path}\")\n",
    "\n",
    "# # Save as CSV (one row)\n",
    "# summary_path = csv_save_path.replace(\".csv\", \"_metrics_summary.csv\")\n",
    "# pd.DataFrame([metrics]).to_csv(summary_path, index=False)\n",
    "# print(f\"📁 Metrics summary saved to: {summary_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using wandb.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Initialize Weights & Biases\n",
    "wandb.init(project=\"resnet50_finetuning\", name=\"linprob_2.5x\", config={\n",
    "    \"epochs\": 3,\n",
    "    \"lr\": 2e-5,\n",
    "    \"model\": \"ResNet50\",\n",
    "    \"task\": \"linear_probing\",\n",
    "    \"magnification\": \"2.5x\"\n",
    "})\n",
    "\n",
    "# Optimizer setup\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=wandb.config.lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = 'cuda'\n",
    "num_epochs = wandb.config.epochs\n",
    "patience = 5\n",
    "\n",
    "# Paths\n",
    "model_dir = \"/Users/Vivian/Documents/CONCH/_finetune_weights_ResNet50/wandb_2.5x\"\n",
    "csv_dir = \"patch_predictions/wandb_2.5x\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(csv_dir, exist_ok=True)\n",
    "\n",
    "model_save_path = os.path.join(model_dir, \"linprob.pth\")\n",
    "csv_save_path = os.path.join(csv_dir, \"ResNet50_linprob.csv\")\n",
    "\n",
    "# Mixed Precision\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Metrics tracking\n",
    "best_val_accuracy = 0\n",
    "epochs_no_improve = 0\n",
    "epoch_metrics = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    correct_train, total_train = 0, 0\n",
    "    all_train_labels, all_train_preds, all_train_probs = [], [], []\n",
    "\n",
    "    for images, labels, _ in tqdm.tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "        all_train_labels.extend(labels.cpu().numpy())\n",
    "        all_train_preds.extend(predicted.cpu().numpy())\n",
    "        all_train_probs.extend(probs.detach().cpu().numpy())\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_precision = precision_score(all_train_labels, all_train_preds)\n",
    "    train_recall = recall_score(all_train_labels, all_train_preds)\n",
    "    train_f1 = f1_score(all_train_labels, all_train_preds)\n",
    "    train_auroc = roc_auc_score(all_train_labels, all_train_probs)\n",
    "\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Acc: {train_accuracy:.4f} | \"\n",
    "          f\"Prec: {train_precision:.4f} | Rec: {train_recall:.4f} | F1: {train_f1:.4f} | AUROC: {train_auroc:.4f}\")\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    correct_val, total_val = 0, 0\n",
    "    all_val_labels, all_val_preds, all_val_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in tqdm.tqdm(val_loader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "            all_val_labels.extend(labels.cpu().numpy())\n",
    "            all_val_preds.extend(predicted.cpu().numpy())\n",
    "            all_val_probs.extend(probs.detach().cpu().numpy())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_accuracy = correct_val / total_val\n",
    "    val_precision = precision_score(all_val_labels, all_val_preds)\n",
    "    val_recall = recall_score(all_val_labels, all_val_preds)\n",
    "    val_f1 = f1_score(all_val_labels, all_val_preds)\n",
    "    val_auroc = roc_auc_score(all_val_labels, all_val_probs)\n",
    "\n",
    "    print(f\"Val Loss: {avg_val_loss:.4f} | Acc: {val_accuracy:.4f} | \"\n",
    "          f\"Prec: {val_precision:.4f} | Rec: {val_recall:.4f} | F1: {val_f1:.4f} | AUROC: {val_auroc:.4f}\")\n",
    "\n",
    "    # Log to wandb\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train/loss\": avg_train_loss,\n",
    "        \"train/accuracy\": train_accuracy,\n",
    "        \"train/precision\": train_precision,\n",
    "        \"train/recall\": train_recall,\n",
    "        \"train/f1\": train_f1,\n",
    "        \"train/auroc\": train_auroc,\n",
    "        \"val/loss\": avg_val_loss,\n",
    "        \"val/accuracy\": val_accuracy,\n",
    "        \"val/precision\": val_precision,\n",
    "        \"val/recall\": val_recall,\n",
    "        \"val/f1\": val_f1,\n",
    "        \"val/auroc\": val_auroc,\n",
    "    })\n",
    "\n",
    "    # Save best model\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(\"✅ Saved best model\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"⏹️ Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    epoch_metrics.append({\n",
    "        \"Epoch\": epoch + 1,\n",
    "        \"Train Loss\": avg_train_loss,\n",
    "        \"Train Accuracy\": train_accuracy,\n",
    "        \"Train Precision\": train_precision,\n",
    "        \"Train Recall\": train_recall,\n",
    "        \"Train F1 Score\": train_f1,\n",
    "        \"Train AUROC\": train_auroc,\n",
    "        \"Val Loss\": avg_val_loss,\n",
    "        \"Val Accuracy\": val_accuracy,\n",
    "        \"Val Precision\": val_precision,\n",
    "        \"Val Recall\": val_recall,\n",
    "        \"Val F1 Score\": val_f1,\n",
    "        \"Val AUROC\": val_auroc\n",
    "    })\n",
    "\n",
    "# Save epoch metrics to CSV\n",
    "metrics_df = pd.DataFrame(epoch_metrics)\n",
    "metrics_csv_path = csv_save_path.replace(\".csv\", \"_epoch_metrics.csv\")\n",
    "metrics_df.to_csv(metrics_csv_path, index=False)\n",
    "print(f\"📊 Saved metrics to: {metrics_csv_path}\")\n",
    "\n",
    "\n",
    "# --- Final Test Evaluation ---\n",
    "print(\"\\n🔍 Evaluating best model on the test set...\")\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.eval()\n",
    "\n",
    "total_test_loss = 0\n",
    "correct_test, total_test = 0, 0\n",
    "all_test_labels, all_test_preds = [], []\n",
    "test_predictions_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, file_paths in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_test_loss += loss.item()\n",
    "        probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "        total_test += labels.size(0)\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "        all_test_preds.extend(probs.cpu().numpy())  # For AUROC\n",
    "\n",
    "        # Append test predictions for CSV\n",
    "        for i in range(labels.size(0)):\n",
    "            test_predictions_list.append([\n",
    "                file_paths[i],\n",
    "                int(predicted[i].cpu()),\n",
    "                int(labels[i].cpu())\n",
    "            ])\n",
    "\n",
    "avg_test_loss = total_test_loss / len(test_loader)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "y_true = np.array(all_test_labels)\n",
    "y_pred = np.array([int(p > 0.5) for p in all_test_preds])  # threshold probs at 0.5\n",
    "y_probs = np.array(all_test_preds)  # for AUROC\n",
    "\n",
    "# Compute metrics\n",
    "test_accuracy = (y_pred == y_true).mean()\n",
    "test_precision = precision_score(y_true, y_pred, average=\"binary\")\n",
    "test_recall = recall_score(y_true, y_pred, average=\"binary\")\n",
    "test_f1 = f1_score(y_true, y_pred, average=\"binary\")\n",
    "test_auroc = roc_auc_score(y_true, y_probs)\n",
    "\n",
    "print(f\"\\n📊 Final Test Results:\\n\"\n",
    "      f\"Test Loss: {avg_test_loss:.4f} | Accuracy: {test_accuracy:.4f} | \"\n",
    "      f\"Precision: {test_precision:.4f} | Recall: {test_recall:.4f} | F1 Score: {test_f1:.4f} | AUROC: {test_auroc:.4f}\")\n",
    "\n",
    "wandb.log({\n",
    "    \"test/loss\": avg_test_loss,\n",
    "    \"test/accuracy\": test_accuracy,\n",
    "    \"test/precision\": test_precision,\n",
    "    \"test/recall\": test_recall,\n",
    "    \"test/f1\": test_f1,\n",
    "    \"test/auroc\": test_auroc\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Final Test Evaluation ---\n",
    "print(\"\\n🔍 Evaluating best model on the test set...\")\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.eval()\n",
    "\n",
    "total_test_loss = 0\n",
    "correct_test, total_test = 0, 0\n",
    "all_test_labels, all_test_preds = [], []\n",
    "test_predictions_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, file_paths in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_test_loss += loss.item()\n",
    "        probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "        total_test += labels.size(0)\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "        all_test_preds.extend(probs.cpu().numpy())  # For AUROC\n",
    "\n",
    "        # Append test predictions for CSV\n",
    "        for i in range(labels.size(0)):\n",
    "            test_predictions_list.append([\n",
    "                file_paths[i],\n",
    "                int(predicted[i].cpu()),\n",
    "                int(labels[i].cpu())\n",
    "            ])\n",
    "\n",
    "avg_test_loss = total_test_loss / len(test_loader)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "y_true = np.array(all_test_labels)\n",
    "y_pred = np.array([int(p > 0.5) for p in all_test_preds])  # threshold probs at 0.5\n",
    "y_probs = np.array(all_test_preds)  # for AUROC\n",
    "\n",
    "# Compute metrics\n",
    "test_accuracy = (y_pred == y_true).mean()\n",
    "test_precision = precision_score(y_true, y_pred, average=\"binary\")\n",
    "test_recall = recall_score(y_true, y_pred, average=\"binary\")\n",
    "test_f1 = f1_score(y_true, y_pred, average=\"binary\")\n",
    "test_auroc = roc_auc_score(y_true, y_probs)\n",
    "\n",
    "print(f\"\\n📊 Final Test Results:\\n\"\n",
    "      f\"Test Loss: {avg_test_loss:.4f} | Accuracy: {test_accuracy:.4f} | \"\n",
    "      f\"Precision: {test_precision:.4f} | Recall: {test_recall:.4f} | F1 Score: {test_f1:.4f} | AUROC: {test_auroc:.4f}\")\n",
    "\n",
    "wandb.log({\n",
    "    \"test/loss\": avg_test_loss,\n",
    "    \"test/accuracy\": test_accuracy,\n",
    "    \"test/precision\": test_precision,\n",
    "    \"test/recall\": test_recall,\n",
    "    \"test/f1\": test_f1,\n",
    "    \"test/auroc\": test_auroc\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
