{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from conch.open_clip_custom import create_model_from_pretrained, tokenize, get_tokenizer\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import skimage\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# show all jupyter output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('../').resolve()\n",
    "os.chdir(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONCHModelForFinetuning(nn.Module):\n",
    "    def __init__(self, num_classes=2, config={'hidden_size': 512}): # change number of classes for each dataset(8 for breast, 2 for breast)\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.model = self.make_conch()\n",
    "        # self.fc = nn.Linear(self.config['hidden_size'], num_classes) # full finetuning?\n",
    "\n",
    "        # linear probing\n",
    "        # Freeze all parameters in the backbone\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Only this linear layer will be trained\n",
    "        self.fc = nn.Linear(self.config['hidden_size'], num_classes)\n",
    "\n",
    "    def make_conch(self):\n",
    "        # Load the model from \"create_model_from_pretrained\"\n",
    "        model_cfg = 'conch_ViT-B-16'\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        # checkpoint_path = 'checkpoints/CONCH/pytorch_model.bin'\n",
    "        checkpoint_path = 'C:\\\\Users\\\\Vivian\\\\Documents\\\\CONCH\\\\checkpoints\\\\conch\\\\pytorch_model.bin' # load in checkpoint here\n",
    "        # checkpoint_path = r'C:\\Users\\Vivian\\Documents\\CONCH\\_finetune_weights\\Fold2_F_PT_model.pth' # loading breakhis finetuned model\n",
    "        model, preprocess = create_model_from_pretrained(model_cfg, checkpoint_path, device=device)\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, h = self.model.visual(x)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vivian\\Documents\\CONCH\\conch\\open_clip_custom\\factory.py:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=map_location)\n"
     ]
    }
   ],
   "source": [
    "model = CONCHModelForFinetuning().to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load breakhis (PT + FA) checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONCHModelForFinetuning(nn.Module):\n",
    "    def __init__(self, num_classes=2, config={'hidden_size': 512}, checkpoint_path=None):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.model = self.make_conch()\n",
    "        self.fc = nn.Linear(self.config['hidden_size'], num_classes)\n",
    "\n",
    "        if checkpoint_path is not None:\n",
    "            print(f\"Loading fine-tuned weights from: {checkpoint_path}\")\n",
    "            self.load_state_dict(torch.load(checkpoint_path, map_location='cuda'))\n",
    "\n",
    "    def make_conch(self):\n",
    "        # Load the base pretrained model\n",
    "        model_cfg = 'conch_ViT-B-16'\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        base_checkpoint = 'C:\\\\Users\\\\Vivian\\\\Documents\\\\CONCH\\\\checkpoints\\\\conch\\\\pytorch_model.bin'\n",
    "        model, _ = create_model_from_pretrained(model_cfg, base_checkpoint, device=device)\n",
    "        return model\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, h = self.model.visual(x)\n",
    "        return self.fc(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fine-tuned weights from: C:\\Users\\Vivian\\Documents\\CONCH\\_finetune_weights\\Fold2_F_PT_model.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_7452\\3735721263.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.load_state_dict(torch.load(checkpoint_path, map_location='cuda'))\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = r'C:\\Users\\Vivian\\Documents\\CONCH\\_finetune_weights\\Fold2_F_PT_model.pth'\n",
    "model = CONCHModelForFinetuning(num_classes=2, checkpoint_path=checkpoint_path).to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNI 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from huggingface_hub import login, hf_hub_download\n",
    "\n",
    "class UNI2ModelForFinetuning(nn.Module):\n",
    "    def __init__(self, num_classes=2): # change number of classes for each dataset\n",
    "        super().__init__()\n",
    "        # self.config = config\n",
    "        self.model = self.make_uni2()\n",
    "        # self.fc = nn.Linear(self.config['hidden_size'], num_classes)\n",
    "        self.fc = nn.Linear(1536, num_classes)  # Match Vision Transformer output\n",
    "\n",
    "    def make_uni2(self):\n",
    "        # # Load the model from \"create_model_from_pretrained\"\n",
    "        # model_cfg = 'conch_ViT-B-16'\n",
    "        # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        # # checkpoint_path = 'checkpoints/CONCH/pytorch_model.bin'\n",
    "        # checkpoint_path = 'C:\\\\Users\\\\Vivian\\\\Documents\\\\CONCH\\\\checkpoints\\\\conch\\\\pytorch_model.bin' # load in checkpoint here\n",
    "        # model, preprocess = create_model_from_pretrained(model_cfg, checkpoint_path, device=device)\n",
    "        \n",
    "        # return model\n",
    "\n",
    "        # local_dir = 'assets\\\\ckpts\\\\uni2-h'\n",
    "        local_dir = 'C:\\\\Users\\\\Vivian\\\\Documents\\\\UNI2\\\\UNI\\\\assets\\\\ckpts\\\\uni2-h' \n",
    "        os.makedirs(local_dir, exist_ok=True)  # create directory if it does not exist\n",
    "        # hf_hub_download(\"MahmoodLab/UNI2-h\", filename=\"pytorch_model.bin\", local_dir=local_dir, force_download=True)\n",
    "       \n",
    "        timm_kwargs = {\n",
    "        'model_name': 'vit_giant_patch14_224',\n",
    "        'img_size': 224, \n",
    "        'patch_size': 14, \n",
    "        'depth': 24,\n",
    "        'num_heads': 24,\n",
    "        'init_values': 1e-5, \n",
    "        'embed_dim': 1536,\n",
    "        'mlp_ratio': 2.66667*2,\n",
    "        'num_classes': 0, \n",
    "        'no_embed_class': True,\n",
    "        'mlp_layer': timm.layers.SwiGLUPacked, \n",
    "        'act_layer': torch.nn.SiLU, \n",
    "        'reg_tokens': 8, \n",
    "        'dynamic_img_size': True\n",
    "        }\n",
    "        model = timm.create_model(**timm_kwargs)\n",
    "        model.load_state_dict(torch.load(os.path.join(local_dir, \"pytorch_model.bin\"), map_location=\"cpu\"), strict=True)\n",
    "        # transform = transforms.Compose(\n",
    "        # [\n",
    "        # transforms.Resize(224),\n",
    "        # transforms.CenterCrop(224),\n",
    "        # transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        # ]\n",
    "        # )\n",
    "\n",
    "        return model \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        # out, h = self.model.visual(x)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_22300\\1031666799.py:47: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(local_dir, \"pytorch_model.bin\"), map_location=\"cpu\"), strict=True)\n"
     ]
    }
   ],
   "source": [
    "model = UNI2ModelForFinetuning().to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from huggingface_hub import login, hf_hub_download\n",
    "\n",
    "\n",
    "class UNIModelForFinetuning(nn.Module):\n",
    "    def __init__(self, num_classes=2): # change number of classes accordingly \n",
    "        ## ************ change for UNI ************\n",
    "        super().__init__()\n",
    "        # self.config = config\n",
    "        self.model = self.make_uni()\n",
    "        # self.fc = nn.Linear(self.config['hidden_size'], num_classes) # keep commented\n",
    "        # self.fc = nn.Linear(1024, num_classes)  # Match Vision Transformer output # full finetuning\n",
    "\n",
    "        #***** Freeze all backbone parameters - linear probing *****\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Add a trainable classification head\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "    \n",
    "    def make_uni(self):\n",
    "        # login()  # login with your User Access Token, found at https://huggingface.co/settings/tokens\n",
    "\n",
    "        local_dir = r\"C:\\Users\\Vivian\\Documents\\CONCH\\checkpoints\\uni\" # load in UNI model\n",
    "        os.makedirs(local_dir, exist_ok=True)  # create directory if it does not exist\n",
    "        \n",
    "        # hf_hub_download(\"MahmoodLab/UNI\", filename=\"pytorch_model.bin\", local_dir=local_dir, force_download=True)\n",
    "        model = timm.create_model(\n",
    "            \"vit_large_patch16_224\", img_size=224, patch_size=16, init_values=1e-5, num_classes=0, dynamic_img_size=True\n",
    "        )\n",
    "        model.load_state_dict(torch.load(os.path.join(local_dir, \"pytorch_model.bin\"), map_location=\"cpu\"), strict=True)\n",
    "        \n",
    "        # transform = transforms.Compose(\n",
    "        #     [\n",
    "        #         transforms.Resize(224),\n",
    "        #         transforms.ToTensor(),\n",
    "        #         transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        #     ]\n",
    "        # )\n",
    "        # model.eval()\n",
    "        return model \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        # out, h = self.model.visual(x)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_11968\\3532133654.py:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(local_dir, \"pytorch_model.bin\"), map_location=\"cpu\"), strict=True)\n"
     ]
    }
   ],
   "source": [
    "model = UNIModelForFinetuning().to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves metadata to csv for each fold and mode - use this \n",
    "# need to make metadata for new datasets\n",
    "def make_metadata(fold):\n",
    "    metadata = pd.DataFrame()\n",
    "    for mode in ['train', 'test']:\n",
    "        pathname = f'/Users/Vivian/Documents/CONCH/Folds/Fold {fold}/{mode}/'\n",
    "        images = os.listdir(pathname)\n",
    "        for image in images:\n",
    "            if not image.startswith('SOB'):\n",
    "                continue\n",
    "            label = image.split('-')[0].replace('SOB_', '')\n",
    "            class_name, subclass_name = label.split('_')\n",
    "            #metadata = metadata.append({'image': pathname+image, 'fold': fold, 'mode': mode, 'class': class_name, 'subclass': subclass_name}, ignore_index=True)\n",
    "            metadata = pd.concat([metadata, pd.DataFrame({'image': pathname+image, 'fold': fold, 'mode': mode, 'class': class_name, 'subclass': subclass_name}, index=[0])], ignore_index=True)\n",
    "        metadata.to_csv(f'/Users/Vivian/Documents/CONCH/Folds/Fold {fold}/{mode}/metadata.csv', index=False)\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making metadata for our private dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def make_metadata():\n",
    "    metadata = pd.DataFrame()\n",
    "    \n",
    "    # # Define paths\n",
    "    # base_path = \"patches\"  # Root where patches are stored\n",
    "    # metadata_dir = \"metadata\"  # Directory containing train/test CSVs\n",
    "    # output_dir = \"metadata/fine_tuning\"  # Where metadata CSVs will be saved\n",
    "    # os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # ***********Define paths for only test set\n",
    "    base_path = \"patches_annotated\"  # Root where patches are stored\n",
    "    metadata_dir = \"metadata\"  # Directory containing train/test CSVs\n",
    "    output_dir = \"metadata/fine_tuning\"  # Where metadata CSVs will be saved\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # ************\n",
    "\n",
    "    # Load train/test slide selections\n",
    "    # train_slides = pd.read_csv(os.path.join(metadata_dir, \"train_patient_split.csv\"))\n",
    "    test_slides = pd.read_csv(os.path.join(metadata_dir, \"test_ann_series8.csv\"))\n",
    "\n",
    "    # train_slides = pd.read_csv(os.path.join(metadata_dir, \"train_all_slides.csv\"))\n",
    "    # test_slides = pd.read_csv(os.path.join(metadata_dir, \"test_all_slides.csv\"))\n",
    "\n",
    "\n",
    "    # Process both train and test sets\n",
    "    # for mode, slides_df in zip([\"train\", \"test\"], [train_slides, test_slides]):\n",
    "    for mode, slides_df in zip([\"test\"], [test_slides]): # only creating test set\n",
    "\n",
    "        entries = []\n",
    "        \n",
    "        for _, row in slides_df.iterrows():\n",
    "            slide_name = row[\"Filename\"]\n",
    "            class_name = row[\"Class\"]\n",
    "            magnification = f\"{row['Magnification']}x\"\n",
    "\n",
    "            # Define the path where patches are stored for this slide\n",
    "            slide_patch_dir = os.path.join(base_path, magnification, class_name, slide_name)\n",
    "\n",
    "            # Ensure slide directory exists and has patches\n",
    "            if not os.path.exists(slide_patch_dir) or len(os.listdir(slide_patch_dir)) == 0:\n",
    "                print(f\"Skipping {slide_name}: No patches found.\")\n",
    "                continue\n",
    "            \n",
    "            # Add all patches in the slide directory to the metadata\n",
    "            for patch_file in os.listdir(slide_patch_dir):\n",
    "                if patch_file.endswith(\".npy\"):  # Ensure we're only adding valid patch files\n",
    "                    patch_path = os.path.join(slide_patch_dir, patch_file)\n",
    "                    entries.append({\n",
    "                        \"image\": patch_path,\n",
    "                        \"fold\": 1,  # Since you're using only one fold\n",
    "                        \"mode\": mode,\n",
    "                        \"class\": class_name,\n",
    "                        \"magnification\": magnification\n",
    "                    })\n",
    "\n",
    "        # Convert list to DataFrame\n",
    "        mode_metadata = pd.DataFrame(entries)\n",
    "\n",
    "        # output_csv = \n",
    "\n",
    "        # Save metadata CSV for the mode\n",
    "        mode_metadata.to_csv(os.path.join(output_dir, f\"{mode}_ann_series8_2.csv\"), index=False) # manually change metadata file name here\n",
    "\n",
    "        print(f\"Saved {mode}_ann_series8_2.csv with {len(mode_metadata)} entries.\")\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making metadata for our private dataset - train, val, test\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def make_metadata():\n",
    "    # === CONFIGURATION ===\n",
    "    annotated_base_path = \"patches_annotated\"\n",
    "    fallback_base_path = \"patches\"\n",
    "    metadata_dir = \"metadata/patient_split_annotate/slide_csv\"\n",
    "    output_dir = \"metadata/patient_split_annotate/patch_csv\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Define your CSVs and the filenames for outputs\n",
    "    slide_sets = {\n",
    "        \"train\": {\n",
    "            \"input_csv\": os.path.join(metadata_dir, \"train_split.csv\"),\n",
    "            \"output_csv\": \"train_patches.csv\"\n",
    "        },\n",
    "        \"val\": {\n",
    "            \"input_csv\": os.path.join(metadata_dir, \"val_split.csv\"),\n",
    "            \"output_csv\": \"val_patches.csv\"\n",
    "        },\n",
    "        \"test\": {\n",
    "            \"input_csv\": os.path.join(metadata_dir, \"test_split.csv\"),\n",
    "            \"output_csv\": \"test_patches.csv\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # === PROCESS EACH SET ===\n",
    "    for mode, paths in slide_sets.items():\n",
    "        slides_df = pd.read_csv(paths[\"input_csv\"])\n",
    "        entries = []\n",
    "\n",
    "        for _, row in slides_df.iterrows():\n",
    "            slide_name = row[\"Filename\"]\n",
    "            class_name = row[\"Class\"]\n",
    "            magnification = f\"{row['Magnification']}x\"\n",
    "\n",
    "            # Try annotated path first\n",
    "            slide_patch_dir = os.path.join(annotated_base_path, magnification, class_name, slide_name)\n",
    "\n",
    "            # Fallback to regular patches if needed\n",
    "            if not os.path.exists(slide_patch_dir) or len(os.listdir(slide_patch_dir)) == 0:\n",
    "                slide_patch_dir = os.path.join(fallback_base_path, magnification, class_name, slide_name)\n",
    "                if not os.path.exists(slide_patch_dir) or len(os.listdir(slide_patch_dir)) == 0:\n",
    "                    print(f\"[{mode}] Skipping {slide_name}: No patches found in either location.\")\n",
    "                    continue\n",
    "\n",
    "            # Collect patch metadata\n",
    "            for patch_file in os.listdir(slide_patch_dir):\n",
    "                if patch_file.endswith(\".npy\"):\n",
    "                    patch_path = os.path.join(slide_patch_dir, patch_file)\n",
    "                    entries.append({\n",
    "                        \"image\": patch_path,\n",
    "                        \"fold\": 1,\n",
    "                        \"mode\": mode,\n",
    "                        \"class\": class_name,\n",
    "                        \"magnification\": magnification\n",
    "                    })\n",
    "\n",
    "        # Save metadata to CSV\n",
    "        mode_metadata = pd.DataFrame(entries)\n",
    "        output_csv_path = os.path.join(output_dir, paths[\"output_csv\"])\n",
    "        mode_metadata.to_csv(output_csv_path, index=False)\n",
    "        print(f\"[{mode}] Saved {paths['output_csv']} with {len(mode_metadata)} entries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Saved train_patches.csv with 380280 entries.\n",
      "[val] Saved val_patches.csv with 105808 entries.\n",
      "[test] Saved test_patches.csv with 105902 entries.\n"
     ]
    }
   ],
   "source": [
    "make_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "class HistopathologyDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.label_map = {\n",
    "            'B_A': 0,\n",
    "            'B_F': 1,\n",
    "            'B_PT': 2,\n",
    "            'B_TA': 3,\n",
    "            'M_DC': 4,\n",
    "            'M_LC': 5,\n",
    "            'M_MC': 6,\n",
    "            'M_PC': 7\n",
    "        }  # Example mapping of subclasses to numerical labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx]['image']\n",
    "        class_name = self.data.iloc[idx]['class']\n",
    "        subclass_name = self.data.iloc[idx]['subclass']\n",
    "        label = self.label_map[class_name + '_' + subclass_name]\n",
    "        image = plt.imread(img_path)\n",
    "        image = skimage.transform.resize(image, (224, 224))\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using breakhis dataset but only with 2 classes FA and PT \n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class HistopathologyDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.label_map = {\n",
    "            'B_F': 0,   # Fibroadenoma → Class 0\n",
    "            'B_PT': 1   # Phyllodes Tumor → Class 1\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx]['image']\n",
    "        class_name = self.data.iloc[idx]['class']\n",
    "        subclass_name = self.data.iloc[idx]['subclass']\n",
    "\n",
    "        # Map \"B_F\" -> 0, \"B_PT\" -> 1\n",
    "        label = self.label_map[class_name + '_' + subclass_name]\n",
    "\n",
    "        # Load and preprocess image\n",
    "        image = plt.imread(img_path)\n",
    "        image = skimage.transform.resize(image, (224, 224))\n",
    "        image = image.transpose((2, 0, 1))  # Convert to C x H x W for PyTorch\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated dataset class for our private dataset with png images\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "\n",
    "class HistopathologyDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir=None, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (str): Path to the metadata CSV file.\n",
    "            root_dir (str, optional): Root directory to prepend to image paths.\n",
    "            transform (callable, optional): Transformations to apply to images.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # Mapping classes to numerical labels (modify based on your dataset)\n",
    "        self.label_map = {\n",
    "            'FA': 0,\n",
    "            'PT': 1,  # Add additional classes if needed\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get image path\n",
    "        img_path = self.data.iloc[idx]['image']\n",
    "        if self.root_dir:\n",
    "            img_path = os.path.join(self.root_dir, img_path)\n",
    "\n",
    "        # Load image using PIL (handles grayscale and RGB)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Get class label\n",
    "        class_name = self.data.iloc[idx]['class']\n",
    "        label = self.label_map.get(class_name, -1)  # -1 for unknown classes\n",
    "    \n",
    "        # Apply transformations    \n",
    "        image = plt.imread(img_path)\n",
    "        image = skimage.transform.resize(image, (224, 224))\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated dataset class for our private dataset with numpy files\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class HistopathologyDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        \"\"\"\n",
    "        Custom PyTorch Dataset for loading histopathology patches from .npy files.\n",
    "        \n",
    "        Args:\n",
    "            csv_file (str): Path to the dataset metadata CSV file.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "        # Mapping FA -> 0, PT -> 1\n",
    "        self.label_map = {'FA': 0, 'PT': 1}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image patch\n",
    "        img_path = self.data.iloc[idx]['image']\n",
    "        image = np.load(img_path)  # Load .npy file (already in NumPy format)\n",
    "\n",
    "        # Ensure image is in (C, H, W) format for PyTorch\n",
    "        if image.shape[-1] == 3:  # Check if image is in (H, W, C) format\n",
    "            image = np.transpose(image, (2, 0, 1))  # Convert to (C, H, W)\n",
    "\n",
    "        # Resize to 224x224 if needed\n",
    "        if image.shape[1] != 224 or image.shape[2] != 224:\n",
    "            import skimage.transform\n",
    "            image = skimage.transform.resize(image, (3, 224, 224), anti_aliasing=True)\n",
    "        \n",
    "        # Normalize pixel values\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "\n",
    "        # Apply transformations if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Get label\n",
    "        class_name = self.data.iloc[idx]['class']\n",
    "        label = self.label_map[class_name]  # Convert class name to label\n",
    "\n",
    "        return image, label, img_path\n",
    "        # return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "right now, we are only using the first fold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = HistopathologyDataset('/Users/Vivian/Documents/CONCH/Folds/Fold 1/train/metadata.csv')\n",
    "# test_data = HistopathologyDataset('/Users/Vivian/Documents/CONCH/Folds/Fold 1/test/metadata.csv')\n",
    "\n",
    "# early results --> pick one fold \n",
    "# pick a fold to train and test\n",
    "\n",
    "train_data = HistopathologyDataset('/Users/Vivian/Documents/CONCH/Folds/Fold 2/train/metadata.csv')\n",
    "test_data = HistopathologyDataset('/Users/Vivian/Documents/CONCH/Folds/Fold 2/test/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataloder for me please \n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train and test using breakhis FA and PT classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = HistopathologyDataset('C:\\\\Users\\\\Vivian\\\\Documents\\\\CONCH\\\\Folds\\\\Fold 2\\\\train\\\\F_PT_metadata.csv')\n",
    "test_data = HistopathologyDataset('C:\\\\Users\\\\Vivian\\\\Documents\\\\CONCH\\\\Folds\\\\Fold 2\\\\test\\\\F_PT_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataloder for me please \n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instantiating train and test set for private data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# subset of slides\n",
    "# train_dataset = HistopathologyDataset(\"metadata/fine_tuning/train_metadata.csv\")\n",
    "# test_dataset = HistopathologyDataset(\"metadata/fine_tuning/test_metadata.csv\")\n",
    "\n",
    "# testing with all slides successfully tiled\n",
    "# train_dataset = HistopathologyDataset(\"metadata\\\\fine_tuning\\\\train_patient_split_metadata.csv\")\n",
    "# test_dataset = HistopathologyDataset(\"metadata\\\\fine_tuning\\\\test_patient_split_metadata.csv\")\n",
    "\n",
    "# adding val set\n",
    "train_dataset = HistopathologyDataset(\"metadata\\\\patient_split_annotate\\\\patch_csv\\\\train_patches.csv\")\n",
    "val_dataset = HistopathologyDataset(\"metadata\\\\patient_split_annotate\\\\patch_csv\\\\val_patches.csv\")\n",
    "test_dataset = HistopathologyDataset(\"metadata\\\\patient_split_annotate\\\\patch_csv\\\\test_patches.csv\")\n",
    "\n",
    "# Check dataset sample\n",
    "# sample_image, sample_label = train_dataset[0]\n",
    "# print(\"Image shape:\", sample_image.shape)\n",
    "# print(\"Label:\", sample_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataloder \n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCH - printing patch predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Define loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Define number of epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Define model save path\n",
    "model_save_path = '/Users/Vivian/Documents/CONCH/_finetune_weights_breast/all_slides_model3.pth'\n",
    "\n",
    "# Define CSV path for saving predictions\n",
    "csv_save_path = \"/Users/Vivian/Documents/CONCH/patch_predictions.csv\"\n",
    "\n",
    "# Best accuracy tracker\n",
    "best_accuracy = 0\n",
    "\n",
    "# Device setup\n",
    "device = 'cuda'\n",
    "\n",
    "# Start training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Starting epoch {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    num_train_batches = 0\n",
    "\n",
    "    # Training phase\n",
    "    for batch in tqdm.tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels, img_path = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        num_train_batches += 1\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_train_batches\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Training Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "    # Evaluation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_test_loss = 0\n",
    "        num_test_batches = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "        predictions_list = []  # List to store results for CSV\n",
    "\n",
    "        for batch in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "            images, labels, file_paths = batch  # Unpack three values\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)  # Compute test loss\n",
    "            total_test_loss += loss.item()\n",
    "            num_test_batches += 1\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "            # Store predictions for CSV\n",
    "            for i in range(labels.size(0)):\n",
    "                predictions_list.append([file_paths[i], predicted[i].item(), labels[i].item()])\n",
    "\n",
    "        # Compute classification metrics\n",
    "        accuracy = correct / total\n",
    "        precision = precision_score(all_labels, all_predictions, average=\"binary\")  # Use 'binary' for 2 classes\n",
    "        recall = recall_score(all_labels, all_predictions, average=\"binary\")\n",
    "        f1 = f1_score(all_labels, all_predictions, average=\"binary\")\n",
    "        avg_test_loss = total_test_loss / num_test_batches  # Compute average test loss\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Test Loss: {avg_test_loss:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "        # Save predictions to CSV\n",
    "        df_predictions = pd.DataFrame(predictions_list, columns=[\"Patch Path\", \"Predicted\", \"True Label\"])\n",
    "        df_predictions.to_csv(csv_save_path, index=False)\n",
    "\n",
    "        # Save model if it has the best accuracy\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Model saved with accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCH - printing train metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CONCHModelForFinetuning(\n",
       "  (model): CoCa(\n",
       "    (text): TextTransformer(\n",
       "      (token_embedding): Embedding(32007, 768)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-11): 12 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_1): Identity()\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (visual): VisualModel(\n",
       "      (trunk): VisionTransformer(\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          (norm): Identity()\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (patch_drop): Identity()\n",
       "        (norm_pre): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (2): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (3): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (4): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (5): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (6): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (7): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (8): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (9): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (10): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (11): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (fc_norm): Identity()\n",
       "        (head_drop): Dropout(p=0.0, inplace=False)\n",
       "        (head): Identity()\n",
       "      )\n",
       "      (attn_pool_contrast): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_contrast): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (head): Sequential()\n",
       "      (attn_pool_caption): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_caption): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (text_decoder): MultimodalTransformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (cross_attn): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_1_kv): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 51837/51837 [53:09<00:00, 16.25it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Train Loss: 0.6671\n",
      "Epoch 1/5 - Train Accuracy: 0.5808, Precision: 0.5805, Recall: 0.8118, F1 Score: 0.6769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CONCHModelForFinetuning(\n",
       "  (model): CoCa(\n",
       "    (text): TextTransformer(\n",
       "      (token_embedding): Embedding(32007, 768)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-11): 12 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_1): Identity()\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (visual): VisualModel(\n",
       "      (trunk): VisionTransformer(\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          (norm): Identity()\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (patch_drop): Identity()\n",
       "        (norm_pre): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (2): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (3): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (4): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (5): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (6): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (7): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (8): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (9): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (10): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (11): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (fc_norm): Identity()\n",
       "        (head_drop): Dropout(p=0.0, inplace=False)\n",
       "        (head): Identity()\n",
       "      )\n",
       "      (attn_pool_contrast): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_contrast): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (head): Sequential()\n",
       "      (attn_pool_caption): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_caption): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (text_decoder): MultimodalTransformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (cross_attn): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_1_kv): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 14199/14199 [14:41<00:00, 16.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Test Loss: 0.7049\n",
      "Epoch 1/5 - Test Accuracy: 0.4920, Precision: 0.4601, Recall: 0.6596, F1 Score: 0.5421\n",
      "Model saved with accuracy: 0.4920\n",
      "Patch predictions saved to: /Users/Vivian/Documents/CONCH/patch_predictions/patient_split_CONCH70_linearprob.csv\n",
      "Starting epoch 2/5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CONCHModelForFinetuning(\n",
       "  (model): CoCa(\n",
       "    (text): TextTransformer(\n",
       "      (token_embedding): Embedding(32007, 768)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-11): 12 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_1): Identity()\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (visual): VisualModel(\n",
       "      (trunk): VisionTransformer(\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          (norm): Identity()\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (patch_drop): Identity()\n",
       "        (norm_pre): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (2): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (3): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (4): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (5): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (6): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (7): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (8): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (9): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (10): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (11): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (fc_norm): Identity()\n",
       "        (head_drop): Dropout(p=0.0, inplace=False)\n",
       "        (head): Identity()\n",
       "      )\n",
       "      (attn_pool_contrast): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_contrast): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (head): Sequential()\n",
       "      (attn_pool_caption): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_caption): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (text_decoder): MultimodalTransformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (cross_attn): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_1_kv): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   9%|▉         | 4813/51837 [05:02<49:11, 15.93it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     48\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 49\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     51\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[3], line 28\u001b[0m, in \u001b[0;36mCONCHModelForFinetuning.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 28\u001b[0m     out, h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisual\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(out)\n",
      "File \u001b[1;32mc:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Vivian\\Documents\\CONCH\\conch\\open_clip_custom\\vision_tower.py:133\u001b[0m, in \u001b[0;36mVisualModel.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 133\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrunk(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrunk_kwargs)\n\u001b[0;32m    134\u001b[0m     tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_attentional_pool_contrast:\n",
      "File \u001b[1;32mc:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\timm\\models\\vision_transformer.py:803\u001b[0m, in \u001b[0;36mVisionTransformer.forward_features\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 803\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos_embed(x)\n\u001b[0;32m    805\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_drop(x)\n",
      "File \u001b[1;32mc:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\timm\\layers\\patch_embed.py:131\u001b[0m, in \u001b[0;36mPatchEmbed.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    129\u001b[0m     pad_w \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m W \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_size[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    130\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpad(x, (\u001b[38;5;241m0\u001b[39m, pad_w, \u001b[38;5;241m0\u001b[39m, pad_h))\n\u001b[1;32m--> 131\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflatten:\n\u001b[0;32m    133\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# NCHW -> NLC\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Define optimizer\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Only optimize the classification head (linear layer) - for linear probing\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-5)\n",
    "\n",
    "# Define loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Define number of epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Define model save path\n",
    "model_save_path = '/Users/Vivian/Documents/CONCH/_finetune_weights_CONCH/patient_split_70_linearprob.pth'\n",
    "\n",
    "# Define CSV path for saving predictions\n",
    "csv_save_path = \"/Users/Vivian/Documents/CONCH/patch_predictions/patient_split_CONCH70_linearprob.csv\"\n",
    "\n",
    "# Best accuracy tracker\n",
    "best_accuracy = 0\n",
    "\n",
    "# Device setup\n",
    "device = 'cuda'\n",
    "\n",
    "# Start training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Starting epoch {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    num_train_batches = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    all_train_labels = []\n",
    "    all_train_predictions = []\n",
    "\n",
    "    # Training phase\n",
    "    for batch in tqdm.tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels, img_path = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        num_train_batches += 1\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "        all_train_labels.extend(labels.cpu().numpy())\n",
    "        all_train_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_train_batches\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_precision = precision_score(all_train_labels, all_train_predictions, average=\"binary\")\n",
    "    train_recall = recall_score(all_train_labels, all_train_predictions, average=\"binary\")\n",
    "    train_f1 = f1_score(all_train_labels, all_train_predictions, average=\"binary\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Accuracy: {train_accuracy:.4f}, \"\n",
    "          f\"Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "    # Evaluation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_test_loss = 0\n",
    "        num_test_batches = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "        predictions_list = []  # List to store results for CSV\n",
    "\n",
    "        for batch in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "            images, labels, file_paths = batch\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_test_loss += loss.item()\n",
    "            num_test_batches += 1\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "            # Store predictions for CSV\n",
    "            for i in range(labels.size(0)):\n",
    "                predictions_list.append([file_paths[i], predicted[i].item(), labels[i].item()])\n",
    "\n",
    "        accuracy = correct / total\n",
    "        precision = precision_score(all_labels, all_predictions, average=\"binary\")\n",
    "        recall = recall_score(all_labels, all_predictions, average=\"binary\")\n",
    "        f1 = f1_score(all_labels, all_predictions, average=\"binary\")\n",
    "        avg_test_loss = total_test_loss / num_test_batches\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Test Loss: {avg_test_loss:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Test Accuracy: {accuracy:.4f}, \"\n",
    "              f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "        # Save predictions and model if test accuracy improves\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Model saved with accuracy: {accuracy:.4f}\")\n",
    "\n",
    "            df_predictions = pd.DataFrame(predictions_list, columns=[\"Patch Path\", \"Predicted\", \"True Label\"])\n",
    "            df_predictions.to_csv(csv_save_path, index=False)\n",
    "            print(f\"Patch predictions saved to: {csv_save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCH val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_29236\\2614587232.py:30: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CONCHModelForFinetuning(\n",
       "  (model): CoCa(\n",
       "    (text): TextTransformer(\n",
       "      (token_embedding): Embedding(32007, 768)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-11): 12 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_1): Identity()\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (visual): VisualModel(\n",
       "      (trunk): VisionTransformer(\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          (norm): Identity()\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (patch_drop): Identity()\n",
       "        (norm_pre): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (2): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (3): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (4): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (5): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (6): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (7): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (8): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (9): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (10): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (11): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (fc_norm): Identity()\n",
       "        (head_drop): Dropout(p=0.0, inplace=False)\n",
       "        (head): Identity()\n",
       "      )\n",
       "      (attn_pool_contrast): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_contrast): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (head): Sequential()\n",
       "      (attn_pool_caption): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_caption): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (text_decoder): MultimodalTransformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (cross_attn): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_1_kv): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/47535 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_29236\\2614587232.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 47535/47535 [46:05<00:00, 17.19it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6724 | Accuracy: 0.5790 | Precision: 0.5818 | Recall: 0.8575 | F1 Score: 0.6932\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CONCHModelForFinetuning(\n",
       "  (model): CoCa(\n",
       "    (text): TextTransformer(\n",
       "      (token_embedding): Embedding(32007, 768)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-11): 12 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_1): Identity()\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (visual): VisualModel(\n",
       "      (trunk): VisionTransformer(\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          (norm): Identity()\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (patch_drop): Identity()\n",
       "        (norm_pre): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (2): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (3): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (4): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (5): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (6): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (7): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (8): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (9): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (10): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (11): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (fc_norm): Identity()\n",
       "        (head_drop): Dropout(p=0.0, inplace=False)\n",
       "        (head): Identity()\n",
       "      )\n",
       "      (attn_pool_contrast): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_contrast): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (head): Sequential()\n",
       "      (attn_pool_caption): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_caption): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (text_decoder): MultimodalTransformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (cross_attn): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_1_kv): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/13226 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_29236\\2614587232.py:87: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 13226/13226 [12:42<00:00, 17.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6620 | Accuracy: 0.5639 | Precision: 0.5613 | Recall: 0.8325 | F1 Score: 0.6705\n",
      "✅ Model saved with improved val accuracy: 0.5639\n",
      "\n",
      "Epoch 2/7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CONCHModelForFinetuning(\n",
       "  (model): CoCa(\n",
       "    (text): TextTransformer(\n",
       "      (token_embedding): Embedding(32007, 768)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-11): 12 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_1): Identity()\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (visual): VisualModel(\n",
       "      (trunk): VisionTransformer(\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          (norm): Identity()\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (patch_drop): Identity()\n",
       "        (norm_pre): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (2): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (3): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (4): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (5): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (6): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (7): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (8): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (9): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (10): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (11): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (fc_norm): Identity()\n",
       "        (head_drop): Dropout(p=0.0, inplace=False)\n",
       "        (head): Identity()\n",
       "      )\n",
       "      (attn_pool_contrast): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_contrast): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (head): Sequential()\n",
       "      (attn_pool_caption): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_caption): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (text_decoder): MultimodalTransformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (cross_attn): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_1_kv): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/47535 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_29236\\2614587232.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 47535/47535 [45:56<00:00, 17.24it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6704 | Accuracy: 0.5771 | Precision: 0.5854 | Recall: 0.8153 | F1 Score: 0.6815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CONCHModelForFinetuning(\n",
       "  (model): CoCa(\n",
       "    (text): TextTransformer(\n",
       "      (token_embedding): Embedding(32007, 768)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-11): 12 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_1): Identity()\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (visual): VisualModel(\n",
       "      (trunk): VisionTransformer(\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          (norm): Identity()\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (patch_drop): Identity()\n",
       "        (norm_pre): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (2): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (3): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (4): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (5): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (6): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (7): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (8): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (9): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (10): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (11): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (fc_norm): Identity()\n",
       "        (head_drop): Dropout(p=0.0, inplace=False)\n",
       "        (head): Identity()\n",
       "      )\n",
       "      (attn_pool_contrast): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_contrast): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (head): Sequential()\n",
       "      (attn_pool_caption): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_caption): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (text_decoder): MultimodalTransformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (cross_attn): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_1_kv): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/13226 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_29236\\2614587232.py:87: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 13226/13226 [12:39<00:00, 17.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6616 | Accuracy: 0.5644 | Precision: 0.5620 | Recall: 0.8284 | F1 Score: 0.6697\n",
      "✅ Model saved with improved val accuracy: 0.5644\n",
      "\n",
      "Epoch 3/7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CONCHModelForFinetuning(\n",
       "  (model): CoCa(\n",
       "    (text): TextTransformer(\n",
       "      (token_embedding): Embedding(32007, 768)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-11): 12 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_1): Identity()\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (visual): VisualModel(\n",
       "      (trunk): VisionTransformer(\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          (norm): Identity()\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (patch_drop): Identity()\n",
       "        (norm_pre): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (2): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (3): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (4): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (5): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (6): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (7): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (8): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (9): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (10): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (11): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (fc_norm): Identity()\n",
       "        (head_drop): Dropout(p=0.0, inplace=False)\n",
       "        (head): Identity()\n",
       "      )\n",
       "      (attn_pool_contrast): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_contrast): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (head): Sequential()\n",
       "      (attn_pool_caption): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_caption): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (text_decoder): MultimodalTransformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (cross_attn): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_1_kv): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/47535 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_29236\\2614587232.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 47535/47535 [45:58<00:00, 17.23it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6704 | Accuracy: 0.5763 | Precision: 0.5849 | Recall: 0.8148 | F1 Score: 0.6809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CONCHModelForFinetuning(\n",
       "  (model): CoCa(\n",
       "    (text): TextTransformer(\n",
       "      (token_embedding): Embedding(32007, 768)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-11): 12 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_1): Identity()\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (visual): VisualModel(\n",
       "      (trunk): VisionTransformer(\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          (norm): Identity()\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (patch_drop): Identity()\n",
       "        (norm_pre): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (2): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (3): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (4): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (5): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (6): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (7): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (8): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (9): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (10): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (11): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (fc_norm): Identity()\n",
       "        (head_drop): Dropout(p=0.0, inplace=False)\n",
       "        (head): Identity()\n",
       "      )\n",
       "      (attn_pool_contrast): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_contrast): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (head): Sequential()\n",
       "      (attn_pool_caption): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_caption): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (text_decoder): MultimodalTransformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (cross_attn): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_1_kv): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/13226 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_29236\\2614587232.py:87: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 13226/13226 [12:41<00:00, 17.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6605 | Accuracy: 0.5706 | Precision: 0.5685 | Recall: 0.8067 | F1 Score: 0.6670\n",
      "✅ Model saved with improved val accuracy: 0.5706\n",
      "\n",
      "Epoch 4/7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CONCHModelForFinetuning(\n",
       "  (model): CoCa(\n",
       "    (text): TextTransformer(\n",
       "      (token_embedding): Embedding(32007, 768)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-11): 12 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_1): Identity()\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (visual): VisualModel(\n",
       "      (trunk): VisionTransformer(\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          (norm): Identity()\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (patch_drop): Identity()\n",
       "        (norm_pre): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (2): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (3): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (4): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (5): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (6): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (7): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (8): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (9): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (10): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (11): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (fc_norm): Identity()\n",
       "        (head_drop): Dropout(p=0.0, inplace=False)\n",
       "        (head): Identity()\n",
       "      )\n",
       "      (attn_pool_contrast): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_contrast): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (head): Sequential()\n",
       "      (attn_pool_caption): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_caption): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (text_decoder): MultimodalTransformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (cross_attn): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_1_kv): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/47535 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_29236\\2614587232.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 47535/47535 [46:04<00:00, 17.19it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6703 | Accuracy: 0.5767 | Precision: 0.5851 | Recall: 0.8147 | F1 Score: 0.6811\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CONCHModelForFinetuning(\n",
       "  (model): CoCa(\n",
       "    (text): TextTransformer(\n",
       "      (token_embedding): Embedding(32007, 768)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-11): 12 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_1): Identity()\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (visual): VisualModel(\n",
       "      (trunk): VisionTransformer(\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          (norm): Identity()\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (patch_drop): Identity()\n",
       "        (norm_pre): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (2): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (3): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (4): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (5): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (6): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (7): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (8): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (9): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (10): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (11): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (fc_norm): Identity()\n",
       "        (head_drop): Dropout(p=0.0, inplace=False)\n",
       "        (head): Identity()\n",
       "      )\n",
       "      (attn_pool_contrast): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_contrast): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (head): Sequential()\n",
       "      (attn_pool_caption): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_caption): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (text_decoder): MultimodalTransformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (cross_attn): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_1_kv): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/13226 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_29236\\2614587232.py:87: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 13226/13226 [12:55<00:00, 17.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6610 | Accuracy: 0.5668 | Precision: 0.5646 | Recall: 0.8184 | F1 Score: 0.6682\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 5/7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CONCHModelForFinetuning(\n",
       "  (model): CoCa(\n",
       "    (text): TextTransformer(\n",
       "      (token_embedding): Embedding(32007, 768)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-11): 12 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_1): Identity()\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (visual): VisualModel(\n",
       "      (trunk): VisionTransformer(\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          (norm): Identity()\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (patch_drop): Identity()\n",
       "        (norm_pre): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (2): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (3): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (4): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (5): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (6): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (7): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (8): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (9): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (10): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (11): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (fc_norm): Identity()\n",
       "        (head_drop): Dropout(p=0.0, inplace=False)\n",
       "        (head): Identity()\n",
       "      )\n",
       "      (attn_pool_contrast): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_contrast): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (head): Sequential()\n",
       "      (attn_pool_caption): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_caption): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (text_decoder): MultimodalTransformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (cross_attn): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_1_kv): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/47535 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_29236\\2614587232.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 47535/47535 [47:07<00:00, 16.81it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6701 | Accuracy: 0.5770 | Precision: 0.5854 | Recall: 0.8145 | F1 Score: 0.6812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CONCHModelForFinetuning(\n",
       "  (model): CoCa(\n",
       "    (text): TextTransformer(\n",
       "      (token_embedding): Embedding(32007, 768)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-11): 12 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_1): Identity()\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (visual): VisualModel(\n",
       "      (trunk): VisionTransformer(\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          (norm): Identity()\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (patch_drop): Identity()\n",
       "        (norm_pre): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (2): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (3): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (4): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (5): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (6): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (7): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (8): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (9): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (10): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (11): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (fc_norm): Identity()\n",
       "        (head_drop): Dropout(p=0.0, inplace=False)\n",
       "        (head): Identity()\n",
       "      )\n",
       "      (attn_pool_contrast): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_contrast): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (head): Sequential()\n",
       "      (attn_pool_caption): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_caption): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (text_decoder): MultimodalTransformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (cross_attn): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_1_kv): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/13226 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_29236\\2614587232.py:87: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 13226/13226 [12:42<00:00, 17.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6633 | Accuracy: 0.5568 | Precision: 0.5547 | Recall: 0.8547 | F1 Score: 0.6728\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 6/7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CONCHModelForFinetuning(\n",
       "  (model): CoCa(\n",
       "    (text): TextTransformer(\n",
       "      (token_embedding): Embedding(32007, 768)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-11): 12 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_1): Identity()\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (visual): VisualModel(\n",
       "      (trunk): VisionTransformer(\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          (norm): Identity()\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (patch_drop): Identity()\n",
       "        (norm_pre): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (2): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (3): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (4): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (5): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (6): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (7): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (8): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (9): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (10): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (11): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (fc_norm): Identity()\n",
       "        (head_drop): Dropout(p=0.0, inplace=False)\n",
       "        (head): Identity()\n",
       "      )\n",
       "      (attn_pool_contrast): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_contrast): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (head): Sequential()\n",
       "      (attn_pool_caption): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_caption): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (text_decoder): MultimodalTransformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (cross_attn): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_1_kv): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/47535 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_29236\\2614587232.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 47535/47535 [45:58<00:00, 17.23it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6701 | Accuracy: 0.5770 | Precision: 0.5852 | Recall: 0.8158 | F1 Score: 0.6815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CONCHModelForFinetuning(\n",
       "  (model): CoCa(\n",
       "    (text): TextTransformer(\n",
       "      (token_embedding): Embedding(32007, 768)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-11): 12 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_1): Identity()\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (visual): VisualModel(\n",
       "      (trunk): VisionTransformer(\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          (norm): Identity()\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (patch_drop): Identity()\n",
       "        (norm_pre): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (2): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (3): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (4): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (5): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (6): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (7): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (8): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (9): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (10): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (11): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (fc_norm): Identity()\n",
       "        (head_drop): Dropout(p=0.0, inplace=False)\n",
       "        (head): Identity()\n",
       "      )\n",
       "      (attn_pool_contrast): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_contrast): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (head): Sequential()\n",
       "      (attn_pool_caption): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_caption): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (text_decoder): MultimodalTransformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (cross_attn): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_1_kv): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/13226 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_29236\\2614587232.py:87: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 13226/13226 [12:41<00:00, 17.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6597 | Accuracy: 0.5826 | Precision: 0.5820 | Recall: 0.7697 | F1 Score: 0.6628\n",
      "✅ Model saved with improved val accuracy: 0.5826\n",
      "\n",
      "Epoch 7/7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CONCHModelForFinetuning(\n",
       "  (model): CoCa(\n",
       "    (text): TextTransformer(\n",
       "      (token_embedding): Embedding(32007, 768)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-11): 12 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_1): Identity()\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (visual): VisualModel(\n",
       "      (trunk): VisionTransformer(\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          (norm): Identity()\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (patch_drop): Identity()\n",
       "        (norm_pre): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (2): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (3): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (4): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (5): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (6): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (7): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (8): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (9): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (10): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (11): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (fc_norm): Identity()\n",
       "        (head_drop): Dropout(p=0.0, inplace=False)\n",
       "        (head): Identity()\n",
       "      )\n",
       "      (attn_pool_contrast): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_contrast): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (head): Sequential()\n",
       "      (attn_pool_caption): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_caption): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (text_decoder): MultimodalTransformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (cross_attn): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_1_kv): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/47535 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_29236\\2614587232.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 47535/47535 [45:55<00:00, 17.25it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6700 | Accuracy: 0.5769 | Precision: 0.5852 | Recall: 0.8151 | F1 Score: 0.6813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CONCHModelForFinetuning(\n",
       "  (model): CoCa(\n",
       "    (text): TextTransformer(\n",
       "      (token_embedding): Embedding(32007, 768)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-11): 12 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_1): Identity()\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (visual): VisualModel(\n",
       "      (trunk): VisionTransformer(\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          (norm): Identity()\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (patch_drop): Identity()\n",
       "        (norm_pre): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (2): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (3): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (4): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (5): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (6): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (7): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (8): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (9): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (10): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (11): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (fc_norm): Identity()\n",
       "        (head_drop): Dropout(p=0.0, inplace=False)\n",
       "        (head): Identity()\n",
       "      )\n",
       "      (attn_pool_contrast): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_contrast): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (head): Sequential()\n",
       "      (attn_pool_caption): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_caption): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (text_decoder): MultimodalTransformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (cross_attn): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_1_kv): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/13226 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_29236\\2614587232.py:87: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 13226/13226 [12:40<00:00, 17.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6621 | Accuracy: 0.5605 | Precision: 0.5583 | Recall: 0.8401 | F1 Score: 0.6708\n",
      "No improvement for 1 epoch(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x500 with 0 Axes>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11c9a5bb280>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11d019175e0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss Curve')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11d01be6110>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11c9fbc1ea0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11c9fbc3520>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy Curve')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x11c9a5ba9b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Evaluating best model on the test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_29236\\2614587232.py:145: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_save_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "CONCHModelForFinetuning(\n",
       "  (model): CoCa(\n",
       "    (text): TextTransformer(\n",
       "      (token_embedding): Embedding(32007, 768)\n",
       "      (transformer): Transformer(\n",
       "        (resblocks): ModuleList(\n",
       "          (0-11): 12 x ResidualAttentionBlock(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): MultiheadAttention(\n",
       "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_1): Identity()\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): Sequential(\n",
       "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (gelu): GELU(approximate='none')\n",
       "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            )\n",
       "            (ls_2): Identity()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (visual): VisualModel(\n",
       "      (trunk): VisionTransformer(\n",
       "        (patch_embed): PatchEmbed(\n",
       "          (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "          (norm): Identity()\n",
       "        )\n",
       "        (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "        (patch_drop): Identity()\n",
       "        (norm_pre): Identity()\n",
       "        (blocks): Sequential(\n",
       "          (0): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (1): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (2): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (3): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (4): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (5): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (6): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (7): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (8): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (9): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (10): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "          (11): Block(\n",
       "            (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (attn): Attention(\n",
       "              (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "              (q_norm): Identity()\n",
       "              (k_norm): Identity()\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls1): Identity()\n",
       "            (drop_path1): Identity()\n",
       "            (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "            (mlp): Mlp(\n",
       "              (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (act): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (norm): Identity()\n",
       "              (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (ls2): Identity()\n",
       "            (drop_path2): Identity()\n",
       "          )\n",
       "        )\n",
       "        (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (fc_norm): Identity()\n",
       "        (head_drop): Dropout(p=0.0, inplace=False)\n",
       "        (head): Identity()\n",
       "      )\n",
       "      (attn_pool_contrast): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_contrast): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (head): Sequential()\n",
       "      (attn_pool_caption): AttentionalPooler(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (ln_q): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (ln_k): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (ln_caption): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (text_decoder): MultimodalTransformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (cross_attn): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_1_kv): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "      (ln_final): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 13238/13238 [13:43<00:00, 16.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Final Test Results:\n",
      "Test Loss: 0.7153 | Accuracy: 0.4709 | Precision: 0.2800 | Recall: 0.8448 | F1 Score: 0.4206\n",
      "✅ Test predictions saved to: patch_predictions/annotated/CONCH_linprob_ann_test.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Setup\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Only optimize the classification head (linear layer) - for linear probing\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-5)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = 'cuda'\n",
    "num_epochs = 7\n",
    "patience = 5\n",
    "\n",
    "# model_save_path = '/Users/Vivian/Documents/CONCH/_finetune_weights_CONCH/with_val_earlystop.pth'\n",
    "# csv_save_path = \"/Users/Vivian/Documents/CONCH/patch_predictions/with_val_earlystop.csv\"\n",
    "\n",
    "# Define model save path\n",
    "model_save_path = \"/Users/Vivian/Documents/CONCH/_finetune_weights_CONCH/linprob_ann.pth\"\n",
    "# Define CSV path for saving patch predictions\n",
    "csv_save_path = \"patch_predictions/annotated/CONCH_linprob_ann.csv\"\n",
    "\n",
    "best_val_accuracy = 0\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# Mixed Precision\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Metrics tracking\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    correct_train, total_train = 0, 0\n",
    "    all_train_labels, all_train_preds = [], []\n",
    "\n",
    "    for images, labels, _ in tqdm.tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "        all_train_labels.extend(labels.cpu().numpy())\n",
    "        all_train_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # print(f\"Train Loss: {avg_train_loss:.4f} | Accuracy: {train_accuracy:.4f}\")\n",
    "    train_precision = precision_score(all_train_labels, all_train_preds, average=\"binary\")\n",
    "    train_recall = recall_score(all_train_labels, all_train_preds, average=\"binary\")\n",
    "    train_f1 = f1_score(all_train_labels, all_train_preds, average=\"binary\")\n",
    "\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Accuracy: {train_accuracy:.4f} | \"\n",
    "        f\"Precision: {train_precision:.4f} | Recall: {train_recall:.4f} | F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    correct_val, total_val = 0, 0\n",
    "    all_val_labels, all_val_preds = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in tqdm.tqdm(val_loader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "            all_val_labels.extend(labels.cpu().numpy())\n",
    "            all_val_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_accuracy = correct_val / total_val\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    val_precision = precision_score(all_val_labels, all_val_preds, average=\"binary\")\n",
    "    val_recall = recall_score(all_val_labels, all_val_preds, average=\"binary\")\n",
    "    val_f1 = f1_score(all_val_labels, all_val_preds, average=\"binary\")\n",
    "\n",
    "    print(f\"Val Loss: {avg_val_loss:.4f} | Accuracy: {val_accuracy:.4f} | \"\n",
    "          f\"Precision: {val_precision:.4f} | Recall: {val_recall:.4f} | F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "    # --- Early Stopping ---\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"✅ Model saved with improved val accuracy: {val_accuracy:.4f}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No improvement for {epochs_no_improve} epoch(s)\")\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"⏹️ Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# --- Plotting ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Val Accuracy')\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Final Test Evaluation ---\n",
    "print(\"\\n🔍 Evaluating best model on the test set...\")\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.eval()\n",
    "\n",
    "total_test_loss = 0\n",
    "correct_test, total_test = 0, 0\n",
    "all_test_labels, all_test_preds = [], []\n",
    "test_predictions_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, file_paths in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "        total_test += labels.size(0)\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "        all_test_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        for i in range(labels.size(0)):\n",
    "            test_predictions_list.append([file_paths[i], predicted[i].item(), labels[i].item()])\n",
    "\n",
    "avg_test_loss = total_test_loss / len(test_loader)\n",
    "test_accuracy = correct_test / total_test\n",
    "test_precision = precision_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "test_recall = recall_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "test_f1 = f1_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "\n",
    "print(f\"\\n📊 Final Test Results:\\n\"\n",
    "      f\"Test Loss: {avg_test_loss:.4f} | Accuracy: {test_accuracy:.4f} | \"\n",
    "      f\"Precision: {test_precision:.4f} | Recall: {test_recall:.4f} | F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "# Save test predictions\n",
    "test_csv_path = csv_save_path.replace(\".csv\", \"_test.csv\")\n",
    "df_test = pd.DataFrame(test_predictions_list, columns=[\"Patch Path\", \"Predicted\", \"True Label\"])\n",
    "df_test.to_csv(test_csv_path, index=False)\n",
    "print(f\"✅ Test predictions saved to: {test_csv_path}\")\n",
    "\n",
    "# --- Save metrics summary to CSV ---\n",
    "metrics = {\n",
    "    \"Epochs Trained\": len(train_losses),\n",
    "    \"Best Val Accuracy\": best_val_accuracy,\n",
    "    \n",
    "    # Final epoch training metrics\n",
    "    \"Train Loss\": train_losses[-1],\n",
    "    \"Train Accuracy\": train_accuracy,\n",
    "    \"Train Precision\": train_precision,\n",
    "    \"Train Recall\": train_recall,\n",
    "    \"Train F1 Score\": train_f1,\n",
    "\n",
    "    # Final epoch validation metrics\n",
    "    \"Val Loss\": avg_val_loss,\n",
    "    \"Val Accuracy\": val_accuracy,\n",
    "    \"Val Precision\": val_precision,\n",
    "    \"Val Recall\": val_recall,\n",
    "    \"Val F1 Score\": val_f1,\n",
    "\n",
    "    # Final test metrics\n",
    "    \"Test Loss\": avg_test_loss,\n",
    "    \"Test Accuracy\": test_accuracy,\n",
    "    \"Test Precision\": test_precision,\n",
    "    \"Test Recall\": test_recall,\n",
    "    \"Test F1 Score\": test_f1\n",
    "}\n",
    "\n",
    "# Save as CSV (one row)\n",
    "summary_path = csv_save_path.replace(\".csv\", \"_metrics_summary.csv\")\n",
    "pd.DataFrame([metrics]).to_csv(summary_path, index=False)\n",
    "print(f\"📁 Metrics summary saved to: {summary_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCH/UNI with validation set + training curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_11968\\3572286680.py:30: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/47535 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_11968\\3572286680.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 47535/47535 [50:12<00:00, 15.78it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6713 | Accuracy: 0.5734 | Precision: 0.5842 | Recall: 0.8020 | F1 Score: 0.6760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/13226 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_11968\\3572286680.py:87: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 13226/13226 [14:16<00:00, 15.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6576 | Accuracy: 0.5656 | Precision: 0.5637 | Recall: 0.8187 | F1 Score: 0.6677\n",
      "✅ Model saved with improved val accuracy: 0.5656\n",
      "\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/47535 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_11968\\3572286680.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 47535/47535 [51:37<00:00, 15.34it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6674 | Accuracy: 0.5788 | Precision: 0.5889 | Recall: 0.7973 | F1 Score: 0.6775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/13226 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_11968\\3572286680.py:87: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 13226/13226 [14:16<00:00, 15.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6556 | Accuracy: 0.5898 | Precision: 0.5888 | Recall: 0.7634 | F1 Score: 0.6648\n",
      "✅ Model saved with improved val accuracy: 0.5898\n",
      "\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/47535 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_11968\\3572286680.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 47535/47535 [51:14<00:00, 15.46it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6657 | Accuracy: 0.5800 | Precision: 0.5902 | Recall: 0.7950 | F1 Score: 0.6775\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/13226 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_11968\\3572286680.py:87: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 13226/13226 [14:07<00:00, 15.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6555 | Accuracy: 0.5758 | Precision: 0.5729 | Recall: 0.8018 | F1 Score: 0.6683\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/47535 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_11968\\3572286680.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 47535/47535 [51:07<00:00, 15.49it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6647 | Accuracy: 0.5807 | Precision: 0.5907 | Recall: 0.7954 | F1 Score: 0.6779\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/13226 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_11968\\3572286680.py:87: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 13226/13226 [13:58<00:00, 15.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6528 | Accuracy: 0.6076 | Precision: 0.6107 | Recall: 0.7274 | F1 Score: 0.6640\n",
      "✅ Model saved with improved val accuracy: 0.6076\n",
      "\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/47535 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_11968\\3572286680.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 47535/47535 [51:15<00:00, 15.45it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6637 | Accuracy: 0.5818 | Precision: 0.5917 | Recall: 0.7944 | F1 Score: 0.6782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/13226 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_11968\\3572286680.py:87: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 13226/13226 [14:07<00:00, 15.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6541 | Accuracy: 0.5770 | Precision: 0.5723 | Recall: 0.8161 | F1 Score: 0.6728\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/47535 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_11968\\3572286680.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 47535/47535 [52:45<00:00, 15.02it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6630 | Accuracy: 0.5832 | Precision: 0.5926 | Recall: 0.7957 | F1 Score: 0.6793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/13226 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_11968\\3572286680.py:87: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 13226/13226 [14:09<00:00, 15.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6575 | Accuracy: 0.5732 | Precision: 0.5658 | Recall: 0.8561 | F1 Score: 0.6813\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/47535 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_11968\\3572286680.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 47535/47535 [51:11<00:00, 15.48it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6625 | Accuracy: 0.5832 | Precision: 0.5924 | Recall: 0.7975 | F1 Score: 0.6799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/13226 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_11968\\3572286680.py:87: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 13226/13226 [14:12<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6543 | Accuracy: 0.5828 | Precision: 0.5764 | Recall: 0.8197 | F1 Score: 0.6769\n",
      "No improvement for 3 epoch(s)\n",
      "\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/47535 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_11968\\3572286680.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 47535/47535 [50:41<00:00, 15.63it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6618 | Accuracy: 0.5841 | Precision: 0.5931 | Recall: 0.7976 | F1 Score: 0.6803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/13226 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_11968\\3572286680.py:87: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 13226/13226 [14:09<00:00, 15.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6537 | Accuracy: 0.5971 | Precision: 0.5918 | Recall: 0.7863 | F1 Score: 0.6754\n",
      "No improvement for 4 epoch(s)\n",
      "\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/47535 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_11968\\3572286680.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training:   4%|▍         | 1858/47535 [01:58<48:26, 15.72it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 44\u001b[0m\n\u001b[0;32m     41\u001b[0m correct_train, total_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     42\u001b[0m all_train_labels, all_train_preds \u001b[38;5;241m=\u001b[39m [], []\n\u001b[1;32m---> 44\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m images, labels, _ \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     45\u001b[0m     images, labels \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     46\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mc:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[6], line 29\u001b[0m, in \u001b[0;36mHistopathologyDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Load image patch\u001b[39;00m\n\u001b[0;32m     28\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39miloc[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 29\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Load .npy file (already in NumPy format)\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;66;03m# Ensure image is in (C, H, W) format for PyTorch\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:  \u001b[38;5;66;03m# Check if image is in (H, W, C) format\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\numpy\\lib\\npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Setup\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Only optimize the classification head (linear layer) - for linear probing\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-5)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = 'cuda'\n",
    "num_epochs = 10\n",
    "patience = 5\n",
    "\n",
    "# model_save_path = '/Users/Vivian/Documents/CONCH/_finetune_weights_CONCH/with_val_earlystop.pth'\n",
    "# csv_save_path = \"/Users/Vivian/Documents/CONCH/patch_predictions/with_val_earlystop.csv\"\n",
    "\n",
    "# Define model save path\n",
    "model_save_path = \"/Users/Vivian/Documents/CONCH/_finetune_weights_UNI/linprob_ann.pth\"\n",
    "# Define CSV path for saving patch predictions\n",
    "csv_save_path = \"patch_predictions/annotated/UNI_linprob_ann.csv\"\n",
    "\n",
    "best_val_accuracy = 0\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# Mixed Precision\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Metrics tracking\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    correct_train, total_train = 0, 0\n",
    "    all_train_labels, all_train_preds = [], []\n",
    "\n",
    "    for images, labels, _ in tqdm.tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "        all_train_labels.extend(labels.cpu().numpy())\n",
    "        all_train_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # print(f\"Train Loss: {avg_train_loss:.4f} | Accuracy: {train_accuracy:.4f}\")\n",
    "    train_precision = precision_score(all_train_labels, all_train_preds, average=\"binary\")\n",
    "    train_recall = recall_score(all_train_labels, all_train_preds, average=\"binary\")\n",
    "    train_f1 = f1_score(all_train_labels, all_train_preds, average=\"binary\")\n",
    "\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Accuracy: {train_accuracy:.4f} | \"\n",
    "        f\"Precision: {train_precision:.4f} | Recall: {train_recall:.4f} | F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    correct_val, total_val = 0, 0\n",
    "    all_val_labels, all_val_preds = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in tqdm.tqdm(val_loader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "            all_val_labels.extend(labels.cpu().numpy())\n",
    "            all_val_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_accuracy = correct_val / total_val\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    val_precision = precision_score(all_val_labels, all_val_preds, average=\"binary\")\n",
    "    val_recall = recall_score(all_val_labels, all_val_preds, average=\"binary\")\n",
    "    val_f1 = f1_score(all_val_labels, all_val_preds, average=\"binary\")\n",
    "\n",
    "    print(f\"Val Loss: {avg_val_loss:.4f} | Accuracy: {val_accuracy:.4f} | \"\n",
    "          f\"Precision: {val_precision:.4f} | Recall: {val_recall:.4f} | F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "    # --- Early Stopping ---\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"✅ Model saved with improved val accuracy: {val_accuracy:.4f}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No improvement for {epochs_no_improve} epoch(s)\")\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"⏹️ Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# --- Plotting ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Val Accuracy')\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Final Test Evaluation ---\n",
    "print(\"\\n🔍 Evaluating best model on the test set...\")\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.eval()\n",
    "\n",
    "total_test_loss = 0\n",
    "correct_test, total_test = 0, 0\n",
    "all_test_labels, all_test_preds = [], []\n",
    "test_predictions_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, file_paths in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "        total_test += labels.size(0)\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "        all_test_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        for i in range(labels.size(0)):\n",
    "            test_predictions_list.append([file_paths[i], predicted[i].item(), labels[i].item()])\n",
    "\n",
    "avg_test_loss = total_test_loss / len(test_loader)\n",
    "test_accuracy = correct_test / total_test\n",
    "test_precision = precision_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "test_recall = recall_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "test_f1 = f1_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "\n",
    "print(f\"\\n📊 Final Test Results:\\n\"\n",
    "      f\"Test Loss: {avg_test_loss:.4f} | Accuracy: {test_accuracy:.4f} | \"\n",
    "      f\"Precision: {test_precision:.4f} | Recall: {test_recall:.4f} | F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "# Save test predictions\n",
    "test_csv_path = csv_save_path.replace(\".csv\", \"_test.csv\")\n",
    "df_test = pd.DataFrame(test_predictions_list, columns=[\"Patch Path\", \"Predicted\", \"True Label\"])\n",
    "df_test.to_csv(test_csv_path, index=False)\n",
    "print(f\"✅ Test predictions saved to: {test_csv_path}\")\n",
    "\n",
    "# --- Save metrics summary to CSV ---\n",
    "metrics = {\n",
    "    \"Epochs Trained\": len(train_losses),\n",
    "    \"Best Val Accuracy\": best_val_accuracy,\n",
    "    \n",
    "    # Final epoch training metrics\n",
    "    \"Train Loss\": train_losses[-1],\n",
    "    \"Train Accuracy\": train_accuracy,\n",
    "    \"Train Precision\": train_precision,\n",
    "    \"Train Recall\": train_recall,\n",
    "    \"Train F1 Score\": train_f1,\n",
    "\n",
    "    # Final epoch validation metrics\n",
    "    \"Val Loss\": avg_val_loss,\n",
    "    \"Val Accuracy\": val_accuracy,\n",
    "    \"Val Precision\": val_precision,\n",
    "    \"Val Recall\": val_recall,\n",
    "    \"Val F1 Score\": val_f1,\n",
    "\n",
    "    # Final test metrics\n",
    "    \"Test Loss\": avg_test_loss,\n",
    "    \"Test Accuracy\": test_accuracy,\n",
    "    \"Test Precision\": test_precision,\n",
    "    \"Test Recall\": test_recall,\n",
    "    \"Test F1 Score\": test_f1\n",
    "}\n",
    "\n",
    "# Save as CSV (one row)\n",
    "summary_path = csv_save_path.replace(\".csv\", \"_metrics_summary.csv\")\n",
    "pd.DataFrame([metrics]).to_csv(summary_path, index=False)\n",
    "print(f\"📁 Metrics summary saved to: {summary_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x500 with 0 Axes>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x210e1f24ac0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x210e1f24ca0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss Curve')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x210abf94cd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x210e24c2c20>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x210e24c2ec0>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy Curve')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x210e1f25a80>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Evaluating best model on the test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_11968\\2356989140.py:23: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_save_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 13238/13238 [24:12<00:00,  9.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Final Test Results:\n",
      "Test Loss: 0.6941 | Accuracy: 0.5359 | Precision: 0.2895 | Recall: 0.7159 | F1 Score: 0.4123\n",
      "✅ Test predictions saved to: patch_predictions/annotated/UNI_linprob_ann_test.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Plotting ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Val Accuracy')\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Final Test Evaluation ---\n",
    "print(\"\\n🔍 Evaluating best model on the test set...\")\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.eval()\n",
    "\n",
    "total_test_loss = 0\n",
    "correct_test, total_test = 0, 0\n",
    "all_test_labels, all_test_preds = [], []\n",
    "test_predictions_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, file_paths in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "        total_test += labels.size(0)\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "        all_test_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        for i in range(labels.size(0)):\n",
    "            test_predictions_list.append([file_paths[i], predicted[i].item(), labels[i].item()])\n",
    "\n",
    "avg_test_loss = total_test_loss / len(test_loader)\n",
    "test_accuracy = correct_test / total_test\n",
    "test_precision = precision_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "test_recall = recall_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "test_f1 = f1_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "\n",
    "print(f\"\\n📊 Final Test Results:\\n\"\n",
    "      f\"Test Loss: {avg_test_loss:.4f} | Accuracy: {test_accuracy:.4f} | \"\n",
    "      f\"Precision: {test_precision:.4f} | Recall: {test_recall:.4f} | F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "# Save test predictions\n",
    "test_csv_path = csv_save_path.replace(\".csv\", \"_test.csv\")\n",
    "df_test = pd.DataFrame(test_predictions_list, columns=[\"Patch Path\", \"Predicted\", \"True Label\"])\n",
    "df_test.to_csv(test_csv_path, index=False)\n",
    "print(f\"✅ Test predictions saved to: {test_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNI2 - fold 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop - attempting to add other metrics\n",
    "# epoch 1: testing: 100%|██████████| 989/989 [11:00<00:00,  1.50it/s]\n",
    "# Accuracy: 0.8459982298647111\n",
    "# Precision: 0.8539486117274182\n",
    "# Recall: 0.8459982298647111\n",
    "# F1 Score: 0.8446127567770744\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# define the loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# define the number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# define the path to save the model\n",
    "model_save_path = '/Users/Vivian/Documents/CONCH/_finetune_weights_UNI2/fine_tuned_model-fold2.pth'\n",
    "\n",
    "# define the best accuracy\n",
    "best_accuracy = 0\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "# start the training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Starting epoch {epoch+1}/{num_epochs}')\n",
    "    model.train()\n",
    "    for batch in tqdm.tqdm(train_loader, desc='training'):\n",
    "        images, labels = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} done')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "        for batch in tqdm.tqdm(test_loader, desc='testing'):\n",
    "            images, labels = batch\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "        accuracy = correct / total\n",
    "        precision = precision_score(all_labels, all_predictions, average='weighted')\n",
    "        recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "        f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "        print(f'Accuracy: {accuracy}')\n",
    "        print(f'Precision: {precision}')\n",
    "        print(f'Recall: {recall}')\n",
    "        print(f'F1 Score: {f1}')\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f'Model saved with accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNI 2 - patch predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Define loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Define number of epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Define model save path\n",
    "model_save_path = \"/Users/Vivian/Documents/CONCH/_finetune_weights_UNI2/all_slides_model1.pth\"\n",
    "\n",
    "# Define CSV path for saving patch predictions\n",
    "csv_save_path = \"/Users/Vivian/Documents/CONCH/patch_predictions_UNI2.csv\"\n",
    "\n",
    "# Best accuracy tracker\n",
    "best_accuracy = 0\n",
    "\n",
    "# Device setup\n",
    "device = 'cuda'\n",
    "\n",
    "# Start training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Starting epoch {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    num_train_batches = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    all_train_labels = []\n",
    "    all_train_predictions = []\n",
    "\n",
    "    # Training phase\n",
    "    for batch in tqdm.tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels, img_path = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        num_train_batches += 1\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "        all_train_labels.extend(labels.cpu().numpy())\n",
    "        all_train_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_train_batches\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_precision = precision_score(all_train_labels, all_train_predictions, average=\"binary\")\n",
    "    train_recall = recall_score(all_train_labels, all_train_predictions, average=\"binary\")\n",
    "    train_f1 = f1_score(all_train_labels, all_train_predictions, average=\"binary\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "    # Evaluation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_test_loss = 0\n",
    "        num_test_batches = 0\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        all_test_labels = []\n",
    "        all_test_predictions = []\n",
    "        predictions_list = []  # List to store patch-level predictions\n",
    "\n",
    "        for batch in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "            images, labels, file_paths = batch\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)  # Compute test loss\n",
    "            total_test_loss += loss.item()\n",
    "            num_test_batches += 1\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "            total_test += labels.size(0)\n",
    "            all_test_labels.extend(labels.cpu().numpy())\n",
    "            all_test_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "            # Store predictions for CSV\n",
    "            for i in range(labels.size(0)):\n",
    "                predictions_list.append([file_paths[i], predicted[i].item(), labels[i].item()])\n",
    "\n",
    "        # Compute test classification metrics\n",
    "        test_accuracy = correct_test / total_test\n",
    "        test_precision = precision_score(all_test_labels, all_test_predictions, average=\"binary\")\n",
    "        test_recall = recall_score(all_test_labels, all_test_predictions, average=\"binary\")\n",
    "        test_f1 = f1_score(all_test_labels, all_test_predictions, average=\"binary\")\n",
    "        avg_test_loss = total_test_loss / num_test_batches  # Compute average test loss\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Test Loss: {avg_test_loss:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Test Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "        # Save model and predictions CSV only if test accuracy improves\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Model saved with accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "            # Save predictions to CSV\n",
    "            df_predictions = pd.DataFrame(predictions_list, columns=[\"Patch Path\", \"Predicted\", \"True Label\"])\n",
    "            df_predictions.to_csv(csv_save_path, index=False)\n",
    "            print(f\"Patch predictions saved to: {csv_save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNI2 - Trying to use mixed precison to speed up training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking very long to train - only 14% through first epoch after 7 hours\n",
    "\n",
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Define loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Define number of epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Define model save path\n",
    "model_save_path = \"/Users/Vivian/Documents/CONCH/_finetune_weights_UNI2/all_slides_model1.pth\"\n",
    "\n",
    "# Define CSV path for saving patch predictions\n",
    "csv_save_path = \"/Users/Vivian/Documents/CONCH/patch_predictions_UNI2.csv\"\n",
    "\n",
    "# Best accuracy tracker\n",
    "best_accuracy = 0\n",
    "\n",
    "# Enable AMP for mixed precision training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Device setup\n",
    "device = 'cuda'\n",
    "\n",
    "# Start training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Starting epoch {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    num_train_batches = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    all_train_labels = []\n",
    "    all_train_predictions = []\n",
    "\n",
    "    # Training phase\n",
    "    for batch in tqdm.tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels, img_path = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass using AMP\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Track training loss\n",
    "        total_train_loss += loss.item()\n",
    "        num_train_batches += 1\n",
    "\n",
    "        # Track training accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "        all_train_labels.extend(labels.cpu().numpy())\n",
    "        all_train_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_train_batches\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_precision = precision_score(all_train_labels, all_train_predictions, average=\"binary\")\n",
    "    train_recall = recall_score(all_train_labels, all_train_predictions, average=\"binary\")\n",
    "    train_f1 = f1_score(all_train_labels, all_train_predictions, average=\"binary\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "    # Evaluation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_test_loss = 0\n",
    "        num_test_batches = 0\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        all_test_labels = []\n",
    "        all_test_predictions = []\n",
    "        predictions_list = []  # List to store patch-level predictions\n",
    "\n",
    "        for batch in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "            images, labels, file_paths = batch\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass using AMP\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            # Track test loss\n",
    "            total_test_loss += loss.item()\n",
    "            num_test_batches += 1\n",
    "\n",
    "            # Track test accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "            total_test += labels.size(0)\n",
    "            all_test_labels.extend(labels.cpu().numpy())\n",
    "            all_test_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "            # Store predictions for CSV\n",
    "            for i in range(labels.size(0)):\n",
    "                predictions_list.append([file_paths[i], predicted[i].item(), labels[i].item()])\n",
    "\n",
    "        # Compute test classification metrics\n",
    "        test_accuracy = correct_test / total_test\n",
    "        test_precision = precision_score(all_test_labels, all_test_predictions, average=\"binary\")\n",
    "        test_recall = recall_score(all_test_labels, all_test_predictions, average=\"binary\")\n",
    "        test_f1 = f1_score(all_test_labels, all_test_predictions, average=\"binary\")\n",
    "        avg_test_loss = total_test_loss / num_test_batches  # Compute average test loss\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Test Loss: {avg_test_loss:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Test Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "        # Save model and predictions CSV only if test accuracy improves\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Model saved with accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "            # Save predictions to CSV\n",
    "            df_predictions = pd.DataFrame(predictions_list, columns=[\"Patch Path\", \"Predicted\", \"True Label\"])\n",
    "            df_predictions.to_csv(csv_save_path, index=False)\n",
    "            print(f\"Patch predictions saved to: {csv_save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNI - fold 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t\n",
    "# Accuracy: 0.8403085092932102\n",
    "# Precision: 0.8393633460472893\n",
    "# Recall: 0.8403085092932102\n",
    "# F1 Score: 0.836823046643581\n",
    "# Model saved with accuracy: 0.8403085092932102\n",
    "# Starting epoch 5/10\n",
    "\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# define the loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# define the number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# define the path to save the model\n",
    "model_save_path = '/Users/Vivian/Documents/CONCH/_finetune_weights_UNI/fine_tuned_model-fold2.pth'\n",
    "\n",
    "# define the best accuracy\n",
    "best_accuracy = 0\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "# start the training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Starting epoch {epoch+1}/{num_epochs}')\n",
    "    model.train()\n",
    "    for batch in tqdm.tqdm(train_loader, desc='training'):\n",
    "        images, labels = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}/{num_epochs} done')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_labels = []\n",
    "        all_predictions = []\n",
    "        for batch in tqdm.tqdm(test_loader, desc='testing'):\n",
    "            images, labels = batch\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "        accuracy = correct / total\n",
    "        precision = precision_score(all_labels, all_predictions, average='weighted')\n",
    "        recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "        f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "        print(f'Accuracy: {accuracy}')\n",
    "        print(f'Precision: {precision}')\n",
    "        print(f'Recall: {recall}')\n",
    "        print(f'F1 Score: {f1}')\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f'Model saved with accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNI - patch predictions with amp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_2236\\1279580505.py:28: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/51837 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_2236\\1279580505.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():  # Enable mixed precision\n",
      "Training: 100%|██████████| 51837/51837 [54:42<00:00, 15.79it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Train Loss: 0.6563\n",
      "Epoch 1/5 - Train Accuracy: 0.5958, Precision: 0.6135, Recall: 0.6833, F1 Score: 0.6465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/14199 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_2236\\1279580505.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Testing: 100%|██████████| 14199/14199 [15:03<00:00, 15.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Test Loss: 0.6975\n",
      "Epoch 1/5 - Test Accuracy: 0.5187, Precision: 0.4689, Recall: 0.4210, F1 Score: 0.4437\n",
      "Model saved with accuracy: 0.5187\n",
      "Patch predictions saved to: /Users/Vivian/Documents/CONCH/patch_predictions/patient_split_UNI70_linprob.csv\n",
      "Starting epoch 2/5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/51837 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_2236\\1279580505.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():  # Enable mixed precision\n",
      "Training: 100%|██████████| 51837/51837 [54:39<00:00, 15.81it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Train Loss: 0.6500\n",
      "Epoch 2/5 - Train Accuracy: 0.6029, Precision: 0.6221, Recall: 0.6777, F1 Score: 0.6487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/14199 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_2236\\1279580505.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Testing: 100%|██████████| 14199/14199 [15:02<00:00, 15.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 - Test Loss: 0.7023\n",
      "Epoch 2/5 - Test Accuracy: 0.5206, Precision: 0.4763, Recall: 0.5214, F1 Score: 0.4978\n",
      "Model saved with accuracy: 0.5206\n",
      "Patch predictions saved to: /Users/Vivian/Documents/CONCH/patch_predictions/patient_split_UNI70_linprob.csv\n",
      "Starting epoch 3/5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/51837 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_2236\\1279580505.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():  # Enable mixed precision\n",
      "Training: 100%|██████████| 51837/51837 [54:53<00:00, 15.74it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Train Loss: 0.6476\n",
      "Epoch 3/5 - Train Accuracy: 0.6052, Precision: 0.6240, Recall: 0.6799, F1 Score: 0.6508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/14199 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_2236\\1279580505.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Testing: 100%|██████████| 14199/14199 [15:02<00:00, 15.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 - Test Loss: 0.7029\n",
      "Epoch 3/5 - Test Accuracy: 0.5224, Precision: 0.4700, Recall: 0.3739, F1 Score: 0.4165\n",
      "Model saved with accuracy: 0.5224\n",
      "Patch predictions saved to: /Users/Vivian/Documents/CONCH/patch_predictions/patient_split_UNI70_linprob.csv\n",
      "Starting epoch 4/5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/51837 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_2236\\1279580505.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():  # Enable mixed precision\n",
      "Training: 100%|██████████| 51837/51837 [54:39<00:00, 15.81it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Train Loss: 0.6453\n",
      "Epoch 4/5 - Train Accuracy: 0.6085, Precision: 0.6267, Recall: 0.6833, F1 Score: 0.6538\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/14199 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_2236\\1279580505.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Testing: 100%|██████████| 14199/14199 [15:03<00:00, 15.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 - Test Loss: 0.7060\n",
      "Epoch 4/5 - Test Accuracy: 0.5255, Precision: 0.4824, Recall: 0.5591, F1 Score: 0.5179\n",
      "Model saved with accuracy: 0.5255\n",
      "Patch predictions saved to: /Users/Vivian/Documents/CONCH/patch_predictions/patient_split_UNI70_linprob.csv\n",
      "Starting epoch 5/5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/51837 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_2236\\1279580505.py:53: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():  # Enable mixed precision\n",
      "Training: 100%|██████████| 51837/51837 [54:52<00:00, 15.74it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Train Loss: 0.6434\n",
      "Epoch 5/5 - Train Accuracy: 0.6103, Precision: 0.6283, Recall: 0.6850, F1 Score: 0.6554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNIModelForFinetuning(\n",
       "  (model): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "      (norm): Identity()\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (patch_drop): Identity()\n",
       "    (norm_pre): Identity()\n",
       "    (blocks): Sequential(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (12): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (13): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (14): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (15): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (16): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (17): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (18): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (19): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (20): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (21): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (22): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "      (23): Block(\n",
       "        (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "          (q_norm): Identity()\n",
       "          (k_norm): Identity()\n",
       "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "          (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls1): LayerScale()\n",
       "        (drop_path1): Identity()\n",
       "        (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (act): GELU(approximate='none')\n",
       "          (drop1): Dropout(p=0.0, inplace=False)\n",
       "          (norm): Identity()\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (drop2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (ls2): LayerScale()\n",
       "        (drop_path2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (fc_norm): Identity()\n",
       "    (head_drop): Dropout(p=0.0, inplace=False)\n",
       "    (head): Identity()\n",
       "  )\n",
       "  (fc): Linear(in_features=1024, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/14199 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_2236\\1279580505.py:96: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Testing: 100%|██████████| 14199/14199 [16:00<00:00, 14.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 - Test Loss: 0.7298\n",
      "Epoch 5/5 - Test Accuracy: 0.5385, Precision: 0.4960, Recall: 0.7718, F1 Score: 0.6039\n",
      "Model saved with accuracy: 0.5385\n",
      "Patch predictions saved to: /Users/Vivian/Documents/CONCH/patch_predictions/patient_split_UNI70_linprob.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Define optimizer\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Only optimize the classification head (linear layer) - for linear probing\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-4)\n",
    "\n",
    "# Define loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Define number of epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Define model save path\n",
    "model_save_path = \"/Users/Vivian/Documents/CONCH/_finetune_weights_UNI/patient_split_70_linprob.pth\"\n",
    "\n",
    "# Define CSV path for saving patch predictions\n",
    "csv_save_path = \"/Users/Vivian/Documents/CONCH/patch_predictions/patient_split_UNI70_linprob.csv\"\n",
    "\n",
    "# Best accuracy tracker\n",
    "best_accuracy = 0\n",
    "\n",
    "# Mixed Precision Training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Device setup\n",
    "device = 'cuda'\n",
    "\n",
    "# Start training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Starting epoch {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    num_train_batches = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    all_train_labels = []\n",
    "    all_train_predictions = []\n",
    "\n",
    "    # Training phase\n",
    "    for batch in tqdm.tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels, img_path = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():  # Enable mixed precision\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        num_train_batches += 1\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "        all_train_labels.extend(labels.cpu().numpy())\n",
    "        all_train_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_train_batches\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_precision = precision_score(all_train_labels, all_train_predictions, average=\"binary\")\n",
    "    train_recall = recall_score(all_train_labels, all_train_predictions, average=\"binary\")\n",
    "    train_f1 = f1_score(all_train_labels, all_train_predictions, average=\"binary\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "    # Evaluation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_test_loss = 0\n",
    "        num_test_batches = 0\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        all_test_labels = []\n",
    "        all_test_predictions = []\n",
    "        predictions_list = []  # List to store patch-level predictions\n",
    "\n",
    "        for batch in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "            images, labels, file_paths = batch\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)  # Compute test loss\n",
    "\n",
    "            total_test_loss += loss.item()\n",
    "            num_test_batches += 1\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "            total_test += labels.size(0)\n",
    "            all_test_labels.extend(labels.cpu().numpy())\n",
    "            all_test_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "            # Store predictions for CSV\n",
    "            for i in range(labels.size(0)):\n",
    "                predictions_list.append([file_paths[i], predicted[i].item(), labels[i].item()])\n",
    "\n",
    "        # Compute test classification metrics\n",
    "        test_accuracy = correct_test / total_test\n",
    "        test_precision = precision_score(all_test_labels, all_test_predictions, average=\"binary\")\n",
    "        test_recall = recall_score(all_test_labels, all_test_predictions, average=\"binary\")\n",
    "        test_f1 = f1_score(all_test_labels, all_test_predictions, average=\"binary\")\n",
    "        avg_test_loss = total_test_loss / num_test_batches  # Compute average test loss\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Test Loss: {avg_test_loss:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Test Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "        # Save model and predictions CSV only if test accuracy improves\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Model saved with accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "            # Save predictions to CSV\n",
    "            df_predictions = pd.DataFrame(predictions_list, columns=[\"Patch Path\", \"Predicted\", \"True Label\"])\n",
    "            df_predictions.to_csv(csv_save_path, index=False)\n",
    "            print(f\"Patch predictions saved to: {csv_save_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNI - without mixed precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Define loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Define number of epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Define model save path\n",
    "model_save_path = \"/Users/Vivian/Documents/CONCH/_finetune_weights_UNI/all_slides_model1.pth\"\n",
    "\n",
    "# Define CSV path for saving patch predictions\n",
    "csv_save_path = \"/Users/Vivian/Documents/CONCH/patch_predictions_UNI.csv\"\n",
    "\n",
    "# Best accuracy tracker\n",
    "best_accuracy = 0\n",
    "\n",
    "# Device setup\n",
    "device = 'cuda'\n",
    "\n",
    "# Start training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Starting epoch {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    num_train_batches = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    all_train_labels = []\n",
    "    all_train_predictions = []\n",
    "\n",
    "    # Training phase\n",
    "    for batch in tqdm.tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels, img_path = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass (no AMP)\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track training loss\n",
    "        total_train_loss += loss.item()\n",
    "        num_train_batches += 1\n",
    "\n",
    "        # Track training accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "        all_train_labels.extend(labels.cpu().numpy())\n",
    "        all_train_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_train_batches\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_precision = precision_score(all_train_labels, all_train_predictions, average=\"binary\")\n",
    "    train_recall = recall_score(all_train_labels, all_train_predictions, average=\"binary\")\n",
    "    train_f1 = f1_score(all_train_labels, all_train_predictions, average=\"binary\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "    # Evaluation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_test_loss = 0\n",
    "        num_test_batches = 0\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        all_test_labels = []\n",
    "        all_test_predictions = []\n",
    "        predictions_list = []  # List to store patch-level predictions\n",
    "\n",
    "        for batch in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "            images, labels, file_paths = batch\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass (no AMP)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)  # Compute test loss\n",
    "\n",
    "            # Track test loss\n",
    "            total_test_loss += loss.item()\n",
    "            num_test_batches += 1\n",
    "\n",
    "            # Track test accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "            total_test += labels.size(0)\n",
    "            all_test_labels.extend(labels.cpu().numpy())\n",
    "            all_test_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "            # Store predictions for CSV\n",
    "            for i in range(labels.size(0)):\n",
    "                predictions_list.append([file_paths[i], predicted[i].item(), labels[i].item()])\n",
    "\n",
    "        # Compute test classification metrics\n",
    "        test_accuracy = correct_test / total_test\n",
    "        test_precision = precision_score(all_test_labels, all_test_predictions, average=\"binary\")\n",
    "        test_recall = recall_score(all_test_labels, all_test_predictions, average=\"binary\")\n",
    "        test_f1 = f1_score(all_test_labels, all_test_predictions, average=\"binary\")\n",
    "        avg_test_loss = total_test_loss / num_test_batches  # Compute average test loss\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Test Loss: {avg_test_loss:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Test Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "        # Save model and predictions CSV only if test accuracy improves\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Model saved with accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "            # Save predictions to CSV\n",
    "            df_predictions = pd.DataFrame(predictions_list, columns=[\"Patch Path\", \"Predicted\", \"True Label\"])\n",
    "            df_predictions.to_csv(csv_save_path, index=False)\n",
    "            print(f\"Patch predictions saved to: {csv_save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
