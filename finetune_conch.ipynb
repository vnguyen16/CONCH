{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from conch.open_clip_custom import create_model_from_pretrained, tokenize, get_tokenizer\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import skimage\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from huggingface_hub import login, hf_hub_download\n",
    "\n",
    "# show all jupyter output\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = Path('../').resolve()\n",
    "os.chdir(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONCHModelForFinetuning(nn.Module):\n",
    "    def __init__(self, num_classes=2, config={'hidden_size': 512}): # change number of classes for each dataset(8 for breast, 2 for breast)\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.model = self.make_conch()\n",
    "        # self.fc = nn.Linear(self.config['hidden_size'], num_classes) # full finetuning?\n",
    "\n",
    "        # linear probing\n",
    "        # Freeze all parameters in the backbone\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Only this linear layer will be trained\n",
    "        self.fc = nn.Linear(self.config['hidden_size'], num_classes)\n",
    "\n",
    "    def make_conch(self):\n",
    "        # Load the model from \"create_model_from_pretrained\"\n",
    "        model_cfg = 'conch_ViT-B-16'\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        # checkpoint_path = 'checkpoints/CONCH/pytorch_model.bin'\n",
    "        checkpoint_path = 'C:\\\\Users\\\\Vivian\\\\Documents\\\\CONCH\\\\checkpoints\\\\conch\\\\pytorch_model.bin' # load in checkpoint here\n",
    "        # checkpoint_path = r'C:\\Users\\Vivian\\Documents\\CONCH\\_finetune_weights\\Fold2_F_PT_model.pth' # loading breakhis finetuned model\n",
    "        model, preprocess = create_model_from_pretrained(model_cfg, checkpoint_path, device=device)\n",
    "        \n",
    "        return model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, h = self.model.visual(x)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CONCHModelForFinetuning().to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load breakhis (PT + FA) checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONCHModelForFinetuning(nn.Module):\n",
    "    def __init__(self, num_classes=2, config={'hidden_size': 512}, checkpoint_path=None):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.model = self.make_conch()\n",
    "        self.fc = nn.Linear(self.config['hidden_size'], num_classes)\n",
    "\n",
    "        if checkpoint_path is not None:\n",
    "            print(f\"Loading fine-tuned weights from: {checkpoint_path}\")\n",
    "            self.load_state_dict(torch.load(checkpoint_path, map_location='cuda'))\n",
    "\n",
    "    def make_conch(self):\n",
    "        # Load the base pretrained model\n",
    "        model_cfg = 'conch_ViT-B-16'\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        base_checkpoint = 'C:\\\\Users\\\\Vivian\\\\Documents\\\\CONCH\\\\checkpoints\\\\conch\\\\pytorch_model.bin'\n",
    "        model, _ = create_model_from_pretrained(model_cfg, base_checkpoint, device=device)\n",
    "        return model\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, h = self.model.visual(x)\n",
    "        return self.fc(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = r'C:\\Users\\Vivian\\Documents\\CONCH\\_finetune_weights\\Fold2_F_PT_model.pth'\n",
    "model = CONCHModelForFinetuning(num_classes=2, checkpoint_path=checkpoint_path).to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNI 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class UNI2ModelForFinetuning(nn.Module):\n",
    "    def __init__(self, num_classes=2): # change number of classes for each dataset\n",
    "        super().__init__()\n",
    "        # self.config = config\n",
    "        self.model = self.make_uni2()\n",
    "        # self.fc = nn.Linear(1536, num_classes)  # Match Vision Transformer output # full finetuning\n",
    "\n",
    "        # Freeze all backbone parameters for linear probing\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Add a small trainable classification head\n",
    "        self.fc = nn.Linear(1536, num_classes)  # Match Vision Transformer output\n",
    "\n",
    "    def make_uni2(self):\n",
    "        # # Load the model from \"create_model_from_pretrained\"\n",
    "        # model_cfg = 'conch_ViT-B-16'\n",
    "        # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        # # checkpoint_path = 'checkpoints/CONCH/pytorch_model.bin'\n",
    "        # checkpoint_path = 'C:\\\\Users\\\\Vivian\\\\Documents\\\\CONCH\\\\checkpoints\\\\conch\\\\pytorch_model.bin' # load in checkpoint here\n",
    "        # model, preprocess = create_model_from_pretrained(model_cfg, checkpoint_path, device=device)\n",
    "        \n",
    "        # return model\n",
    "\n",
    "        # local_dir = 'assets\\\\ckpts\\\\uni2-h'\n",
    "        local_dir = 'C:\\\\Users\\\\Vivian\\\\Documents\\\\UNI2\\\\UNI\\\\assets\\\\ckpts\\\\uni2-h' \n",
    "        os.makedirs(local_dir, exist_ok=True)  # create directory if it does not exist\n",
    "        # hf_hub_download(\"MahmoodLab/UNI2-h\", filename=\"pytorch_model.bin\", local_dir=local_dir, force_download=True)\n",
    "       \n",
    "        timm_kwargs = {\n",
    "        'model_name': 'vit_giant_patch14_224',\n",
    "        'img_size': 224, \n",
    "        'patch_size': 14, \n",
    "        'depth': 24,\n",
    "        'num_heads': 24,\n",
    "        'init_values': 1e-5, \n",
    "        'embed_dim': 1536,\n",
    "        'mlp_ratio': 2.66667*2,\n",
    "        'num_classes': 0, \n",
    "        'no_embed_class': True,\n",
    "        'mlp_layer': timm.layers.SwiGLUPacked, \n",
    "        'act_layer': torch.nn.SiLU, \n",
    "        'reg_tokens': 8, \n",
    "        'dynamic_img_size': True\n",
    "        }\n",
    "        model = timm.create_model(**timm_kwargs)\n",
    "        model.load_state_dict(torch.load(os.path.join(local_dir, \"pytorch_model.bin\"), map_location=\"cpu\"), strict=True)\n",
    "        # transform = transforms.Compose(\n",
    "        # [\n",
    "        # transforms.Resize(224),\n",
    "        # transforms.CenterCrop(224),\n",
    "        # transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        # ]\n",
    "        # )\n",
    "\n",
    "        return model \n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        # out, h = self.model.visual(x)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNI2ModelForFinetuning().to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import timm\n",
    "from huggingface_hub import login, hf_hub_download\n",
    "\n",
    "\n",
    "class UNIModelForFinetuning(nn.Module):\n",
    "    def __init__(self, num_classes=2,checkpoint_path=None): # change number of classes accordingly \n",
    "        ## ************ change for UNI ************\n",
    "        super().__init__()\n",
    "        # self.config = config\n",
    "        self.model = self.make_uni()\n",
    "        # self.fc = nn.Linear(self.config['hidden_size'], num_classes) # keep commented\n",
    "        # self.fc = nn.Linear(1024, num_classes)  # Match Vision Transformer output # full finetuning\n",
    "\n",
    "        #***** Freeze all backbone parameters - linear probing *****\n",
    "        for param in self.model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Add a trainable classification head\n",
    "        self.fc = nn.Linear(1024, num_classes)\n",
    "\n",
    "        # ----- Load checkpoint if needed -----\n",
    "        if checkpoint_path:\n",
    "            print(f\"Loading checkpoint from: {checkpoint_path}\")\n",
    "            self.load_state_dict(torch.load(checkpoint_path, map_location='cuda'))\n",
    "    \n",
    "    def make_uni(self):\n",
    "        # login()  # login with your User Access Token, found at https://huggingface.co/settings/tokens\n",
    "\n",
    "        local_dir = r\"C:\\Users\\Vivian\\Documents\\CONCH\\checkpoints\\uni\" # load in UNI model\n",
    "        os.makedirs(local_dir, exist_ok=True)  # create directory if it does not exist\n",
    "        \n",
    "        # hf_hub_download(\"MahmoodLab/UNI\", filename=\"pytorch_model.bin\", local_dir=local_dir, force_download=True)\n",
    "        model = timm.create_model(\n",
    "            \"vit_large_patch16_224\", img_size=224, patch_size=16, init_values=1e-5, num_classes=0, dynamic_img_size=True\n",
    "        )\n",
    "        model.load_state_dict(torch.load(os.path.join(local_dir, \"pytorch_model.bin\"), map_location=\"cpu\"), strict=True)\n",
    "        \n",
    "        # transform = transforms.Compose(\n",
    "        #     [\n",
    "        #         transforms.Resize(224),\n",
    "        #         transforms.ToTensor(),\n",
    "        #         transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "        #     ]\n",
    "        # )\n",
    "        # model.eval()\n",
    "        return model \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        # out, h = self.model.visual(x)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNIModelForFinetuning().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a checkpoint\n",
    "model = UNIModelForFinetuning(num_classes=2, checkpoint_path=r\"C:\\Users\\Vivian\\Documents\\CONCH\\_finetune_weights_UNI\\linprob_ann_CL_uni.pth\").to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Vivian\\anaconda3\\envs\\conch\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "# resnet = models.resnet18(pretrained=True) # resnet18\n",
    "resnet = models.resnet50(pretrained=True) # resnet50\n",
    "resnet.fc = nn.Linear(resnet.fc.in_features, 2)  # 2 output classes for CrossEntropyLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet.to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Making metadata -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves metadata to csv for each fold and mode - use this \n",
    "# need to make metadata for new datasets\n",
    "def make_metadata(fold):\n",
    "    metadata = pd.DataFrame()\n",
    "    for mode in ['train', 'test']:\n",
    "        pathname = f'/Users/Vivian/Documents/CONCH/Folds/Fold {fold}/{mode}/'\n",
    "        images = os.listdir(pathname)\n",
    "        for image in images:\n",
    "            if not image.startswith('SOB'):\n",
    "                continue\n",
    "            label = image.split('-')[0].replace('SOB_', '')\n",
    "            class_name, subclass_name = label.split('_')\n",
    "            #metadata = metadata.append({'image': pathname+image, 'fold': fold, 'mode': mode, 'class': class_name, 'subclass': subclass_name}, ignore_index=True)\n",
    "            metadata = pd.concat([metadata, pd.DataFrame({'image': pathname+image, 'fold': fold, 'mode': mode, 'class': class_name, 'subclass': subclass_name}, index=[0])], ignore_index=True)\n",
    "        metadata.to_csv(f'/Users/Vivian/Documents/CONCH/Folds/Fold {fold}/{mode}/metadata.csv', index=False)\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making metadata for our private dataset\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def make_metadata():\n",
    "    metadata = pd.DataFrame()\n",
    "    \n",
    "    # # Define paths\n",
    "    # base_path = \"patches\"  # Root where patches are stored\n",
    "    # metadata_dir = \"metadata\"  # Directory containing train/test CSVs\n",
    "    # output_dir = \"metadata/fine_tuning\"  # Where metadata CSVs will be saved\n",
    "    # os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # ***********Define paths for only test set\n",
    "    base_path = \"patches_annotated\"  # Root where patches are stored\n",
    "    metadata_dir = \"metadata\"  # Directory containing train/test CSVs\n",
    "    output_dir = \"metadata/fine_tuning\"  # Where metadata CSVs will be saved\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # ************\n",
    "\n",
    "    # Load train/test slide selections\n",
    "    # train_slides = pd.read_csv(os.path.join(metadata_dir, \"train_patient_split.csv\"))\n",
    "    test_slides = pd.read_csv(os.path.join(metadata_dir, \"test_ann_series8.csv\"))\n",
    "\n",
    "    # train_slides = pd.read_csv(os.path.join(metadata_dir, \"train_all_slides.csv\"))\n",
    "    # test_slides = pd.read_csv(os.path.join(metadata_dir, \"test_all_slides.csv\"))\n",
    "\n",
    "\n",
    "    # Process both train and test sets\n",
    "    # for mode, slides_df in zip([\"train\", \"test\"], [train_slides, test_slides]):\n",
    "    for mode, slides_df in zip([\"test\"], [test_slides]): # only creating test set\n",
    "\n",
    "        entries = []\n",
    "        \n",
    "        for _, row in slides_df.iterrows():\n",
    "            slide_name = row[\"Filename\"]\n",
    "            class_name = row[\"Class\"]\n",
    "            magnification = f\"{row['Magnification']}x\"\n",
    "\n",
    "            # Define the path where patches are stored for this slide\n",
    "            slide_patch_dir = os.path.join(base_path, magnification, class_name, slide_name)\n",
    "\n",
    "            # Ensure slide directory exists and has patches\n",
    "            if not os.path.exists(slide_patch_dir) or len(os.listdir(slide_patch_dir)) == 0:\n",
    "                print(f\"Skipping {slide_name}: No patches found.\")\n",
    "                continue\n",
    "            \n",
    "            # Add all patches in the slide directory to the metadata\n",
    "            for patch_file in os.listdir(slide_patch_dir):\n",
    "                if patch_file.endswith(\".npy\"):  # Ensure we're only adding valid patch files\n",
    "                    patch_path = os.path.join(slide_patch_dir, patch_file)\n",
    "                    entries.append({\n",
    "                        \"image\": patch_path,\n",
    "                        \"fold\": 1,  # Since you're using only one fold\n",
    "                        \"mode\": mode,\n",
    "                        \"class\": class_name,\n",
    "                        \"magnification\": magnification\n",
    "                    })\n",
    "\n",
    "        # Convert list to DataFrame\n",
    "        mode_metadata = pd.DataFrame(entries)\n",
    "\n",
    "        # output_csv = \n",
    "\n",
    "        # Save metadata CSV for the mode\n",
    "        mode_metadata.to_csv(os.path.join(output_dir, f\"{mode}_ann_series8_2.csv\"), index=False) # manually change metadata file name here\n",
    "\n",
    "        print(f\"Saved {mode}_ann_series8_2.csv with {len(mode_metadata)} entries.\")\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making metadata for our private dataset - train, val, test\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def make_metadata():\n",
    "    # === CONFIGURATION ===\n",
    "    annotated_base_path = r\"C:\\Users\\Vivian\\Documents\\CONCH\\patches_tiled\\patches_10x\"\n",
    "    # fallback_base_path = \"patches\"\n",
    "    metadata_dir = \"metadata/patient_split_annotate/slide_csv\"\n",
    "    output_dir = \"metadata/patient_split_annotate/patch_csv_10x\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Define your CSVs and the filenames for outputs\n",
    "    slide_sets = {\n",
    "        \"train\": {\n",
    "            \"input_csv\": os.path.join(metadata_dir, \"train_split.csv\"),\n",
    "            \"output_csv\": \"train_patches.csv\"\n",
    "        },\n",
    "        \"val\": {\n",
    "            \"input_csv\": os.path.join(metadata_dir, \"val_split.csv\"),\n",
    "            \"output_csv\": \"val_patches.csv\"\n",
    "        },\n",
    "        \"test\": {\n",
    "            \"input_csv\": os.path.join(metadata_dir, \"test_split.csv\"),\n",
    "            \"output_csv\": \"test_patches.csv\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # === PROCESS EACH SET ===\n",
    "    for mode, paths in slide_sets.items():\n",
    "        slides_df = pd.read_csv(paths[\"input_csv\"])\n",
    "        entries = []\n",
    "\n",
    "        for _, row in slides_df.iterrows():\n",
    "            slide_name = row[\"Filename\"]\n",
    "            class_name = row[\"Class\"]\n",
    "            magnification = f\"{row['Magnification']}x\"\n",
    "\n",
    "            # Try annotated path first\n",
    "            slide_patch_dir = os.path.join(annotated_base_path, magnification, class_name, slide_name)\n",
    "            if not os.path.exists(slide_patch_dir) or len(os.listdir(slide_patch_dir)) == 0:\n",
    "                print(f\"[{mode}] Skipping {slide_name}: No patches found in annotated path.\")\n",
    "                continue\n",
    "\n",
    "            # # Fallback to regular patches if needed\n",
    "            # if not os.path.exists(slide_patch_dir) or len(os.listdir(slide_patch_dir)) == 0:\n",
    "            #     slide_patch_dir = os.path.join(fallback_base_path, magnification, class_name, slide_name)\n",
    "            #     if not os.path.exists(slide_patch_dir) or len(os.listdir(slide_patch_dir)) == 0:\n",
    "            #         print(f\"[{mode}] Skipping {slide_name}: No patches found in either location.\")\n",
    "            #         continue\n",
    "\n",
    "            # Collect patch metadata\n",
    "            for patch_file in os.listdir(slide_patch_dir):\n",
    "                if patch_file.endswith(\".npy\"):\n",
    "                    patch_path = os.path.join(slide_patch_dir, patch_file)\n",
    "                    entries.append({\n",
    "                        \"image\": patch_path,\n",
    "                        \"fold\": 1,\n",
    "                        \"mode\": mode,\n",
    "                        \"class\": class_name,\n",
    "                        \"magnification\": magnification\n",
    "                    })\n",
    "\n",
    "        # Save metadata to CSV\n",
    "        mode_metadata = pd.DataFrame(entries)\n",
    "        output_csv_path = os.path.join(output_dir, paths[\"output_csv\"])\n",
    "        mode_metadata.to_csv(output_csv_path, index=False)\n",
    "        print(f\"[{mode}] Saved {paths['output_csv']} with {len(mode_metadata)} entries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Saved train_patches.csv with 1044596 entries.\n",
      "[val] Saved val_patches.csv with 289282 entries.\n",
      "[test] Saved test_patches.csv with 203137 entries.\n"
     ]
    }
   ],
   "source": [
    "make_metadata() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "class HistopathologyDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.label_map = {\n",
    "            'B_A': 0,\n",
    "            'B_F': 1,\n",
    "            'B_PT': 2,\n",
    "            'B_TA': 3,\n",
    "            'M_DC': 4,\n",
    "            'M_LC': 5,\n",
    "            'M_MC': 6,\n",
    "            'M_PC': 7\n",
    "        }  # Example mapping of subclasses to numerical labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx]['image']\n",
    "        class_name = self.data.iloc[idx]['class']\n",
    "        subclass_name = self.data.iloc[idx]['subclass']\n",
    "        label = self.label_map[class_name + '_' + subclass_name]\n",
    "        image = plt.imread(img_path)\n",
    "        image = skimage.transform.resize(image, (224, 224))\n",
    "        image = image.transpose((2, 0, 1))\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using breakhis dataset but only with 2 classes FA and PT \n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class HistopathologyDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "        self.label_map = {\n",
    "            'B_F': 0,   # Fibroadenoma → Class 0\n",
    "            'B_PT': 1   # Phyllodes Tumor → Class 1\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.data.iloc[idx]['image']\n",
    "        class_name = self.data.iloc[idx]['class']\n",
    "        subclass_name = self.data.iloc[idx]['subclass']\n",
    "\n",
    "        # Map \"B_F\" -> 0, \"B_PT\" -> 1\n",
    "        label = self.label_map[class_name + '_' + subclass_name]\n",
    "\n",
    "        # Load and preprocess image\n",
    "        image = plt.imread(img_path)\n",
    "        image = skimage.transform.resize(image, (224, 224))\n",
    "        image = image.transpose((2, 0, 1))  # Convert to C x H x W for PyTorch\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated dataset class for our private dataset with numpy files\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class HistopathologyDataset(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        \"\"\"\n",
    "        Custom PyTorch Dataset for loading histopathology patches from .npy files.\n",
    "        \n",
    "        Args:\n",
    "            csv_file (str): Path to the dataset metadata CSV file.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "        # Mapping FA -> 0, PT -> 1\n",
    "        self.label_map = {'FA': 0, 'PT': 1}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image patch\n",
    "        img_path = self.data.iloc[idx]['image']\n",
    "        image = np.load(img_path)  # Load .npy file (already in NumPy format)\n",
    "\n",
    "        # Ensure image is in (C, H, W) format for PyTorch\n",
    "        if image.shape[-1] == 3:  # Check if image is in (H, W, C) format\n",
    "            image = np.transpose(image, (2, 0, 1))  # Convert to (C, H, W)\n",
    "\n",
    "        # Resize to 224x224 if needed\n",
    "        if image.shape[1] != 224 or image.shape[2] != 224:\n",
    "            import skimage.transform\n",
    "            image = skimage.transform.resize(image, (3, 224, 224), anti_aliasing=True)\n",
    "        \n",
    "        # Normalize pixel values\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "\n",
    "        # Apply transformations if provided\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Get label\n",
    "        class_name = self.data.iloc[idx]['class']\n",
    "        label = self.label_map[class_name]  # Convert class name to label\n",
    "\n",
    "        return image, label, img_path\n",
    "        # return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "right now, we are only using the first fold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = HistopathologyDataset('/Users/Vivian/Documents/CONCH/Folds/Fold 1/train/metadata.csv')\n",
    "# test_data = HistopathologyDataset('/Users/Vivian/Documents/CONCH/Folds/Fold 1/test/metadata.csv')\n",
    "\n",
    "# early results --> pick one fold \n",
    "# pick a fold to train and test\n",
    "\n",
    "train_data = HistopathologyDataset('/Users/Vivian/Documents/CONCH/Folds/Fold 2/train/metadata.csv')\n",
    "test_data = HistopathologyDataset('/Users/Vivian/Documents/CONCH/Folds/Fold 2/test/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataloder for me please \n",
    "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instantiating train and test set for private data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example usage\n",
    "# subset of slides\n",
    "# train_dataset = HistopathologyDataset(\"metadata/fine_tuning/train_metadata.csv\")\n",
    "# test_dataset = HistopathologyDataset(\"metadata/fine_tuning/test_metadata.csv\")\n",
    "\n",
    "# testing with all slides successfully tiled\n",
    "# train_dataset = HistopathologyDataset(\"metadata\\\\fine_tuning\\\\train_patient_split_metadata.csv\")\n",
    "# test_dataset = HistopathologyDataset(\"metadata\\\\fine_tuning\\\\test_patient_split_metadata.csv\")\n",
    "\n",
    "# adding val set\n",
    "# train_dataset = HistopathologyDataset(\"metadata\\\\patient_split_annotate\\\\patch_csv\\\\train_cleaned_CL_patches.csv\")\n",
    "train_dataset = HistopathologyDataset(r\"C:\\Users\\Vivian\\Documents\\CONCH\\metadata\\patient_split_annotate\\patch_csv_2.5x\\train_patches.csv\")\n",
    "# val_dataset = HistopathologyDataset(\"metadata\\\\patient_split_annotate\\\\patch_csv\\\\val_cleaned_CL_patches.csv\")\n",
    "val_dataset = HistopathologyDataset(r\"C:\\Users\\Vivian\\Documents\\CONCH\\metadata\\patient_split_annotate\\patch_csv_2.5x\\val_patches.csv\")\n",
    "test_dataset = HistopathologyDataset(r\"C:\\Users\\Vivian\\Documents\\CONCH\\metadata\\patient_split_annotate\\patch_csv_2.5x\\test_patches.csv\")\n",
    "\n",
    "# Check dataset sample\n",
    "# sample_image, sample_label = train_dataset[0]\n",
    "# print(\"Image shape:\", sample_image.shape)\n",
    "# print(\"Label:\", sample_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataloder \n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNI with validation set + training curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Setup\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Only optimize the classification head (linear layer) - for linear probing\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-5)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = 'cuda'\n",
    "num_epochs = 10\n",
    "patience = 5\n",
    "\n",
    "# model_save_path = '/Users/Vivian/Documents/CONCH/_finetune_weights_CONCH/with_val_earlystop.pth'\n",
    "# csv_save_path = \"/Users/Vivian/Documents/CONCH/patch_predictions/with_val_earlystop.csv\"\n",
    "\n",
    "# Define model save path\n",
    "model_save_path = \"/Users/Vivian/Documents/CONCH/_finetune_weights_UNI/linprob_ann_cleanlearning.pth\"\n",
    "# Define CSV path for saving patch predictions\n",
    "csv_save_path = \"patch_predictions/annotated/UNI_linprob_ann_cleanlearning.csv\"\n",
    "\n",
    "best_val_accuracy = 0\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# Mixed Precision\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Metrics tracking\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    correct_train, total_train = 0, 0\n",
    "    all_train_labels, all_train_preds = [], []\n",
    "\n",
    "    for images, labels, _ in tqdm.tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "        all_train_labels.extend(labels.cpu().numpy())\n",
    "        all_train_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # print(f\"Train Loss: {avg_train_loss:.4f} | Accuracy: {train_accuracy:.4f}\")\n",
    "    train_precision = precision_score(all_train_labels, all_train_preds, average=\"binary\")\n",
    "    train_recall = recall_score(all_train_labels, all_train_preds, average=\"binary\")\n",
    "    train_f1 = f1_score(all_train_labels, all_train_preds, average=\"binary\")\n",
    "\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Accuracy: {train_accuracy:.4f} | \"\n",
    "        f\"Precision: {train_precision:.4f} | Recall: {train_recall:.4f} | F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    correct_val, total_val = 0, 0\n",
    "    all_val_labels, all_val_preds = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in tqdm.tqdm(val_loader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "            all_val_labels.extend(labels.cpu().numpy())\n",
    "            all_val_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_accuracy = correct_val / total_val\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    val_precision = precision_score(all_val_labels, all_val_preds, average=\"binary\")\n",
    "    val_recall = recall_score(all_val_labels, all_val_preds, average=\"binary\")\n",
    "    val_f1 = f1_score(all_val_labels, all_val_preds, average=\"binary\")\n",
    "\n",
    "    print(f\"Val Loss: {avg_val_loss:.4f} | Accuracy: {val_accuracy:.4f} | \"\n",
    "          f\"Precision: {val_precision:.4f} | Recall: {val_recall:.4f} | F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "    # --- Early Stopping ---\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"✅ Model saved with improved val accuracy: {val_accuracy:.4f}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No improvement for {epochs_no_improve} epoch(s)\")\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"⏹️ Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# --- Plotting ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Val Accuracy')\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Final Test Evaluation ---\n",
    "print(\"\\n🔍 Evaluating best model on the test set...\")\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.eval()\n",
    "\n",
    "total_test_loss = 0\n",
    "correct_test, total_test = 0, 0\n",
    "all_test_labels, all_test_preds = [], []\n",
    "test_predictions_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, file_paths in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "        total_test += labels.size(0)\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "        all_test_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        for i in range(labels.size(0)):\n",
    "            test_predictions_list.append([file_paths[i], predicted[i].item(), labels[i].item()])\n",
    "\n",
    "avg_test_loss = total_test_loss / len(test_loader)\n",
    "test_accuracy = correct_test / total_test\n",
    "test_precision = precision_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "test_recall = recall_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "test_f1 = f1_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "\n",
    "print(f\"\\n📊 Final Test Results:\\n\"\n",
    "      f\"Test Loss: {avg_test_loss:.4f} | Accuracy: {test_accuracy:.4f} | \"\n",
    "      f\"Precision: {test_precision:.4f} | Recall: {test_recall:.4f} | F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "# Save test predictions\n",
    "test_csv_path = csv_save_path.replace(\".csv\", \"_test.csv\")\n",
    "df_test = pd.DataFrame(test_predictions_list, columns=[\"Patch Path\", \"Predicted\", \"True Label\"])\n",
    "df_test.to_csv(test_csv_path, index=False)\n",
    "print(f\"✅ Test predictions saved to: {test_csv_path}\")\n",
    "\n",
    "# --- Save metrics summary to CSV ---\n",
    "metrics = {\n",
    "    \"Epochs Trained\": len(train_losses),\n",
    "    \"Best Val Accuracy\": best_val_accuracy,\n",
    "    \n",
    "    # Final epoch training metrics\n",
    "    \"Train Loss\": train_losses[-1],\n",
    "    \"Train Accuracy\": train_accuracy,\n",
    "    \"Train Precision\": train_precision,\n",
    "    \"Train Recall\": train_recall,\n",
    "    \"Train F1 Score\": train_f1,\n",
    "\n",
    "    # Final epoch validation metrics\n",
    "    \"Val Loss\": avg_val_loss,\n",
    "    \"Val Accuracy\": val_accuracy,\n",
    "    \"Val Precision\": val_precision,\n",
    "    \"Val Recall\": val_recall,\n",
    "    \"Val F1 Score\": val_f1,\n",
    "\n",
    "    # Final test metrics\n",
    "    \"Test Loss\": avg_test_loss,\n",
    "    \"Test Accuracy\": test_accuracy,\n",
    "    \"Test Precision\": test_precision,\n",
    "    \"Test Recall\": test_recall,\n",
    "    \"Test F1 Score\": test_f1\n",
    "}\n",
    "\n",
    "# Save as CSV (one row)\n",
    "summary_path = csv_save_path.replace(\".csv\", \"_metrics_summary.csv\")\n",
    "pd.DataFrame([metrics]).to_csv(summary_path, index=False)\n",
    "print(f\"📁 Metrics summary saved to: {summary_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNI - Cleanlab issues patches - run2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_14764\\843638373.py:38: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/130575 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_14764\\843638373.py:59: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 130575/130575 [2:11:34<00:00, 16.54it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6337 | Accuracy: 0.6321 | Precision: 0.6488 | Recall: 0.7395 | F1 Score: 0.6912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/36161 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_14764\\843638373.py:102: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 36161/36161 [31:20<00:00, 19.23it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6600 | Accuracy: 0.6082 | Precision: 0.6264 | Recall: 0.6863 | F1 Score: 0.6550\n",
      "✅ Model saved with improved val accuracy: 0.6082\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/130575 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_14764\\843638373.py:59: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 130575/130575 [2:13:10<00:00, 16.34it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6249 | Accuracy: 0.6423 | Precision: 0.6603 | Recall: 0.7361 | F1 Score: 0.6961\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/36161 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_14764\\843638373.py:102: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 36161/36161 [35:09<00:00, 17.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6614 | Accuracy: 0.6076 | Precision: 0.6358 | Recall: 0.6459 | F1 Score: 0.6408\n",
      "No improvement for 1 epoch(s)\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/130575 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_14764\\843638373.py:59: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 130575/130575 [2:13:55<00:00, 16.25it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6214 | Accuracy: 0.6468 | Precision: 0.6648 | Recall: 0.7372 | F1 Score: 0.6991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/36161 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_14764\\843638373.py:102: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 36161/36161 [35:03<00:00, 17.19it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6639 | Accuracy: 0.6066 | Precision: 0.6407 | Recall: 0.6245 | F1 Score: 0.6325\n",
      "No improvement for 2 epoch(s)\n",
      "\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/130575 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_14764\\843638373.py:59: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 130575/130575 [2:13:25<00:00, 16.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6182 | Accuracy: 0.6497 | Precision: 0.6679 | Recall: 0.7371 | F1 Score: 0.7008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/36161 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_14764\\843638373.py:102: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 36161/36161 [35:00<00:00, 17.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6623 | Accuracy: 0.6109 | Precision: 0.6676 | Recall: 0.5620 | F1 Score: 0.6102\n",
      "✅ Model saved with improved val accuracy: 0.6109\n",
      "\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/130575 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_14764\\843638373.py:59: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 130575/130575 [2:12:55<00:00, 16.37it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6173 | Accuracy: 0.6508 | Precision: 0.6692 | Recall: 0.7369 | F1 Score: 0.7015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/36161 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_14764\\843638373.py:102: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 36161/36161 [35:13<00:00, 17.11it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6693 | Accuracy: 0.6078 | Precision: 0.6105 | Recall: 0.7638 | F1 Score: 0.6786\n",
      "No improvement for 1 epoch(s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x500 with 0 Axes>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c3e14d6320>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c3e14d65c0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss Curve')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c3090d1990>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c3e14d78e0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c34e70c6d0>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy Curve')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c3e8eeb760>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Evaluating best model on the test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_14764\\843638373.py:177: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_save_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 25393/25393 [24:54<00:00, 16.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Final Test Results:\n",
      "Test Loss: 0.6516 | Accuracy: 0.6301 | Precision: 0.2650 | Recall: 0.3985 | F1 Score: 0.3183\n",
      "✅ Test predictions saved to: patch_predictions/10x\\ResNet50_linprob_test.csv\n",
      "📊 Epoch metrics saved to: patch_predictions/10x\\ResNet50_linprob_epoch_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Setup\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Only optimize the classification head (linear layer) - for linear probing\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=2e-5) # increased learning rate\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = 'cuda'\n",
    "num_epochs = 5\n",
    "patience = 5\n",
    "\n",
    "# model_save_path = '/Users/Vivian/Documents/CONCH/_finetune_weights_CONCH/with_val_earlystop.pth'\n",
    "# csv_save_path = \"/Users/Vivian/Documents/CONCH/patch_predictions/with_val_earlystop.csv\"\n",
    "\n",
    "# Define model save path \n",
    "model_dir = \"/Users/Vivian/Documents/CONCH/_finetune_weights_ResNet50/10x\"\n",
    "# Define CSV path for saving patch predictions\n",
    "csv_dir = \"patch_predictions/10x\"\n",
    "\n",
    "# check for model save path directory \n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "model_save_path = os.path.join(model_dir, \"linprob.pth\") # change model name here\n",
    "# check for csv save path directory \n",
    "os.makedirs(csv_dir, exist_ok=True)\n",
    "csv_save_path = os.path.join(csv_dir, \"ResNet50_linprob.csv\") # change prediction csv name here\n",
    "\n",
    "\n",
    "best_val_accuracy = 0\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# Mixed Precision\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Metrics tracking\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "# Store per-epoch metrics as a list of dicts\n",
    "epoch_metrics = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    correct_train, total_train = 0, 0\n",
    "    all_train_labels, all_train_preds = [], []\n",
    "\n",
    "    for images, labels, _ in tqdm.tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1) # without softmax (auroc)\n",
    "\n",
    "        # probs = torch.softmax(outputs, dim=1)[:, 1]  # probability for class 1\n",
    "        # _, predicted = torch.max(outputs, 1)    \n",
    "\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "        all_train_labels.extend(labels.cpu().numpy())\n",
    "        all_train_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # print(f\"Train Loss: {avg_train_loss:.4f} | Accuracy: {train_accuracy:.4f}\")\n",
    "    train_precision = precision_score(all_train_labels, all_train_preds, average=\"binary\")\n",
    "    train_recall = recall_score(all_train_labels, all_train_preds, average=\"binary\")\n",
    "    train_f1 = f1_score(all_train_labels, all_train_preds, average=\"binary\")\n",
    "\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Accuracy: {train_accuracy:.4f} | \"\n",
    "        f\"Precision: {train_precision:.4f} | Recall: {train_recall:.4f} | F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    correct_val, total_val = 0, 0\n",
    "    all_val_labels, all_val_preds = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in tqdm.tqdm(val_loader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "            all_val_labels.extend(labels.cpu().numpy())\n",
    "            all_val_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_accuracy = correct_val / total_val\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    val_precision = precision_score(all_val_labels, all_val_preds, average=\"binary\")\n",
    "    val_recall = recall_score(all_val_labels, all_val_preds, average=\"binary\")\n",
    "    val_f1 = f1_score(all_val_labels, all_val_preds, average=\"binary\")\n",
    "\n",
    "    print(f\"Val Loss: {avg_val_loss:.4f} | Accuracy: {val_accuracy:.4f} | \"\n",
    "          f\"Precision: {val_precision:.4f} | Recall: {val_recall:.4f} | F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "\n",
    "    # Collect metrics for this epoch\n",
    "    epoch_metrics.append({\n",
    "        \"Epoch\": epoch + 1,\n",
    "        \"Train Loss\": avg_train_loss,\n",
    "        \"Train Accuracy\": train_accuracy,\n",
    "        \"Train Precision\": train_precision,\n",
    "        \"Train Recall\": train_recall,\n",
    "        \"Train F1 Score\": train_f1,\n",
    "        \"Val Loss\": avg_val_loss,\n",
    "        \"Val Accuracy\": val_accuracy,\n",
    "        \"Val Precision\": val_precision,\n",
    "        \"Val Recall\": val_recall,\n",
    "        \"Val F1 Score\": val_f1\n",
    "    })\n",
    "\n",
    "\n",
    "    # --- Early Stopping ---\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"✅ Model saved with improved val accuracy: {val_accuracy:.4f}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No improvement for {epochs_no_improve} epoch(s)\")\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"⏹️ Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# --- Plotting ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Val Accuracy')\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Final Test Evaluation ---\n",
    "print(\"\\n🔍 Evaluating best model on the test set...\")\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.eval()\n",
    "\n",
    "total_test_loss = 0\n",
    "correct_test, total_test = 0, 0\n",
    "all_test_labels, all_test_preds = [], []\n",
    "test_predictions_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, file_paths in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "        total_test += labels.size(0)\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "        all_test_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        for i in range(labels.size(0)):\n",
    "            test_predictions_list.append([file_paths[i], predicted[i].item(), labels[i].item()])\n",
    "\n",
    "avg_test_loss = total_test_loss / len(test_loader)\n",
    "test_accuracy = correct_test / total_test\n",
    "test_precision = precision_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "test_recall = recall_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "test_f1 = f1_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "\n",
    "print(f\"\\n📊 Final Test Results:\\n\"\n",
    "      f\"Test Loss: {avg_test_loss:.4f} | Accuracy: {test_accuracy:.4f} | \"\n",
    "      f\"Precision: {test_precision:.4f} | Recall: {test_recall:.4f} | F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "# Save test predictions\n",
    "test_csv_path = csv_save_path.replace(\".csv\", \"_test.csv\")\n",
    "df_test = pd.DataFrame(test_predictions_list, columns=[\"Patch Path\", \"Predicted\", \"True Label\"])\n",
    "df_test.to_csv(test_csv_path, index=False)\n",
    "print(f\"✅ Test predictions saved to: {test_csv_path}\")\n",
    "\n",
    "# --- Append summary row ---\n",
    "summary_row = {\n",
    "    \"Epoch\": \"Best Val\",\n",
    "    \"Train Loss\": \"\",\n",
    "    \"Train Accuracy\": \"\",\n",
    "    \"Train Precision\": \"\",\n",
    "    \"Train Recall\": \"\",\n",
    "    \"Train F1 Score\": \"\",\n",
    "    \"Val Loss\": \"\",\n",
    "    \"Val Accuracy\": best_val_accuracy,\n",
    "    \"Val Precision\": \"\",\n",
    "    \"Val Recall\": \"\",\n",
    "    \"Val F1 Score\": \"\",\n",
    "    \"Test Loss\": avg_test_loss,\n",
    "    \"Test Accuracy\": test_accuracy,\n",
    "    \"Test Precision\": test_precision,\n",
    "    \"Test Recall\": test_recall,\n",
    "    \"Test F1 Score\": test_f1\n",
    "}\n",
    "epoch_metrics.append(summary_row)\n",
    "\n",
    "\n",
    "metrics_df = pd.DataFrame(epoch_metrics)\n",
    "metrics_csv_path = csv_save_path.replace(\".csv\", \"_epoch_metrics.csv\")\n",
    "metrics_df.to_csv(metrics_csv_path, index=False)\n",
    "print(f\"📊 Epoch metrics saved to: {metrics_csv_path}\")\n",
    "\n",
    "# # Save as CSV (one row)\n",
    "# summary_path = csv_save_path.replace(\".csv\", \"_metrics_summary.csv\")\n",
    "# pd.DataFrame([metrics]).to_csv(summary_path, index=False)\n",
    "# print(f\"📁 Metrics summary saved to: {summary_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Final Test Evaluation ---\n",
    "print(\"\\n🔍 Evaluating best model on the test set...\")\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.eval()\n",
    "\n",
    "total_test_loss = 0\n",
    "correct_test, total_test = 0, 0\n",
    "all_test_labels, all_test_preds = [], []\n",
    "test_predictions_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, file_paths in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "        total_test += labels.size(0)\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "        all_test_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        for i in range(labels.size(0)):\n",
    "            test_predictions_list.append([file_paths[i], predicted[i].item(), labels[i].item()])\n",
    "\n",
    "avg_test_loss = total_test_loss / len(test_loader)\n",
    "test_accuracy = correct_test / total_test\n",
    "test_precision = precision_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "test_recall = recall_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "test_f1 = f1_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "\n",
    "print(f\"\\n📊 Final Test Results:\\n\"\n",
    "      f\"Test Loss: {avg_test_loss:.4f} | Accuracy: {test_accuracy:.4f} | \"\n",
    "      f\"Precision: {test_precision:.4f} | Recall: {test_recall:.4f} | F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "# Save test predictions\n",
    "test_csv_path = csv_save_path.replace(\".csv\", \"_test.csv\")\n",
    "df_test = pd.DataFrame(test_predictions_list, columns=[\"Patch Path\", \"Predicted\", \"True Label\"])\n",
    "df_test.to_csv(test_csv_path, index=False)\n",
    "print(f\"✅ Test predictions saved to: {test_csv_path}\")\n",
    "\n",
    "# --- Append summary row ---\n",
    "summary_row = {\n",
    "    \"Epoch\": \"Best Val\",\n",
    "    \"Train Loss\": \"\",\n",
    "    \"Train Accuracy\": \"\",\n",
    "    \"Train Precision\": \"\",\n",
    "    \"Train Recall\": \"\",\n",
    "    \"Train F1 Score\": \"\",\n",
    "    \"Val Loss\": \"\",\n",
    "    \"Val Accuracy\": best_val_accuracy,\n",
    "    \"Val Precision\": \"\",\n",
    "    \"Val Recall\": \"\",\n",
    "    \"Val F1 Score\": \"\",\n",
    "    \"Test Loss\": avg_test_loss,\n",
    "    \"Test Accuracy\": test_accuracy,\n",
    "    \"Test Precision\": test_precision,\n",
    "    \"Test Recall\": test_recall,\n",
    "    \"Test F1 Score\": test_f1\n",
    "}\n",
    "epoch_metrics.append(summary_row)\n",
    "\n",
    "\n",
    "metrics_df = pd.DataFrame(epoch_metrics)\n",
    "metrics_csv_path = csv_save_path.replace(\".csv\", \"_epoch_metrics.csv\")\n",
    "metrics_df.to_csv(metrics_csv_path, index=False)\n",
    "print(f\"📊 Epoch metrics saved to: {metrics_csv_path}\")\n",
    "\n",
    "# # Save as CSV (one row)\n",
    "# summary_path = csv_save_path.replace(\".csv\", \"_metrics_summary.csv\")\n",
    "# pd.DataFrame([metrics]).to_csv(summary_path, index=False)\n",
    "# print(f\"📁 Metrics summary saved to: {summary_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using wandb.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvnguyen16\u001b[0m (\u001b[33mvnguyen16-queen-s-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\Vivian\\Documents\\CONCH\\wandb\\run-20250615_135238-tvg8af0f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vnguyen16-queen-s-university/resnet50_finetuning/runs/tvg8af0f' target=\"_blank\">linprob_2.5x</a></strong> to <a href='https://wandb.ai/vnguyen16-queen-s-university/resnet50_finetuning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vnguyen16-queen-s-university/resnet50_finetuning' target=\"_blank\">https://wandb.ai/vnguyen16-queen-s-university/resnet50_finetuning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vnguyen16-queen-s-university/resnet50_finetuning/runs/tvg8af0f' target=\"_blank\">https://wandb.ai/vnguyen16-queen-s-university/resnet50_finetuning/runs/tvg8af0f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/vnguyen16-queen-s-university/resnet50_finetuning/runs/tvg8af0f?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1be7175d000>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_30164\\633093808.py:35: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/13559 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_30164\\633093808.py:54: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 13559/13559 [13:28<00:00, 16.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6419 | Acc: 0.6169 | Prec: 0.6328 | Rec: 0.7408 | F1: 0.6826 | AUROC: 0.6675\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/3740 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_30164\\633093808.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 3740/3740 [03:47<00:00, 16.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6367 | Acc: 0.6322 | Prec: 0.6451 | Rec: 0.7135 | F1: 0.6776 | AUROC: 0.6796\n",
      "✅ Saved best model\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/13559 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_30164\\633093808.py:54: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 13559/13559 [11:54<00:00, 18.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6252 | Acc: 0.6360 | Prec: 0.6554 | Rec: 0.7281 | F1: 0.6899 | AUROC: 0.6942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/3740 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_30164\\633093808.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 3740/3740 [03:25<00:00, 18.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6452 | Acc: 0.6305 | Prec: 0.6275 | Rec: 0.7826 | F1: 0.6965 | AUROC: 0.6760\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/13559 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_30164\\633093808.py:54: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Training: 100%|██████████| 13559/13559 [10:02<00:00, 22.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6191 | Acc: 0.6424 | Prec: 0.6625 | Rec: 0.7272 | F1: 0.6933 | AUROC: 0.7030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation:   0%|          | 0/3740 [00:00<?, ?it/s]C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_30164\\633093808.py:91: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "Validation: 100%|██████████| 3740/3740 [03:09<00:00, 19.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.6433 | Acc: 0.6276 | Prec: 0.6333 | Rec: 0.7422 | F1: 0.6835 | AUROC: 0.6750\n",
      "📊 Saved metrics to: patch_predictions/wandb_2.5x\\ResNet50_linprob_epoch_metrics.csv\n",
      "\n",
      "🔍 Evaluating best model on the test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_30164\\633093808.py:169: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_save_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/2614 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'i' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 193\u001b[0m\n\u001b[0;32m    191\u001b[0m all_test_preds\u001b[38;5;241m.\u001b[39mextend(probs\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())  \u001b[38;5;66;03m# For AUROC\u001b[39;00m\n\u001b[0;32m    192\u001b[0m all_test_labels\u001b[38;5;241m.\u001b[39mextend(labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m--> 193\u001b[0m test_predictions_list\u001b[38;5;241m.\u001b[39mappend([file_paths[\u001b[43mi\u001b[49m], \u001b[38;5;28mint\u001b[39m(predicted[i]), \u001b[38;5;28mint\u001b[39m(labels[i])])\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)):\n\u001b[0;32m    196\u001b[0m     test_predictions_list\u001b[38;5;241m.\u001b[39mappend([file_paths[i], predicted[i]\u001b[38;5;241m.\u001b[39mitem(), labels[i]\u001b[38;5;241m.\u001b[39mitem()])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'i' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Initialize Weights & Biases\n",
    "wandb.init(project=\"resnet50_finetuning\", name=\"linprob_2.5x\", config={\n",
    "    \"epochs\": 3,\n",
    "    \"lr\": 2e-5,\n",
    "    \"model\": \"ResNet50\",\n",
    "    \"task\": \"linear_probing\",\n",
    "    \"magnification\": \"2.5x\"\n",
    "})\n",
    "\n",
    "# Optimizer setup\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=wandb.config.lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = 'cuda'\n",
    "num_epochs = wandb.config.epochs\n",
    "patience = 5\n",
    "\n",
    "# Paths\n",
    "model_dir = \"/Users/Vivian/Documents/CONCH/_finetune_weights_ResNet50/wandb_2.5x\"\n",
    "csv_dir = \"patch_predictions/wandb_2.5x\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "os.makedirs(csv_dir, exist_ok=True)\n",
    "\n",
    "model_save_path = os.path.join(model_dir, \"linprob.pth\")\n",
    "csv_save_path = os.path.join(csv_dir, \"ResNet50_linprob.csv\")\n",
    "\n",
    "# Mixed Precision\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Metrics tracking\n",
    "best_val_accuracy = 0\n",
    "epochs_no_improve = 0\n",
    "epoch_metrics = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    correct_train, total_train = 0, 0\n",
    "    all_train_labels, all_train_preds, all_train_probs = [], [], []\n",
    "\n",
    "    for images, labels, _ in tqdm.tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "        all_train_labels.extend(labels.cpu().numpy())\n",
    "        all_train_preds.extend(predicted.cpu().numpy())\n",
    "        all_train_probs.extend(probs.detach().cpu().numpy())\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_precision = precision_score(all_train_labels, all_train_preds)\n",
    "    train_recall = recall_score(all_train_labels, all_train_preds)\n",
    "    train_f1 = f1_score(all_train_labels, all_train_preds)\n",
    "    train_auroc = roc_auc_score(all_train_labels, all_train_probs)\n",
    "\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Acc: {train_accuracy:.4f} | \"\n",
    "          f\"Prec: {train_precision:.4f} | Rec: {train_recall:.4f} | F1: {train_f1:.4f} | AUROC: {train_auroc:.4f}\")\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    correct_val, total_val = 0, 0\n",
    "    all_val_labels, all_val_preds, all_val_probs = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in tqdm.tqdm(val_loader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "            probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "            all_val_labels.extend(labels.cpu().numpy())\n",
    "            all_val_preds.extend(predicted.cpu().numpy())\n",
    "            all_val_probs.extend(probs.detach().cpu().numpy())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_accuracy = correct_val / total_val\n",
    "    val_precision = precision_score(all_val_labels, all_val_preds)\n",
    "    val_recall = recall_score(all_val_labels, all_val_preds)\n",
    "    val_f1 = f1_score(all_val_labels, all_val_preds)\n",
    "    val_auroc = roc_auc_score(all_val_labels, all_val_probs)\n",
    "\n",
    "    print(f\"Val Loss: {avg_val_loss:.4f} | Acc: {val_accuracy:.4f} | \"\n",
    "          f\"Prec: {val_precision:.4f} | Rec: {val_recall:.4f} | F1: {val_f1:.4f} | AUROC: {val_auroc:.4f}\")\n",
    "\n",
    "    # Log to wandb\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train/loss\": avg_train_loss,\n",
    "        \"train/accuracy\": train_accuracy,\n",
    "        \"train/precision\": train_precision,\n",
    "        \"train/recall\": train_recall,\n",
    "        \"train/f1\": train_f1,\n",
    "        \"train/auroc\": train_auroc,\n",
    "        \"val/loss\": avg_val_loss,\n",
    "        \"val/accuracy\": val_accuracy,\n",
    "        \"val/precision\": val_precision,\n",
    "        \"val/recall\": val_recall,\n",
    "        \"val/f1\": val_f1,\n",
    "        \"val/auroc\": val_auroc,\n",
    "    })\n",
    "\n",
    "    # Save best model\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(\"✅ Saved best model\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"⏹️ Early stopping triggered\")\n",
    "            break\n",
    "\n",
    "    epoch_metrics.append({\n",
    "        \"Epoch\": epoch + 1,\n",
    "        \"Train Loss\": avg_train_loss,\n",
    "        \"Train Accuracy\": train_accuracy,\n",
    "        \"Train Precision\": train_precision,\n",
    "        \"Train Recall\": train_recall,\n",
    "        \"Train F1 Score\": train_f1,\n",
    "        \"Train AUROC\": train_auroc,\n",
    "        \"Val Loss\": avg_val_loss,\n",
    "        \"Val Accuracy\": val_accuracy,\n",
    "        \"Val Precision\": val_precision,\n",
    "        \"Val Recall\": val_recall,\n",
    "        \"Val F1 Score\": val_f1,\n",
    "        \"Val AUROC\": val_auroc\n",
    "    })\n",
    "\n",
    "# Save epoch metrics to CSV\n",
    "metrics_df = pd.DataFrame(epoch_metrics)\n",
    "metrics_csv_path = csv_save_path.replace(\".csv\", \"_epoch_metrics.csv\")\n",
    "metrics_df.to_csv(metrics_csv_path, index=False)\n",
    "print(f\"📊 Saved metrics to: {metrics_csv_path}\")\n",
    "\n",
    "\n",
    "# --- Final Test Evaluation ---\n",
    "print(\"\\n🔍 Evaluating best model on the test set...\")\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.eval()\n",
    "\n",
    "total_test_loss = 0\n",
    "correct_test, total_test = 0, 0\n",
    "all_test_labels, all_test_preds = [], []\n",
    "test_predictions_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, file_paths in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_test_loss += loss.item()\n",
    "        probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "        total_test += labels.size(0)\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "        all_test_preds.extend(probs.cpu().numpy())  # For AUROC\n",
    "\n",
    "        # Append test predictions for CSV\n",
    "        for i in range(labels.size(0)):\n",
    "            test_predictions_list.append([\n",
    "                file_paths[i],\n",
    "                int(predicted[i].cpu()),\n",
    "                int(labels[i].cpu())\n",
    "            ])\n",
    "\n",
    "avg_test_loss = total_test_loss / len(test_loader)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "y_true = np.array(all_test_labels)\n",
    "y_pred = np.array([int(p > 0.5) for p in all_test_preds])  # threshold probs at 0.5\n",
    "y_probs = np.array(all_test_preds)  # for AUROC\n",
    "\n",
    "# Compute metrics\n",
    "test_accuracy = (y_pred == y_true).mean()\n",
    "test_precision = precision_score(y_true, y_pred, average=\"binary\")\n",
    "test_recall = recall_score(y_true, y_pred, average=\"binary\")\n",
    "test_f1 = f1_score(y_true, y_pred, average=\"binary\")\n",
    "test_auroc = roc_auc_score(y_true, y_probs)\n",
    "\n",
    "print(f\"\\n📊 Final Test Results:\\n\"\n",
    "      f\"Test Loss: {avg_test_loss:.4f} | Accuracy: {test_accuracy:.4f} | \"\n",
    "      f\"Precision: {test_precision:.4f} | Recall: {test_recall:.4f} | F1 Score: {test_f1:.4f} | AUROC: {test_auroc:.4f}\")\n",
    "\n",
    "wandb.log({\n",
    "    \"test/loss\": avg_test_loss,\n",
    "    \"test/accuracy\": test_accuracy,\n",
    "    \"test/precision\": test_precision,\n",
    "    \"test/recall\": test_recall,\n",
    "    \"test/f1\": test_f1,\n",
    "    \"test/auroc\": test_auroc\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Evaluating best model on the test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vivian\\AppData\\Local\\Temp\\ipykernel_30164\\968844249.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_save_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 2614/2614 [00:24<00:00, 106.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Final Test Results:\n",
      "Test Loss: 0.6925 | Accuracy: 0.5798 | Precision: 0.2946 | Recall: 0.6576 | F1 Score: 0.4069 | AUROC: 0.6601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- Final Test Evaluation ---\n",
    "print(\"\\n🔍 Evaluating best model on the test set...\")\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.eval()\n",
    "\n",
    "total_test_loss = 0\n",
    "correct_test, total_test = 0, 0\n",
    "all_test_labels, all_test_preds = [], []\n",
    "test_predictions_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, file_paths in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_test_loss += loss.item()\n",
    "        probs = torch.softmax(outputs, dim=1)[:, 1]\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "        total_test += labels.size(0)\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "        all_test_preds.extend(probs.cpu().numpy())  # For AUROC\n",
    "\n",
    "        # Append test predictions for CSV\n",
    "        for i in range(labels.size(0)):\n",
    "            test_predictions_list.append([\n",
    "                file_paths[i],\n",
    "                int(predicted[i].cpu()),\n",
    "                int(labels[i].cpu())\n",
    "            ])\n",
    "\n",
    "avg_test_loss = total_test_loss / len(test_loader)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "y_true = np.array(all_test_labels)\n",
    "y_pred = np.array([int(p > 0.5) for p in all_test_preds])  # threshold probs at 0.5\n",
    "y_probs = np.array(all_test_preds)  # for AUROC\n",
    "\n",
    "# Compute metrics\n",
    "test_accuracy = (y_pred == y_true).mean()\n",
    "test_precision = precision_score(y_true, y_pred, average=\"binary\")\n",
    "test_recall = recall_score(y_true, y_pred, average=\"binary\")\n",
    "test_f1 = f1_score(y_true, y_pred, average=\"binary\")\n",
    "test_auroc = roc_auc_score(y_true, y_probs)\n",
    "\n",
    "print(f\"\\n📊 Final Test Results:\\n\"\n",
    "      f\"Test Loss: {avg_test_loss:.4f} | Accuracy: {test_accuracy:.4f} | \"\n",
    "      f\"Precision: {test_precision:.4f} | Recall: {test_recall:.4f} | F1 Score: {test_f1:.4f} | AUROC: {test_auroc:.4f}\")\n",
    "\n",
    "wandb.log({\n",
    "    \"test/loss\": avg_test_loss,\n",
    "    \"test/accuracy\": test_accuracy,\n",
    "    \"test/precision\": test_precision,\n",
    "    \"test/recall\": test_recall,\n",
    "    \"test/f1\": test_f1,\n",
    "    \"test/auroc\": test_auroc\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uni og patches - updated LR 1ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Setup\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Only optimize the classification head (linear layer) - for linear probing\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=2e-5) # increased learning rate\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = 'cuda'\n",
    "num_epochs = 1\n",
    "patience = 5\n",
    "\n",
    "# model_save_path = '/Users/Vivian/Documents/CONCH/_finetune_weights_CONCH/with_val_earlystop.pth'\n",
    "# csv_save_path = \"/Users/Vivian/Documents/CONCH/patch_predictions/with_val_earlystop.csv\"\n",
    "\n",
    "# Define model save path \n",
    "model_save_path = \"/Users/Vivian/Documents/CONCH/_finetune_weights_UNI/linprob_ann_newLR_1ep.pth\"\n",
    "# Define CSV path for saving patch predictions\n",
    "csv_save_path = \"patch_predictions/annotated/UNI_ann_newLR_1ep.csv\"\n",
    "\n",
    "best_val_accuracy = 0\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# Mixed Precision\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Metrics tracking\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "# Store per-epoch metrics as a list of dicts\n",
    "epoch_metrics = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    correct_train, total_train = 0, 0\n",
    "    all_train_labels, all_train_preds = [], []\n",
    "\n",
    "    for images, labels, _ in tqdm.tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "        all_train_labels.extend(labels.cpu().numpy())\n",
    "        all_train_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # print(f\"Train Loss: {avg_train_loss:.4f} | Accuracy: {train_accuracy:.4f}\")\n",
    "    train_precision = precision_score(all_train_labels, all_train_preds, average=\"binary\")\n",
    "    train_recall = recall_score(all_train_labels, all_train_preds, average=\"binary\")\n",
    "    train_f1 = f1_score(all_train_labels, all_train_preds, average=\"binary\")\n",
    "\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Accuracy: {train_accuracy:.4f} | \"\n",
    "        f\"Precision: {train_precision:.4f} | Recall: {train_recall:.4f} | F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    correct_val, total_val = 0, 0\n",
    "    all_val_labels, all_val_preds = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in tqdm.tqdm(val_loader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "            all_val_labels.extend(labels.cpu().numpy())\n",
    "            all_val_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_accuracy = correct_val / total_val\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    val_precision = precision_score(all_val_labels, all_val_preds, average=\"binary\")\n",
    "    val_recall = recall_score(all_val_labels, all_val_preds, average=\"binary\")\n",
    "    val_f1 = f1_score(all_val_labels, all_val_preds, average=\"binary\")\n",
    "\n",
    "    print(f\"Val Loss: {avg_val_loss:.4f} | Accuracy: {val_accuracy:.4f} | \"\n",
    "          f\"Precision: {val_precision:.4f} | Recall: {val_recall:.4f} | F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "\n",
    "    # Collect metrics for this epoch\n",
    "    epoch_metrics.append({\n",
    "        \"Epoch\": epoch + 1,\n",
    "        \"Train Loss\": avg_train_loss,\n",
    "        \"Train Accuracy\": train_accuracy,\n",
    "        \"Train Precision\": train_precision,\n",
    "        \"Train Recall\": train_recall,\n",
    "        \"Train F1 Score\": train_f1,\n",
    "        \"Val Loss\": avg_val_loss,\n",
    "        \"Val Accuracy\": val_accuracy,\n",
    "        \"Val Precision\": val_precision,\n",
    "        \"Val Recall\": val_recall,\n",
    "        \"Val F1 Score\": val_f1\n",
    "    })\n",
    "\n",
    "\n",
    "    # --- Early Stopping ---\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        # Ensure directory exists\n",
    "        os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "        \n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"✅ Model saved with improved val accuracy: {val_accuracy:.4f}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No improvement for {epochs_no_improve} epoch(s)\")\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"⏹️ Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# --- Plotting ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Val Accuracy')\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Final Test Evaluation ---\n",
    "print(\"\\n🔍 Evaluating best model on the test set...\")\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.eval()\n",
    "\n",
    "total_test_loss = 0\n",
    "correct_test, total_test = 0, 0\n",
    "all_test_labels, all_test_preds = [], []\n",
    "test_predictions_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, file_paths in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "        total_test += labels.size(0)\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "        all_test_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        for i in range(labels.size(0)):\n",
    "            test_predictions_list.append([file_paths[i], predicted[i].item(), labels[i].item()])\n",
    "\n",
    "avg_test_loss = total_test_loss / len(test_loader)\n",
    "test_accuracy = correct_test / total_test\n",
    "test_precision = precision_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "test_recall = recall_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "test_f1 = f1_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "\n",
    "print(f\"\\n📊 Final Test Results:\\n\"\n",
    "      f\"Test Loss: {avg_test_loss:.4f} | Accuracy: {test_accuracy:.4f} | \"\n",
    "      f\"Precision: {test_precision:.4f} | Recall: {test_recall:.4f} | F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "# Save test predictions\n",
    "test_csv_path = csv_save_path.replace(\".csv\", \"_test.csv\")\n",
    "df_test = pd.DataFrame(test_predictions_list, columns=[\"Patch Path\", \"Predicted\", \"True Label\"])\n",
    "df_test.to_csv(test_csv_path, index=False)\n",
    "print(f\"✅ Test predictions saved to: {test_csv_path}\")\n",
    "\n",
    "\n",
    "# --- Append summary row ---\n",
    "summary_row = {\n",
    "    \"Epoch\": \"Best Val\",\n",
    "    \"Train Loss\": \"\",\n",
    "    \"Train Accuracy\": \"\",\n",
    "    \"Train Precision\": \"\",\n",
    "    \"Train Recall\": \"\",\n",
    "    \"Train F1 Score\": \"\",\n",
    "    \"Val Loss\": \"\",\n",
    "    \"Val Accuracy\": best_val_accuracy,\n",
    "    \"Val Precision\": \"\",\n",
    "    \"Val Recall\": \"\",\n",
    "    \"Val F1 Score\": \"\",\n",
    "    \"Test Loss\": avg_test_loss,\n",
    "    \"Test Accuracy\": test_accuracy,\n",
    "    \"Test Precision\": test_precision,\n",
    "    \"Test Recall\": test_recall,\n",
    "    \"Test F1 Score\": test_f1\n",
    "}\n",
    "epoch_metrics.append(summary_row)\n",
    "\n",
    "\n",
    "metrics_df = pd.DataFrame(epoch_metrics)\n",
    "metrics_csv_path = csv_save_path.replace(\".csv\", \"_epoch_metrics.csv\")\n",
    "metrics_df.to_csv(metrics_csv_path, index=False)\n",
    "print(f\"📊 Epoch metrics saved to: {metrics_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uni original patches (no CL) - updated LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Setup\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Only optimize the classification head (linear layer) - for linear probing\n",
    "optimizer = torch.optim.Adam(model.fc.parameters(), lr=2e-5) # increased learning rate\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = 'cuda'\n",
    "num_epochs = 10\n",
    "patience = 5\n",
    "\n",
    "# model_save_path = '/Users/Vivian/Documents/CONCH/_finetune_weights_CONCH/with_val_earlystop.pth'\n",
    "# csv_save_path = \"/Users/Vivian/Documents/CONCH/patch_predictions/with_val_earlystop.csv\"\n",
    "\n",
    "# Define model save path \n",
    "model_save_path = \"/Users/Vivian/Documents/CONCH/_finetune_weights_UNI/linprob_ann_newLR.pth\"\n",
    "# Define CSV path for saving patch predictions\n",
    "csv_save_path = \"patch_predictions/annotated/UNI_ann_newLR.csv\"\n",
    "\n",
    "best_val_accuracy = 0\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# Mixed Precision\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Metrics tracking\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "# Store per-epoch metrics as a list of dicts\n",
    "epoch_metrics = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    correct_train, total_train = 0, 0\n",
    "    all_train_labels, all_train_preds = [], []\n",
    "\n",
    "    for images, labels, _ in tqdm.tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "        all_train_labels.extend(labels.cpu().numpy())\n",
    "        all_train_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # print(f\"Train Loss: {avg_train_loss:.4f} | Accuracy: {train_accuracy:.4f}\")\n",
    "    train_precision = precision_score(all_train_labels, all_train_preds, average=\"binary\")\n",
    "    train_recall = recall_score(all_train_labels, all_train_preds, average=\"binary\")\n",
    "    train_f1 = f1_score(all_train_labels, all_train_preds, average=\"binary\")\n",
    "\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f} | Accuracy: {train_accuracy:.4f} | \"\n",
    "        f\"Precision: {train_precision:.4f} | Recall: {train_recall:.4f} | F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "\n",
    "    # --- Validation ---\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    correct_val, total_val = 0, 0\n",
    "    all_val_labels, all_val_preds = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels, _ in tqdm.tqdm(val_loader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "            all_val_labels.extend(labels.cpu().numpy())\n",
    "            all_val_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_accuracy = correct_val / total_val\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n",
    "\n",
    "    val_precision = precision_score(all_val_labels, all_val_preds, average=\"binary\")\n",
    "    val_recall = recall_score(all_val_labels, all_val_preds, average=\"binary\")\n",
    "    val_f1 = f1_score(all_val_labels, all_val_preds, average=\"binary\")\n",
    "\n",
    "    print(f\"Val Loss: {avg_val_loss:.4f} | Accuracy: {val_accuracy:.4f} | \"\n",
    "          f\"Precision: {val_precision:.4f} | Recall: {val_recall:.4f} | F1 Score: {val_f1:.4f}\")\n",
    "\n",
    "\n",
    "    # Collect metrics for this epoch\n",
    "    epoch_metrics.append({\n",
    "        \"Epoch\": epoch + 1,\n",
    "        \"Train Loss\": avg_train_loss,\n",
    "        \"Train Accuracy\": train_accuracy,\n",
    "        \"Train Precision\": train_precision,\n",
    "        \"Train Recall\": train_recall,\n",
    "        \"Train F1 Score\": train_f1,\n",
    "        \"Val Loss\": avg_val_loss,\n",
    "        \"Val Accuracy\": val_accuracy,\n",
    "        \"Val Precision\": val_precision,\n",
    "        \"Val Recall\": val_recall,\n",
    "        \"Val F1 Score\": val_f1\n",
    "    })\n",
    "\n",
    "\n",
    "    # --- Early Stopping ---\n",
    "    if val_accuracy > best_val_accuracy:\n",
    "        best_val_accuracy = val_accuracy\n",
    "        epochs_no_improve = 0\n",
    "\n",
    "        # Ensure directory exists\n",
    "        os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
    "        \n",
    "        torch.save(model.state_dict(), model_save_path)\n",
    "        print(f\"✅ Model saved with improved val accuracy: {val_accuracy:.4f}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"No improvement for {epochs_no_improve} epoch(s)\")\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"⏹️ Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "# --- Plotting ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Val Accuracy')\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Final Test Evaluation ---\n",
    "print(\"\\n🔍 Evaluating best model on the test set...\")\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.eval()\n",
    "\n",
    "total_test_loss = 0\n",
    "correct_test, total_test = 0, 0\n",
    "all_test_labels, all_test_preds = [], []\n",
    "test_predictions_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, file_paths in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "        total_test += labels.size(0)\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "        all_test_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        for i in range(labels.size(0)):\n",
    "            test_predictions_list.append([file_paths[i], predicted[i].item(), labels[i].item()])\n",
    "\n",
    "avg_test_loss = total_test_loss / len(test_loader)\n",
    "test_accuracy = correct_test / total_test\n",
    "test_precision = precision_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "test_recall = recall_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "test_f1 = f1_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "\n",
    "print(f\"\\n📊 Final Test Results:\\n\"\n",
    "      f\"Test Loss: {avg_test_loss:.4f} | Accuracy: {test_accuracy:.4f} | \"\n",
    "      f\"Precision: {test_precision:.4f} | Recall: {test_recall:.4f} | F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "# Save test predictions\n",
    "test_csv_path = csv_save_path.replace(\".csv\", \"_test.csv\")\n",
    "df_test = pd.DataFrame(test_predictions_list, columns=[\"Patch Path\", \"Predicted\", \"True Label\"])\n",
    "df_test.to_csv(test_csv_path, index=False)\n",
    "print(f\"✅ Test predictions saved to: {test_csv_path}\")\n",
    "\n",
    "\n",
    "# --- Append summary row ---\n",
    "summary_row = {\n",
    "    \"Epoch\": \"Best Val\",\n",
    "    \"Train Loss\": \"\",\n",
    "    \"Train Accuracy\": \"\",\n",
    "    \"Train Precision\": \"\",\n",
    "    \"Train Recall\": \"\",\n",
    "    \"Train F1 Score\": \"\",\n",
    "    \"Val Loss\": \"\",\n",
    "    \"Val Accuracy\": best_val_accuracy,\n",
    "    \"Val Precision\": \"\",\n",
    "    \"Val Recall\": \"\",\n",
    "    \"Val F1 Score\": \"\",\n",
    "    \"Test Loss\": avg_test_loss,\n",
    "    \"Test Accuracy\": test_accuracy,\n",
    "    \"Test Precision\": test_precision,\n",
    "    \"Test Recall\": test_recall,\n",
    "    \"Test F1 Score\": test_f1\n",
    "}\n",
    "epoch_metrics.append(summary_row)\n",
    "\n",
    "\n",
    "metrics_df = pd.DataFrame(epoch_metrics)\n",
    "metrics_csv_path = csv_save_path.replace(\".csv\", \"_epoch_metrics.csv\")\n",
    "metrics_df.to_csv(metrics_csv_path, index=False)\n",
    "print(f\"📊 Epoch metrics saved to: {metrics_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Plotting ---\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(val_accuracies, label='Val Accuracy')\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Final Test Evaluation ---\n",
    "print(\"\\n🔍 Evaluating best model on the test set...\")\n",
    "model.load_state_dict(torch.load(model_save_path))\n",
    "model.eval()\n",
    "\n",
    "total_test_loss = 0\n",
    "correct_test, total_test = 0, 0\n",
    "all_test_labels, all_test_preds = [], []\n",
    "test_predictions_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, file_paths in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        total_test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_test += (predicted == labels).sum().item()\n",
    "        total_test += labels.size(0)\n",
    "        all_test_labels.extend(labels.cpu().numpy())\n",
    "        all_test_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        for i in range(labels.size(0)):\n",
    "            test_predictions_list.append([file_paths[i], predicted[i].item(), labels[i].item()])\n",
    "\n",
    "avg_test_loss = total_test_loss / len(test_loader)\n",
    "test_accuracy = correct_test / total_test\n",
    "test_precision = precision_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "test_recall = recall_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "test_f1 = f1_score(all_test_labels, all_test_preds, average=\"binary\")\n",
    "\n",
    "print(f\"\\n📊 Final Test Results:\\n\"\n",
    "      f\"Test Loss: {avg_test_loss:.4f} | Accuracy: {test_accuracy:.4f} | \"\n",
    "      f\"Precision: {test_precision:.4f} | Recall: {test_recall:.4f} | F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "# Save test predictions\n",
    "test_csv_path = csv_save_path.replace(\".csv\", \"_test.csv\")\n",
    "df_test = pd.DataFrame(test_predictions_list, columns=[\"Patch Path\", \"Predicted\", \"True Label\"])\n",
    "df_test.to_csv(test_csv_path, index=False)\n",
    "print(f\"✅ Test predictions saved to: {test_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UNI2 - Trying to use mixed precison to speed up training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taking very long to train - only 14% through first epoch after 7 hours\n",
    "\n",
    "import torch\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# Define loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Define number of epochs\n",
    "num_epochs = 5\n",
    "\n",
    "# Define model save path\n",
    "model_save_path = \"/Users/Vivian/Documents/CONCH/_finetune_weights_UNI2/all_slides_model1.pth\"\n",
    "\n",
    "# Define CSV path for saving patch predictions\n",
    "csv_save_path = \"/Users/Vivian/Documents/CONCH/patch_predictions_UNI2.csv\"\n",
    "\n",
    "# Best accuracy tracker\n",
    "best_accuracy = 0\n",
    "\n",
    "# Enable AMP for mixed precision training\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Device setup\n",
    "device = 'cuda'\n",
    "\n",
    "# Start training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Starting epoch {epoch+1}/{num_epochs}\")\n",
    "    model.train()\n",
    "\n",
    "    total_train_loss = 0\n",
    "    num_train_batches = 0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    all_train_labels = []\n",
    "    all_train_predictions = []\n",
    "\n",
    "    # Training phase\n",
    "    for batch in tqdm.tqdm(train_loader, desc=\"Training\"):\n",
    "        images, labels, img_path = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass using AMP\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass with gradient scaling\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Track training loss\n",
    "        total_train_loss += loss.item()\n",
    "        num_train_batches += 1\n",
    "\n",
    "        # Track training accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "        all_train_labels.extend(labels.cpu().numpy())\n",
    "        all_train_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    avg_train_loss = total_train_loss / num_train_batches\n",
    "    train_accuracy = correct_train / total_train\n",
    "    train_precision = precision_score(all_train_labels, all_train_predictions, average=\"binary\")\n",
    "    train_recall = recall_score(all_train_labels, all_train_predictions, average=\"binary\")\n",
    "    train_f1 = f1_score(all_train_labels, all_train_predictions, average=\"binary\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Accuracy: {train_accuracy:.4f}, Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1 Score: {train_f1:.4f}\")\n",
    "\n",
    "    # Evaluation phase\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_test_loss = 0\n",
    "        num_test_batches = 0\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        all_test_labels = []\n",
    "        all_test_predictions = []\n",
    "        predictions_list = []  # List to store patch-level predictions\n",
    "\n",
    "        for batch in tqdm.tqdm(test_loader, desc=\"Testing\"):\n",
    "            images, labels, file_paths = batch\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass using AMP\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "            # Track test loss\n",
    "            total_test_loss += loss.item()\n",
    "            num_test_batches += 1\n",
    "\n",
    "            # Track test accuracy\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "            total_test += labels.size(0)\n",
    "            all_test_labels.extend(labels.cpu().numpy())\n",
    "            all_test_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "            # Store predictions for CSV\n",
    "            for i in range(labels.size(0)):\n",
    "                predictions_list.append([file_paths[i], predicted[i].item(), labels[i].item()])\n",
    "\n",
    "        # Compute test classification metrics\n",
    "        test_accuracy = correct_test / total_test\n",
    "        test_precision = precision_score(all_test_labels, all_test_predictions, average=\"binary\")\n",
    "        test_recall = recall_score(all_test_labels, all_test_predictions, average=\"binary\")\n",
    "        test_f1 = f1_score(all_test_labels, all_test_predictions, average=\"binary\")\n",
    "        avg_test_loss = total_test_loss / num_test_batches  # Compute average test loss\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Test Loss: {avg_test_loss:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} - Test Accuracy: {test_accuracy:.4f}, Precision: {test_precision:.4f}, Recall: {test_recall:.4f}, F1 Score: {test_f1:.4f}\")\n",
    "\n",
    "        # Save model and predictions CSV only if test accuracy improves\n",
    "        if test_accuracy > best_accuracy:\n",
    "            best_accuracy = test_accuracy\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "            print(f\"Model saved with accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "            # Save predictions to CSV\n",
    "            df_predictions = pd.DataFrame(predictions_list, columns=[\"Patch Path\", \"Predicted\", \"True Label\"])\n",
    "            df_predictions.to_csv(csv_save_path, index=False)\n",
    "            print(f\"Patch predictions saved to: {csv_save_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
